{"pages":[{"title":"关于我","text":"简介#zhw,male 经历#2021.11-至今 阿里 Java研发2020.03-2021.11 快手 Java研发2017.07-2020.03 美团点评 Java研发2013.9-2017.07 河北大学 软件工程 爱好#movie, nba, music 时间线、关键字#2023 热火 互动2022 妮妮 买房2021 结婚 淘特2020 杭州 疫情2019 水长城 西安 华山 兵马俑 杭州 jojo 橘猫2018 立水桥 龙德 杭州 天通东苑 LOL 小草包2017 保定 北京 西二旗 西北旺 百望山 美团 望京东 立水桥 厦门","link":"/about/index.html"},{"title":"FAQ","text":"推荐信息来源 我的 RSS 订阅 javadoop 源码解析 面试题","link":"/FAQ/index.html"},{"title":"算法","text":"base backtrack nodelist dp hashmap pointer tree stack","link":"/arithmetic/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"做菜","text":"","link":"/cook/index.html"},{"title":"friends","text":"","link":"/friends/index.html"},{"title":"知识储备","text":"java juc spring jvm mysql redis mq design dt other","link":"/interview/index.html"},{"title":"总结","text":"一、述职前的准备1、review工作，理出来框架日常工作较为零碎，先梳理过去一年做过的项目，再梳理出框架和价值。做多少事情不重要，重要的是在做的事情是不是都是有价值的。 2、PPT准备1）明确你在项目中承担的角色，准确的定位，不多不少，让评委明白你的角色和工作边界。 2）项目表达上，体现出你的工作专业度，你为什么做的比别人好。 3）提前想清楚，评委会问到什么问题，想清楚所做项目对于用户和平台的价值是什么。 3、心态调整对晋升的理解：重要的不是结果，而是为晋升所做的努力和准备过程，在答辩过程中收获的建议、感悟，和新的层级带来的机会和历练。 二、述职中的经验分享1、【自我陈述环节】1）不要紧张，尽可能开头部分说得顺，会容易进入到一个好的状态，后面的表达会渐入佳境。 2）最好能做到演讲前脱稿，可以在脑海中熟练清晰的想清楚每一页的逻辑和重点，不受到PPT的限制，可以更自如，更通顺的表达。 3）表现出对自我工作的认同感，让评委感受到你对工作有热情，有理解，有思考。 2、【问题回答环节】1）听明白评委的问题，这个最最重要，否则后续的回答可能会鸡同鸭讲，文不对题。 2）听懂问题，再去快速思考评委提问的背后，实际是想了解什么。 3）脑海中整理出逻辑，回答问题切中要害，尽可能不说废话，条理清楚的表达出来。 3、【评委建议环节】1）认真听取评委的反馈建议，不仅是对晋升答辩，也是对工作和方法的建议。 三、晋升成功原因分析或心得1、日常工作多思考2、PPT理清楚思路逻辑3、现场表达流利、回答问题清晰 最终，晋升是很好的一次，总结自己一段时间内的工作和成长的机会！","link":"/summary/index.html"},{"title":"专题学习","text":"","link":"/subject/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"旅行","text":"2019 国庆上海苏州四天旅行 2018 清明杭州游","link":"/travel/index.html"},{"title":"周记","text":"2019-09-09 ~ 2019-09-15#早睡早起24:15 左右睡，8:20 起床可以说是晚睡晚起了，应该是23点睡，7点起 本周目标完成了多少上周做了5道题，有简单的，所以不算是很充分，效率没有很高，算完成了70%吧 本周遇到什么开心的事情本周回了家，中秋节，和家人分享快乐，讨论事情，回家也像旅游，让人舒服 本周的不足如何改善下周开始工作日规划表早 7点-7点5分 起床7点5分-7点20分 下楼晨练7点20-7点30洗漱7点30-7点55做饭吃饭8点-8点50学习9点上班 晚 20点-21点 下班回家21点-21点30 做明天午饭21点30-22点 下楼遛弯22点-22点半 洗漱玩耍22点半-23点 上床睡觉","link":"/weeklyRecord/index.html"}],"posts":[{"title":"回溯算法","text":"037-数字在排序数组中出现的次数（二分查找） 电话号码的字母组合 22. 有效括号 39. 组合总和 46. 全排列 139. 单词拆分 037-数字在排序数组中出现的次数（二分查找）#123456789101112131415161718192021222324252627282930313233343536public class Solution { public int GetNumberOfK(int [] array , int k) { int leftIndex = -1,start=0,end=array.length-1,rightIndex=-1; while(start &lt;= end) { int mid = (start+end)/2; if(array[mid] &gt; k) { end = mid-1; }else if(array[mid] &lt; k){ start = mid+1; }else{ leftIndex = mid; end = mid-1; } } start = 0; end = array.length-1; while(start &lt;= end) { int mid = (start+end)/2; if(array[mid] &gt; k) { end = mid-1; }else if(array[mid] &lt; k){ start = mid+1; }else{ rightIndex = mid; start = mid+1; } } if(array.length == 0 || rightIndex == -1) return 0; return rightIndex-leftIndex+1; }} 电话号码的字母组合#12345678910111213141516171819202122232425262728293031323334353637class Solution { Map&lt;String, String&gt; phone = new HashMap&lt;String, String&gt;() {{ put(\"2\", \"abc\"); put(\"3\", \"def\"); put(\"4\", \"ghi\"); put(\"5\", \"jkl\"); put(\"6\", \"mno\"); put(\"7\", \"pqrs\"); put(\"8\", \"tuv\"); put(\"9\", \"wxyz\"); }}; public List&lt;String&gt; letterCombinations(String digits) { List&lt;String&gt; result = new ArrayList&lt;&gt;(); if (digits == null || digits.length() == 0) { return result; } helper(digits, \"\", result); return result; } public void helper(String digits, String combination, List&lt;String&gt; result) { if (\"\".equals(digits)) { result.add(combination); return; } String digit = digits.substring(0, 1); String letters = phone.get(digit); for (int i = 0; i &lt; letters.length(); i++) { String letter = letters.substring(i, i + 1); helper(digits.substring(1), combination + letter, result); } }} 22. 有效括号#给出 n 代表生成括号的对数，请你写出一个函数，使其能够生成所有可能的并且有效的括号组合。 1234567891011121314151617181920212223public List&lt;String&gt; generateParenthesis(int n) { List&lt;String&gt; ans = new ArrayList(); if (n &lt;= 0) { return ans; } backtrack(ans, \"\" , 0, 0, n); return ans;}public void backtrack(List&lt;String&gt; result, String cur, int open, int close, int max) { if (cur.length() == max * 2) { result.add(cur); return; } if (open &lt; max) { backtrack(result, cur + \"(\", open + 1, close, max); } if (close &lt; open) { backtrack(result, cur + \")\", open, close + 1, max); }} 39. 组合总和#给定一个无重复元素的数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。 candidates 中的数字可以无限制重复被选取。 1234567891011121314151617181920212223242526public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) { List&lt;List&lt;Integer&gt;&gt; result = new ArrayList(); List&lt;Integer&gt; cur = new ArrayList(); helper(result, cur, 0, target, candidates, 0); return result;}private void helper(List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; cur, int sum, int target, int[] candidates, int index) { if (sum &gt; target) { return; } if (sum == target) { result.add(new ArrayList(cur)); return; } for (int i = 0;i &lt; candidates.length; i++) { if (i &lt; index) { continue; } cur.add(candidates[i]); helper(result, cur, sum + candidates[i], target, candidates, i); cur.remove(cur.size() - 1); }} 46. 全排列#1234567891011121314151617181920212223public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) { List&lt;List&lt;Integer&gt;&gt; result = new ArrayList(); helper(result, new ArrayList(), nums, new int[nums.length]); return result;}private void helper(List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; cur, int[] nums, int[] index) { if (cur.size() == nums.length) { result.add(new ArrayList(cur)); return; } for (int i=0; i &lt; nums.length; i++) { if (index[i] == 1) { continue; } index[i] = 1; cur.add(nums[i]); helper(result, cur, nums, index); index[i] = 0; cur.remove(cur.size() - 1); }} 139. 单词拆分#给定一个非空字符串 s 和一个包含非空单词列表的字典 wordDict，判定 s 是否可以被空格拆分为一个或多个在字典中出现的单词。 说明： 拆分时可以重复使用字典中的单词。你可以假设字典中没有重复的单词。 123456789101112131415161718192021public boolean wordBreak(String s, List&lt;String&gt; wordDict) { return helper(s, new HashSet(wordDict), 0, new Boolean[s.length()]);}private boolean helper(String s, Set&lt;String&gt; wordDict, int start, Boolean[] menu) { if (start == s.length()) { return true; } if (menu[start] != null) { return menu[start]; } for(int end = start + 1; end &lt;= s.length(); end++) { String sub = s.substring(start, end); if (wordDict.contains(sub) &amp;&amp; helper(s, wordDict, end, menu)) { return menu[start] = true; } } return menu[start] = false;}","link":"/2019/09/09/arithmetic/backtrack/"},{"title":"动态规划算法","text":"030-连续子数组的最大和 62. 不同路径 动态规划 030-连续子数组的最大和#1234567891011121314151617181920public int FindGreatestSumOfSubArray(int[] array) { //设置指针从0开始向右移动，如果当前指针 + 前面指针代表的和为sum，计算max //如果sum &gt; 0 移动 sum = sum //如果素sum &lt; 0 移动 sum归零 重写跳转指针 if(array == null){ return 0; } int i = 0; int max = Integer.MIN_VALUE; int sum = 0; while(i &lt; array.length){ sum = array[i] + sum; max = max &gt; sum ? max : sum; if(sum &lt; 0){ sum = 0; } i++; } return max;} 62. 不同路径#一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为“Start” ）。 12345678910111213141516171819202122232425262728public int uniquePaths(int m, int n) { int[][] res = new int[m][n]; for (int i = 0; i &lt; m; i++) { for (int j = 0; j &lt; n; j++) { if (i == 0) res[0][j] = 1; else if (j == 0) res[i][0] = 1; else res[i][j] = res[i - 1][j] + res[i][j - 1]; } } return res[m - 1][n - 1];}public int uniquePaths(int m, int n) { int[] dp = new int[n]; for (int i = 0; i &lt; n; i++) { dp[i] = 1; } for (int i = 1; i &lt; m; i++) { for (int j = 1; j &lt; n; j++) { dp[j] = dp[j] + dp[j - 1]; } } return dp[n - 1];}","link":"/2019/09/09/arithmetic/dp/"},{"title":"指针算法","text":"014-链表中倒数第k个结点 041-和为S的连续正数序列(滑动窗口思想) * 042-和为S的两个数字(双指针思想) * 盛最多水的容器 三数之和 LinkedList 014-链表中倒数第k个结点#双指针，快指针先走k-1步，然后快慢指针一起走，当快指针走到最后一个节点，慢指针指向倒数第K个节点 1234567891011121314151617181920public class Solution { public ListNode FindKthToTail(ListNode head,int k) { if(head == null || k ==0 ){ return null; } ListNode slow=head; ListNode fast=head; for(int i=0;i&lt;k;i++){ if(fast == null){ return null; } fast=fast.next; } while(fast!=null){ slow=slow.next; fast=fast.next; } return slow; }} 041-和为S的连续正数序列(滑动窗口思想) *#1234567891011121314151617181920212223public ArrayList&lt;ArrayList&lt;integer&gt; &gt; FindContinuousSequence(int sum) { ArrayList&lt;ArrayList&lt;integer&gt;&gt; p=new ArrayList&lt;ArrayList&lt;integer&gt;&gt;(); //因为是连续的，构成等差数列，用等差数列的求和公式 int low=1,hight=2; while(low&lt;hight) { int temp=(low+hight)*(hight-low+1)/2; //如果相等，说明这个连续的数列可以构成和为sum if(temp==sum) { ArrayList&lt;integer&gt; a=new ArrayList&lt;integer&gt;(); for(int i=low;i&lt;=hight;i++) { a.add(i); } p.add(a); //继续找下一组 low++; }else if (temp&lt;sum) { hight++; }else { low++; } } return p;} 042-和为S的两个数字(双指针思想) *#左右双指针 12345678910111213141516public ArrayList&lt;Integer&gt; FindNumbersWithSum(int[] array, int sum) { ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); int l = 0, r = array.length - 1; while (l &lt; r) { if (array[l] + array[r] == sum) { list.add(array[l]); list.add(array[r]); break; } else if (array[l] + array[r] &gt; sum) { r--; } else { l++; } } return list;} 盛最多水的容器#12345678910111213141516public int maxArea(int[] height) { int left = 0, right = height.length - 1; int maxAreaSize = 0; int h = 0, w = 0; while (left &lt; right) { h = Integer.min(height[left], height[right]); w = right - left; maxAreaSize = Integer.max(w * h, maxAreaSize); if (height[left] &lt; height[right]) { left++; } else { right--; } } return maxAreaSize;} 三数之和#12345678910111213141516171819202122232425262728public List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) { List&lt;List&lt;Integer&gt;&gt; result = new ArrayList(); // 排序 Arrays.sort(nums); int l,r,sum; // 固定最左边的数字, 保证不重复 for (int i=0; i&lt;nums.length; i++) { if(i &gt; 0 &amp;&amp; nums[i] == nums[i-1]) continue; l = i+1; r = nums.length - 1; while (l &lt; r) { sum = nums[i] + nums[l] + nums[r]; if (sum == 0) { result.add(Arrays.asList(nums[i],nums[l],nums[r])); while (l &lt; r &amp;&amp; nums[l] == nums[l + 1]) l++; // 去重 while (l &lt; r &amp;&amp; nums[r] == nums[r - 1]) r--; // 去重 l++; } else if (sum &lt; 0) { l++; } else { r--; } } } return result;}","link":"/2019/09/09/arithmetic/pointer/"},{"title":"链表算法","text":"014-链表中倒数第k个结点 015-反转链表 016-合并两个有序链表 036-两个链表的第一个公共结点 055-链表中环的入口结点 056-删除链表中重复的结点 19. 删除链表的倒数第N个节点 LinkedList 014-链表中倒数第k个结点#双指针，快指针先走k-1步，然后快慢指针一起走，当快指针走到最后一个节点，慢指针指向倒数第K个节点 1234567891011121314151617181920public class Solution { public ListNode FindKthToTail(ListNode head,int k) { if(head == null || k ==0 ){ return null; } ListNode slow=head; ListNode fast=head; for(int i=0;i&lt;k;i++){ if(fast == null){ return null; } fast=fast.next; } while(fast!=null){ slow=slow.next; fast=fast.next; } return slow; }} 015-反转链表# 无需额外空间，依次反转，三个指针 用栈 12345678910111213141516public ListNode reverseList(ListNode head) { // 判断链表为空或长度为1的情况 if(head == null || head.next == null){ return head; } ListNode pre = null; // 当前节点的前一个节点 ListNode cur = head; ListNode next = null; // 当前节点的下一个节点 while( cur != null){ next = cur.next; // 记录当前节点的下一个节点位置； cur.next = pre; // 让当前节点指向前一个节点位置，完成反转 pre = cur; // pre 往右走 cur = next;// 当前节点往右继续走 } return pre;} 016-合并两个有序链表#和归并一样 1234567891011121314151617181920212223242526272829303132public ListNode Merge(ListNode list1, ListNode list2) { if (list1 == null) { return list2; } if (list2 == null) { return list1; } ListNode headNode = new ListNode(-1); ListNode pNode = headNode; pNode.next = null; while (list1 != null &amp;&amp; list2 != null) { if (list1.val &lt;= list2.val) { pNode.next = list1; pNode = list1; list1 = list1.next; } else { pNode.next = list2; pNode = list2; list2 = list2.next; } } if (list1 != null) { pNode.next = list1; } if (list2 != null) { pNode.next = list2; } return headNode.next;} 036-两个链表的第一个公共结点#思路1： 长的先走k步, 再快慢一起思路2： 两个指针从两个链表走，如果一个走完就走另一个，这样先走短的指针会先走长的k步，其实第二条的时候后半部分是一样的，前面的长度相同，所以这时候走到后面肯定是一样的. 12345678910public ListNode FindFirstCommonNode(ListNode pHead1, ListNode pHead2) { if (pHead1 == null || pHead2 == null) return null; ListNode p1 = pHead1; ListNode p2 = pHead2; while (p1 != p2) { p1 = p1 == null ? pHead2 : p1.next; p2 = p2 == null ? pHead1 : p2.next; } return p1;} 055-链表中环的入口结点#先快慢节点，确定有环，并找到相交节点，再从相交节点和开始节点同时开始，当相等的时候，就是环的入口节点。 123456789101112131415161718192021222324public ListNode entryNodeOfLoop(ListNode pHead) { if(pHead==null|| pHead.next==null|| pHead.next.next==null) return null; ListNode fast=pHead.next.next; ListNode slow=pHead.next; /////先判断有没有环 while(fast!=slow){ if(fast.next!=null&amp;&amp; fast.next.next!=null){ fast=fast.next.next; slow=slow.next; }else{ //没有环,返回 return null; } } //循环出来的话就是有环，且此时fast==slow. fast = pHead; while(fast!=slow){ fast=fast.next; slow=slow.next; } return slow;} 056-删除链表中重复的结点#假的头结点，三个指针，pre、cur、next, 判断是相等去掉中间重复 还是 整体后移 1234567891011121314151617181920public ListNode deleteDuplication(ListNode pHead){ ListNode head = new ListNode(-1); head.next = pHead; ListNode pre = head; ListNode cur = head.next; while (cur != null) { if (cur.next != null &amp;&amp; cur.val == cur.next.val) { while (cur.next != null &amp;&amp; cur.val == cur.next.val) { cur = cur.next; } pre.next = cur.next; cur = cur = cur.next; } else { pre = pre.next; cur = cur.next; } } return head.next;} 19. 删除链表的倒数第N个节点#1234567891011121314151617181920public ListNode removeNthFromEnd(ListNode head, int n) { ListNode dummy = new ListNode(0); dummy.next = head; ListNode first = dummy; ListNode second = dummy; for (int i = 0; i &lt; n + 1; i++) { first = first.next; if (first == null) { return dummy; } } while (first != null) { first = first.next; second = second.next; } second.next = second.next.next; return dummy.next;}","link":"/2019/09/09/arithmetic/nodelist/"},{"title":"栈&队列算法","text":"021-栈的压入、弹出序列 * 215. 数组中的第K个最大元素 021-栈的压入、弹出序列 *#循环压入序列，先压入，再判断是否可以弹出，如果可以，循环弹出，更新弹出序列下标，最终如果栈正好为空，则表示成功 123456789101112131415public boolean IsPopOrder(int [] pushA,int [] popA) { if (pushA.length == 0 || popA.length == 0 || popA.length != pushA.length) return false; Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); int j = 0; for (int i = 0; i &lt; pushA.length; i++) { stack.push(pushA[i]); while (!stack.isEmpty() &amp;&amp; stack.peek() == popA[j]){ stack.pop(); j++; } } return stack.isEmpty();} 215. 数组中的第K个最大元素#在未排序的数组中找到第 k 个最大的元素。请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元素。 1234567891011121314public int findKthLargest(int[] nums, int k) { if (nums.length &lt; k) { return -1; } Queue&lt;Integer&gt; queue = new PriorityQueue&lt;Integer&gt;((a, b) -&gt; a - b); for (int i = 0; i &lt; nums.length; i++) { int num = nums[i]; queue.offer(num); if (queue.size() &gt; k) { queue.poll(); } } return queue.peek();}","link":"/2019/09/09/arithmetic/stack/"},{"title":"hashmap算法","text":"034-第一个只出现一次的字符 03-无重复字符的最长子串 * 146.实现lru 034-第一个只出现一次的字符#1.使用hashmap2.indexof lastindexof 1234567891011public class Solution { public int FirstNotRepeatingChar(String str) { for (int i = 0; i &lt; str.length(); i++) { char t = str.charAt(i); if (str.indexOf(t) == i &amp;&amp; str.lastIndexOf(t) == i){ return i; } } return -1; }} 03-无重复字符的最长子串 *#1234567891011121314151617public int lengthOfLongestSubstring(String s) { char[] chars = s.toCharArray(); int len = chars.length; int left =0, right = 0; int max = 0; Integer index; Map&lt;Character, Integer&gt; indexMap = new HashMap(); for (;right &lt; len;right ++) { char c = chars[right]; if ((index = indexMap.get(c)) != null &amp;&amp; index &gt;= left) { left = index + 1; } indexMap.put(c, right); max = Math.max(max, right - left + 1); } return max;} 146.实现lru#1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class LRUCache { class DNode { int key; int val; DNode pre; DNode next; } private DNode head; private DNode tail; private HashMap&lt;Integer, DNode&gt; cache = new HashMap&lt;Integer, DNode&gt;(); private int capacity; private int size; public LRUCache(int capacity) { this.capacity = capacity; this.size = 0; head = new DNode(); tail = new DNode(); head.next = tail; tail.pre = head; } public int get(int key) { // cache DNode node = cache.get(key); if (node == null) return -1; // 移到最前面 moveToHead(node); return node.val; } public void put(int key, int value) { DNode node = cache.get(key); if (node != null) { node.val = value; moveToHead(node); } else { node = new DNode(); node.key = key; node.val = value; cache.put(key, node); addFirst(node); size++; if (size &gt; capacity) { cache.remove(tail.pre.key); removeNode(tail.pre); size--; } } } private void moveToHead(DNode node) { // 删除节点 removeNode(node); // 放到首节点后面 addFirst(node); } private void removeNode(DNode node) { DNode pre = node.pre; DNode next = node.next; pre.next = next; next.pre = pre; } private void addFirst(DNode node) { DNode next = head.next; node.next = next; node.pre = head; head.next = node; next.pre = node; }}","link":"/2019/09/09/arithmetic/hashmap/"},{"title":"AQS原理解析","text":"谈谈你对AQS的理解#AQS是JUC(java.util.concurrent)中很多同步组件的构建基础，简单来讲，它内部实现主要是状态变量state和一个FIFO队列来完成，同步队列的头结点是当前获取到同步状态的结点，获取同步状态state失败的线程，会被构造成一个结点（或共享式或独占式）加入到同步队列尾部（采用自旋CAS来保证此操作的线程安全），随后线程会阻塞；释放时唤醒头结点的后继结点，使其加入对同步状态的争夺中。 AQS的内部实现# state 资源状态 exclusiveOwnerThread 持有资源的线程 CLH 同步等待队列。 AQS维护一个共享资源state，内置的同步队列由一个一个的Node结点组成，每个Node结点维护一个prev引用和next引用，分别指向自己的前驱和后继结点。 AQS维护两个指针，分别指向队列头部head和尾部tail 继承自AQS的常见类# CountDownLatch、ReentrantLock、Semaphore等 AQS的两种实现方式#独占式&amp;共享式, 这样方便使用者实现不同类型的同步组件，独占式如ReentrantLock，共享式如Semaphore，CountDownLatch，组合式的如ReentrantReadWriteLock。 AQS定义的以下可重写的方法： 1234567891011121314独占式获取同步状态，试着获取，成功返回true，反之为falseprotected boolean tryAcquire(int arg) 独占式释放同步状态，等待中的其他线程此时将有机会获取到同步状态protected boolean tryRelease(int arg) 共享式获取同步状态，返回值大于等于0，代表获取成功；反之获取失败protected int tryAcquireShared(int arg) 共享式释放同步状态，成功为true，失败为falseprotected boolean tryReleaseShared(int arg) 是否在独占模式下被线程占用protected boolean isHeldExclusively() 独占式 1.tryAcquire方法尝试获取锁，如果成功就返回，如果不成功，走到2. 2.把当前线程和等待状态信息构造成一个Node节点，并将结点放入同步队列的尾部 3.该Node结点在队列中尝试获取同步状态，若获取不到，则阻塞结点线程，直到被前驱结点唤醒或者被中断. 以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的 自我实现独占锁示例，待重写方法提供更新state等操作. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import java.util.concurrent.locks.AbstractQueuedSynchronizer;public class MyLock { private final Sync sync = new Sync(); public void lock() { sync.acquire(1); } public void unlock() { sync.release(1); } public boolean isLocked() { return sync.isHeldExclusively(); } private static class Sync extends AbstractQueuedSynchronizer { @Override protected boolean tryAcquire(int arg) { //首先判断状态是否等于=0,如果状态==0，就将status设置为1 if (compareAndSetState(0,1)) { //将当前线程赋值给独占模式的onwer setExclusiveOwnerThread(Thread.currentThread()); return true; } return false; } @Override protected boolean tryRelease(int arg) { if (getState() == 0) { throw new IllegalMonitorStateException(); } setExclusiveOwnerThread(null); setState(0); return true; } @Override protected boolean isHeldExclusively() { return getState() == 1; } }} 共享式 CountDownLatch:任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。 Semaphore:AQS通过state值来控制对共享资源访问的线程数，有线程请求同步状态成功state值减1，若超过共享资源数量获取同步状态失败，则将线程封装共享模式的Node结点加入到同步队列等待。有线程执行完任务释放同步状态后，state值会增加1，同步队列中的线程才有机会获得执行权。公平锁与非公平锁不同在于公平锁申请获取同步状态前都会先判断同步队列中释放存在Node，若有则将当前线程封装成Node结点入队，从而保证按FIFO的方式获取同步状态，而非公平锁则可以直接通过竞争获取线程执行权。 一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。","link":"/2019/06/02/concurrentProgramming/aqs/"},{"title":"CAS原理、缺点、AtomicInteger使用解析","text":"cas原理#CAS（Compare and Swap），即比较并替换, 是设计并发算法时用到的一种技术。简单来说，比较和替换是使用一个期望值和一个变量的当前值进行比较，如果当前变量的值与我们期望的值相等，就使用一个新值替换当前变量的值。 CAS有三个操作数：内存值V、旧的预期值A、要修改的值B，当且仅当预期值A和内存值V相同时，将内存值修改为B并返回true，否则什么都不做并返回false。 在CAS中，比较和替换是一组原子操作，不会被外部打断，且在性能上更占有优势。 Unsafe提供了三个方法用于CAS操作#123456public final native boolean compareAndSwapObject(Object value, long valueOffset, Object expect, Object update);public final native boolean compareAndSwapInt(Object value, long valueOffset, int expect, int update);public final native boolean compareAndSwapLong(Object value, long valueOffset, long expect, long update); 解析AtomicInteger#当我们使用 AtomicInteger 实现多线程的加操作时，分析源码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class AtomicInteger extends Number implements java.io.Serializable {​ // setup to use Unsafe.compareAndSwapInt for updates​ private static final Unsafe unsafe​ = Unsafe.getUnsafe();​ private static final long valueOffset;​ static {​ try {​ valueOffset = unsafe.objectFieldOffset(AtomicInteger.class.getDeclaredField(​ \"value\"));​ }​ catch (Exception ex) {​ throw new Error(ex);​ }​ }​ private volatile int value;​ public final int get() {​ return value;​ }}public final int getAndAdd(int delta) {​ return unsafe.getAndAddInt(this, valueOffset, delta);}// 重点public final int getAndAddInt(Object var1, long var2, int var4) {​ int var5;​ do {​ var5 = this.getIntVolatile(var1, var2);​ } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));​ return var5;} 解析# Unsafe，是CAS的核心类，由于Java方法无法直接访问底层系统，需要通过本地（native）方法来访问，Unsafe相当于一个后门，基于该类可以直接操作特定内存的数据。 变量valueOffset，表示该变量值在内存中的偏移地址，因为Unsafe就是根据内存偏移地址获取数据的。 变量value用volatile修饰，保证了多线程之间的内存可见性. 我们在使用cas更新value的时候，没有用到volatile，但get、set方法获取value时用到了volatile的可见性。这样结合来看使得AtomicInteger类获取的是主存中最新的值 且 更新时cas是原子性操作。 假设线程A和线程B同时执行getAndAdd操作, 因为比较与替换是原子性操作，所以即使在var5获取到相同的值，也会是顺序的更新。 CAS缺点# ABA问题。 如果在这段期间曾经被改成B，然后又改回A，那CAS操作就会误认为它从来没有被修改过。针对这种情况，java并发包中提供了一个带有标记的原子引用类 AtomicStampedReference，它可以通过控制变量值的版本来保证CAS的正确性, 该类提供一个引用和计数变量。 循环时间长开销大。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。 只能保证一个共享变量的原子操作 当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性 从Java1.5开始JDK提供了 AtomicReference 类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作","link":"/2019/05/29/concurrentProgramming/cas/"},{"title":"并发编程笔记-核心问题与BUG源头","text":"并发编程核心问题#其实并发编程可以总结为三个核心问题：分工、同步、互斥。 所谓分工指的是如何高效地拆解任务并分配给线程，而同步指的是线程之间如何协作，互斥则是保证同一时刻只允许一个线程访问共享资源。Java SDK 并发包很大部分内容都是按照这三个维度组织的，例如 Fork/Join 框架就是一种分工模式，CountDownLatch 就是一种典型的同步方式，而可重入锁则是一种互斥手段。 并发编程全景图之思维导图 并发编程BUG源头#1、缓存导致的可见性问题 一个线程对共享变量的修改，另外一个线程能够立刻看到，我们称为可见性 问题在于每个cpu更改的通常是自身cpu缓存，会导致最终的共享变量的结果不可控。 2、线程切换带来的原子性问题 我们把一个或者多个操作在 CPU 执行的过程中不被中断的特性称为原子性 比如：count+=1，非原子性操作，多线程时，最终count的值不会是想要的值，会小一点，因为会同时get， +1 ，然后写到共享内存，这就是原子性问题。 3、编译优化带来的有序性问题 有序性指的是程序按照代码的先后顺序执行。编译器为了优化性能，有时候会改变程序中语句的先后顺序 比如： new 操作上，我们以为的 new 操作应该是： 1.分配内存 2.在内存M上初始化对象 3将M的地址赋给变量引用 但实际上，1分配内存 2将M的地址赋给变量引用 3 在内存M上初始化对象 这时候就会发生引用变量出现空指针，这是一种指令重排序导致的有序性问题，在双检锁的时候会出现。 针对双检锁的个人分析， happens-before应该是为了并发安全， 包括可见性和指令重排，可见性比如一个线程锁了，另一个线程得等到第一个线程释放锁，才能往下走，这时候，再获取到的对象，如果是从内存中获取，就已经是最新的了，因为解锁的时候，jvm强制刷新缓存，相当于第一个线程的修改，对第二个线程可见， 单例模式双检锁的 synchronized 就是用synchronized 保证第二个线程获取到锁之前，第一个线程已经把所处cpu缓存刷新到内存中了 ，在第二个线程进到锁块儿里 也就是第二个if的时候， 可以判断obj != null ， 这是synchronized的作用，保证synchronized块儿里的第二个线程对第一个线程的可见性， 但synchronized块儿外是没有锁的， 如果现在第一个线程走到new 的时候（， 此时new 里是指令重排序的， 先分配内存，obj不为null，最后初始化）， 第二个线程走到 双检锁的第一个 if的时候， 会判断不为null， 会返回一个没有初始化的对象， 第二个线程里会报空指针， 这是因为指令重排序造成的并发问题， 用 happens-before的 第三条 volatile的规则，写操作先行于后面对这个变量的读操作，如果这个obj 是volatile， 第二个线程在走到第一个if的时候，虽然没在synchronized但会等待，因为volatile的obj 还在被第一个线程写入，等写入完毕 ， 第二个线程就可以读了，此时就不会返回一个没有初始化的对象了。 第二个线程读之前，第一个线程写入volatile变量完毕，会刷新cpu缓存到内存，第二个线程可以获取到最新的对象信息，也算是可见性的体现","link":"/2019/04/10/concurrentProgramming/java并发编程/"},{"title":"volatile可见性、内存屏障","text":"总结#volatile关键字具有许多特性，其中最重要的特性就是保证了用volatile修饰的变量对所有线程的可见性。利用内存屏障使得读写、读读、写写 都不能同时发生, 且不能指令重排。 可见性#当一个线程修改了变量的值，新的值会立刻同步到主内存当中。而其他线程读取这个变量的时候，也会从主内存中拉取最新的变量值。 得益于java语言的先行发生原则（happens-before）对于一个volatile变量的写操作先行发生于后面对这个变量的读操作。 内存屏障#内存屏障（Memory Barrier）是一种CPU指令。禁止重排序，控制执行顺序，刷新缓存与获取最新主存数据。 内存屏障也称为内存栅栏或栅栏指令，是一种屏障指令，它使CPU或编译器对屏障指令之前和之后发出的内存操作执行一个排序约束。 这通常意味着在屏障之前发布的操作被保证在屏障之后发布的操作之前执行。 Java内存屏障主要有Load和Store两类。 对Load Barrier来说，在读指令前插入读屏障，可以让高速缓存中的数据失效，重新从主内存加载数据 对Store Barrier来说，在写指令之后插入写屏障，能让写入缓存的最新数据写回到主内存 内存屏障共分为四种类型： LoadLoad屏障：抽象场景：Load1; LoadLoad; Load2Load1 和 Load2 代表两条读取指令。在Load2要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 StoreStore屏障：抽象场景：Store1; StoreStore; Store2Store1 和 Store2代表两条写入指令。在Store2写入执行前，保证Store1的写入操作对其它处理器可见 LoadStore屏障：抽象场景：Load1; LoadStore; Store2在Store2被写入前，保证Load1要读取的数据被读取完毕。 StoreLoad屏障：抽象场景：Store1; StoreLoad; Load2在Load2读取操作执行前，保证Store1的写入对所有处理器可见。StoreLoad屏障的开销是四种屏障中最大的。 简单总结就是读和写之间都支持通过屏障，等前一个完全结束再进行之后的操作 volatile涉及内存屏障# 在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障; 意思等别人写完自己再写，别人等自己写完之后才能读 在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障。 意思等别人读完自己再读，别人等自己读完之后才能写 读写、读读、写写 都不能同时发生, 且不能重排序","link":"/2019/06/02/concurrentProgramming/volatile/"},{"title":"hashtable and concurrenthashmap1.7、1.8","text":"hashtable&amp;concurrenthashmap1.7&amp;1.8 总结 Hashtable原理#Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。 JDK1.7 ConcurrentHashMap#首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。 ConcurrentHashMap 是由 Segment 数组结构和 HahEntry 数组结构组成。 Segment 实现了 ReentrantLock,所以 Segment 是一种可重入锁，扮演锁的角色。HashEntry 用于存储键值对数据。 1static class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable 一个 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和HashMap类似，是一种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个HashEntry数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment的锁。 JDK1.8 ConcurrentHashMap#ConcurrentHashMap取消了Segment分段锁，采用CAS和synchronized来保证并发安全。数据结构跟HashMap1.8的结构类似，数组+链表/红黑二叉树。 synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生并发，效率又提升N倍。（jdk1.7 segment 数组不能扩容，扩容是 segment 数组某个位置内部的数组 HashEntry[] 进行扩容） put源码#1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public V put(K key, V value) { return putVal(key, value, false);}/** Implementation for put and putIfAbsent */final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) { Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) { if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin } else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { V oldVal = null; synchronized (f) { if (tabAt(tab, i) == f) { if (fh &gt;= 0) { binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) { K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) { pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; } } } else if (f instanceof TreeBin) { Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } } if (binCount != 0) { if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } addCount(1L, binCount); return null;} put解析 根据哈希值算出位置i，空位直接放入，CAS不用加锁, 链表插末尾, 树节点, 按树的方式插入。 ConcurrentHashMap不允许key或value为空。 JDK8的ConcurrentHashMap实现只锁住Node，锁粒度更细。并且只对改冲突链加锁，之前的操作都是无锁且线程安全的。 多线程实现：如果检测到其它线程正在为其扩容（检测到被插入的位置被forward节点占有），当前put方法的线程也要参与到扩容中去。 检测到节点位置为空，直接放入，检测到节点非空且不是foward节点，加锁重构链表或树。加入链表后节点长度大于8，要转为红黑树。（扩容后也可能再降回链表） JDK8实现的ConcurrentHashMap总结： JDK7的实现用Segment减小锁粒度，分段。put时仅锁住Segment。get时不加锁，仅用volatile保证可见性。统计size用两次尝试的办法，不一致再加锁。主要问题是冲突链表的增删改查耗时长。 JDK8的设计优化： 直接锁住Node，减小了锁粒度。 设计了MOVED状态，使其它put线程协助扩容。 3个CAS操作保证线程安全，用更轻量的方式替代了锁。 sizeCtl扩容控制符。 足够信作synchronized，不再使用ReentrantLock get源码#get 方法可以根据指定的键，返回对应的键值对，由于是读操作，所以不涉及到并发问题. 12345678910111213141516171819public V get(Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) { if ((eh = e.hash) == h) { if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; } else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) { if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; } } return null;}","link":"/2019/05/31/concurrenthashmap/concurrenthashmap/"},{"title":"权限管理模型学习","text":"本质上可以抽象出用户(User)、对象(Object)、行为(Action)和策略(Policy)的四个基本要素。策略(Policy)决定了用户(User)在一定的条件下对指定的对象(Object)有什么样的行为(Action)。 ACL#ACL即访问控制列表，是基于资源的一种权限控制管理方式。实现原理非常简单，每一项资源都有一个访问列表，记录哪些用户可以对这个资源做CRUD的操作。当用户访问某个资源的时候，系统会检测用户是否在访问列表里，从而确定用户是否有对资源的操作权限 RBAC#RBAC, 相比与ACL的直接用户上赋予权限 引入角色：角色 —&gt; 权限的集合，批量操作权限，权限可以统一分配和回收，角色可以和企业的岗位对应，能更加好理解和维护。 引入组织架构：组织部门 —&gt; 人员的集合， 批量操作人员 （eg: 赋予部门权限，或判断用户是否在组织中） RBAC的特点如下： 优点是权限只和角色关联，可以统一分配和回收，使用简单，也降低了维护成本。角色可以和企业的岗位对应，能更加好理解和维护。 缺点是当某个角色下的某些用户需要做特别的权限限定，例如去除一些权限，就无能为力。另外，角色规划不好的情况下容易造成角色爆炸和混乱。 ABAC#ABAC是基于属性的权限验证控制，动态的计算一组属性从而判断当前用户是否有操作权限。属性可以分为用户属性(岗位)、环境属性(公司、家里、时间)、对象属性(对象的类型，比如服务器、楼宇等)、操作属性(启动、创建、读取等)。一组属性可以叫做一个策略，策略可以配置在用户实体上，也可以配置在组织架构上 ABAC的特点如下： 非常灵活，可以根据不同的维度、粒度进行权限管控 无需预置判定逻辑，可以根据需要随时调整，在经常变化的系统中可以很好的支持 策略配置复杂时，会给管理者和问题追查时带来困难 策略判定需要实时计算，会带来性能损耗 从策略上不能很直观的看到人和对象的关系 个人总结：ACL太复杂了，容易乱，操作起来级联严重RABC, 适合公司类型，组织架构、人员角色的权限固定管理。ABAC, 策略过于灵活，适合变化非常多的，策略复杂的","link":"/2021/08/13/design/ac/"},{"title":"如何实现延迟队列","text":"如何实现一个延迟队列？ (1) 数据库轮询#例如对于订单支付失效要求比较高的，每2S扫表一次检查过期的订单进行主动关单操作优点是简单缺点是每分钟全局扫表，浪费资源，如果遇到表数据订单量即将过期的订单量很大，会造成关单延迟 (2) JDK的延迟队列#一个无界阻塞队列，该队列只有在延迟期满的时候才能从中获取元素，放入DelayQueue中的对象，是必须实现Delayed接口的优点:效率高,任务触发时间延迟低。缺点:(1)服务器重启后，数据全部消失，怕宕机 (2)集群扩展相当麻烦 (3)因为内存条件限制的原因，比如下单未付款的订单数太多，那么很容易就出现OOM异常 (4)代码复杂度较高 (3) 时间轮算法# 时间轮算法可以类比于时钟，如上图箭头（指针）按某一个方向按固定频率轮动，每一次跳动称为一个 tick。这样可以看出定时轮由个3个重要的属性参数，ticksPerWheel（一轮的tick数），tickDuration（一个tick的持续时间）以及 timeUnit（时间单位），例如当ticksPerWheel=60，tickDuration=1，timeUnit=秒，这就和现实中的始终的秒针走动完全类似了。如果当前指针指在1上面，我有一个任务需要4秒以后执行，那么这个执行的线程回调或者消息将会被放在5上。那如果需要在20秒之后执行怎么办，由于这个环形结构槽数只到8，如果要20秒，指针需要多转2圈。位置是在2圈之后的5上面（20 % 8 + 1） 优点:效率高,任务触发时间延迟时间比delayQueue低，代码复杂度比delayQueue低。缺点: 服务器重启后，数据全部消失，怕宕机 集群扩展相当麻烦 因为内存条件限制的原因，比如下单未付款的订单数太多，那么很容易就出现OOM异常 (4) redis zset实现#利用redis的zset,zset是一个有序集合，每一个元素(member)都关联了一个score,通过score排序来取集合中的值。zset常用命令添加元素: ZADD key score member [[score member] [score member] …]按顺序查询元素: ZRANGE key start stop [WITHSCORES]查询元素score: ZSCORE key member移除元素: ZREM key member [member …] 我们将订单超时时间戳与订单号分别设置为score和member,系统扫描第一个元素判断是否超时（zrange key 0 0 [withscores] ） 存在一个致命的硬伤，在高并发条件下，多消费者会取到同一个订单号.解决方案:(1) 用分布式锁，但是用分布式锁，性能下降了，该方案不细说。(2) 对ZREM的返回值进行判断，只有大于0的时候 (删除成功)，才可消费数据 优点:(1) 由于使用Redis作为消息通道，消息都存储在Redis中。如果发送程序或者任务处理程序挂了，重启之后，还有重新处理数据的可能性。(2) 做集群扩展相当方便(3) 时间准确度高缺点:(1) 需要额外进行redis维护 (5)使用消息队列#我们可以采用rabbitMQ的延时队列。RabbitMQ具有以下两个特性，可以实现延迟队列 RabbitMQ可以针对Queue和Message设置 x-message-tt，来控制消息的生存时间，如果超时，则消息变为dead letterlRabbitMQ的Queue可以配置x-dead-letter-exchange 和x-dead-letter-routing-key（可选）两个参数，用来控制队列内出现了deadletter，则按照这两个参数重新路由。 优缺点优点: 高效,可以利用rabbitmq的分布式特性轻易的进行横向扩展,消息支持持久化增加了可靠性。缺点：本身的易用度要依赖于rabbitMq的运维.因为要引用rabbitMq,所以复杂度和成本变高","link":"/2021/08/21/design/delaymq/"},{"title":"分布式锁","text":"1、 基于MySQL的分布式锁实现原理：直接创建一张锁表，然后通过操作该表中的数据来实现了.。利用唯一索引的排他性来实现分布式锁，只有抢到锁的线程才能插入成功，释放锁删除该条记录即可 缺点：1、强依赖数据库的可用性，存在单点问题。2、数据库在高并发的场景下，性能上表现欠佳 2、基于Redis的分布式锁实现可以通过set nx的特性来实现分布式锁 3、基于Zookeeper的分布式锁实现可以利用临时有序节点的特性来实现分布式锁。原理：1、先建一个目录lock 2、线程A想获取锁就在lock目录下创建一个带顺序的临时节点 3、然后获取比当前顺序号小的顺序号，获取到则获取锁失败，获取不到则获取锁成功。 4、解锁则是删除这个临时节点。 临时节点是根据客户端维护的session会话来维持生命周期的，当客户端不在维护session时，或者说客户端断开连接时，session消失，那么临时节点就会消失，这种特性正好满足了分布式锁要有过期时间的需求，不会产生死锁问题 缺点：抗不了多少并发，内存无法横向扩展","link":"/2021/08/01/design/ds_lock/"},{"title":"幂等设计","text":"请求幂等性总结： 1.是否需要幂等。比如查询，insert含唯一索引的表，update set数据，delete by id 等简单场景是天然幂等。不需要额外做幂等操作。无法这样的比如要做数据的累加，就要做幂等。 2.如何判断重复。 业务唯一键，查记录表或流水表，根据记录的有无和状态来判断。 3.实现。 简单的话接口直接实现, 但通常幂等逻辑是有通用性的 如果服务多接口使用写幂等工具类 如果多服务使用一套幂等逻辑，写sdk 最复杂的多服务间幂等，还无法都获取到记录结果，就要在sdk统一读写幂等表，读写相同的幂等记录做幂等 4.并发处理 单机情况下，使用java锁synchronized 使用数据库锁，悲观锁：select for update，乐观锁：update set XXX and version = 2 where version = 1 使用分布式锁：redis锁：1.过期时间导致并发问题，2.主从切换时锁丢失zookeeper锁：写能力不如redis 原文： 维度1 : 是否需要幂等处理？ 查询场景 select 字段 from 表 where 条件 ，这种是不会对数据产生任何变化，所以查询场景具备天然幂等性；注意这里的幂等是对系统资源的改变，而不是返回数据的结果，即使返回结果不相同但是该操作本身没有副作用，所以幂等 新增场景 insert into 表 （order_id，字段） value（1，字段） ： 1）如果order_id为唯一键，重复操作上面的业务，只会插入一条数据，具备天然幂等性。 2）如order_id不是唯一键，那上面业务多次操作，数据都会新增多条，不具备幂等性。 修改场景 1）直接赋值场景：update 表 set price = 20 where id=1 ；分析： 这种场景不管执行多少次，price都一样，具备天然幂等性； 2）计算赋值场景：update 表 set price = price + 20 where id=1，每次操作price数据都不一样，不具备幂等性； 删除场景 1）delete from 表 where id=1 ，多次操作，结果一样，具备天然幂等性 2）delete from 表 where price &gt; 20,多次操作，结果一样，具备天然幂等性 总结：单纯的查询接口，删除接口，没有计算的更新接口，每次执行结果是天然幂等的，其他情况则可能需要做幂等 维度2 : 是否需要并发控制？ 场景1: 唯一键数据的重复插入 此场景不需要并发控制，天然并发安全，但需要业务方处理DuplicateKeyException异常 场景2：转账，若 a &gt;= 100, a -100， b+100 此场景为了保证数据一致性，事务原子性，需要顺序执行 总结：除了极其简单的场景外，大部分幂等场景都需要并发控制，需要强锁还是弱锁 维度3 : 如何判断是重复请求？ 场景1: 无业务主键的新增 此场景下需要服务端颁发token，通过token判断是否重复，做防重复提交 场景2: 有业务唯一键的新增 此场景下可以使用业务唯一键判断是否重复 场景3: 有业务唯一键的更新 此场景下可以使用业务数据对应的状态判断是否重复 维度4 : 重复请求处理方式？ 场景1：消息重复消费 此场景下，不需要给上游一个返回，重复执行只需要丢弃 场景2：前端重复提交 此场景下，需要给用户一个提示，那么重复请求可以直接抛出一个DuplicateReqeustException异常，由上层捕获，前端展示“请不要重复请求” 场景3: 底层的转账接口 此场景下，同一笔转账，重复调用第一次若成功了，第二次应该返回相同“成功”，若第一次失败了，第二次返回业务执行结果 结论：根据不同场景，应该有不同的结束方式，应该由业务方自己决定是丢弃，抛异常，直接返回，还是执行业务逻辑 维度5 : 重复请求返回是否相同？ 场景1：第一次执行成功，第二次返回应该与第一次相同 场景2：第一次执行因为代码原因导致的异常而失败，第二次返回应该与第一次相同 场景3：第一次执行因为网络原因失败，第二次应该执行业务逻辑，返回结果可能不一致 总结：根据第一次执行的成功和失败，判断第二次应该执行业务逻辑还是直接返回相同结果 维度6 : 重复请求调用下游如何处理？ 场景1: 业务逻辑中，有调用下游rpc接口，第一次执行失败，第二次重复执行业务逻辑再次调用下游接口 总结：此场景本质上是一个分布式一致性问题，需要业务方自己解决，或者保证下游接口也是幂等的 识别相同请求 token机制：每次提交上来的请求，都带上一个token标识，同一个token只处理一次，例如：新增场景的防止重复提交 业务唯一标识：使用id或者unique key，例如：支付后，支付凭证落库 业务唯一标识 + 状态：支付后，通过支付凭证号和当前订单状态，更新订单状态 在业务侧建立同库幂等数据表，记录请求唯一键和执行状态，执行成功后更新状态为成功 并发处理方式 单机情况下，使用java锁synchronized 使用数据库锁，悲观锁：select for update，乐观锁：update set XXX and version = 2 where version = 1 使用分布式锁： redis锁：1.过期时间导致并发问题，2.主从切换时锁丢失 zookeeper锁：写能力不如redis 一致性保证 业务方需保证原子性，本地更新都在一个事务里 若无法保证分布式事务，下游接口需是幂等的，且本地事务必须重试达到最终一致 SDK设计# 并发控制 提供注解，按业务自动划分，提供指定幂等唯一键 提供并发控制，分布式锁服务（redis或zk），指定分布式锁时间 提供并发时幂等处理方式，丢弃/抛异常/等待锁 提供降级选择，不强依赖于锁服务 提供token注解，防止重复提交 判断重复请求 处理方式 优点 缺点 方案一 业务方自己判断 业务方需要自己考虑判重 方案二 sdk提供判重接口，由业务方实现 可以实现重复请求的通用处理 方案三 幂等表：在业务侧建立同库幂等数据表，记录请求唯一键和执行状态，执行成功后更新状态为成功 业务方无需再关心判重问题 数据量大，开发量大，复杂度较高","link":"/2019/12/03/design/idemptent/"},{"title":"pcursor基于游标的分页","text":"一、基于偏移量分页&amp;基于游标分页 1.基于偏移量的分页 2.基于游标的分页 二、接口实现 三、底层实现 1. pcursor游标如何拼接 2.pcursor游标如何使用 3. 生成查询SQL 一、基于偏移量分页&amp;基于游标分页#1.基于偏移量的分页#适用于内容是静态的，或者不用实时返回数据最新的变化。特点：1.只要有新增或删除，就会有大量的数据偏移量的改变，造成重复展示或者漏展示。2.存在数据量大时的offset慢查询问题 2.基于游标的分页#适用于查询结果在用户浏览过程中是变化的。特点：1.时间线里出现新的数据或删除数据，这些变化都可以在 “前一页” 或者 “后一页” 体现出来。 2.没有offset问题 eg: 发现页 下拉获取最新，上拉获取更久 二、接口实现#请求参数 参数名 类型 逻辑 参数名 类型 逻辑 pcursor String 初始值传 “” , 后续值使用后端返回值 count Integer 本次想获取的数据量 响应信息 参数名 类型 逻辑 pcursor String 透传给下一页查询 调用方判断是否为 “no_more”, 若是则不再调用，否则永远停不下来了 三、底层实现#根据更新时间排序 排序规则：order by update_time desc, id desc 原因: 更新时间 + id 的排序, 可以为所有数据确定顺序，即使更新时间相同，即确定每条记录的游标，游标为更新时间+id，只要查询条件不变，即游标可在该顺序下唯一确定一个位置 1. pcursor游标如何拼接# 根据上面排序规则查询出数据 取最后一个数据last，即为该排序下此次查询的终止位置 根据last数据拼接成pcursorpcursor = encrypt ( (“updateTime”, long, 1589439219430); (“id”, long, 95424 ); ) 2.pcursor游标如何使用# pcursor解析为 上次查询last的 last.updateTime, last.id 本次查询where条件中，updateTime &lt; last.updateTime or (update_time = last.updateTime and id &lt; last.id) order by update_time desc, id desc;如下表格，为order by update_time desc, id desc，上次查询游标为last游标位置，则下次查询 updateTime &lt; 1555500001 or (updateTime = 1555500001 and id &lt; 32) order by update_time desc, id desc， 即为后三行数据 update_time id 1555500001 33 1555500001 32 last 游标位置 1555500001 31 1555500000 44 1555500000 42 3. 生成查询SQL#若查询条件为 userId, status, updateTime 则查询语句为 12345678910111213SELECT *FROM ad_xxx_infoWHERE user_id = xxx AND STATUS = xxx AND ( update_time &lt; xxx OR ( update_time = xxx AND id &lt; xxx ) )ORDER BY update_time DESC, id DESCLIMIT 20; 创建联合索引 (user_id, status, update_time) 查询即可全部走索引。注：主键也是索引的一部分，Extra为Using where。using where is fine https://stackoverflow.com/questions/9533841/mysql-fix-using-where","link":"/2020/08/13/design/pcursor/"},{"title":"报表设计学习","text":"es + clickhouse 搭配 总结#es适合做全文检索需求，ch适合做大数据分析需求，本需求使用ch建立es视图表兼容es的维表，将维表数据和事实表数据分开处理，使用时连表查询，充分利用了两种引擎的特性，既支持全文检索，也保证了查询性能 es &amp; clickhouse#clickhouse除了不能全文检索，其他方面完全超过es, 尤其是在事实表，这种日志类型不断增加的业务类型上，主要在查询性能，稳定性，磁盘使用率 上要比es优秀很多， 因为ch本身的一个列式存储，编码压缩，向量化执行等特性。而且ch支持sql语言。 我们这个业务实际没有导入ch，而是ch上建立了一个es的视图表，从ch层兼容了es。 账户维度数据使用es，便于这块数据的更新，因为ch在update原数据方面支持的不算很好，且es支持全文检索消耗事实数据使用ch，这部分量非常大，每个account每分钟一行, 且是纯insert, 适合ch处理。 es的存储特性，让他在全文检索的时候不能替代。","link":"/2021/08/13/design/report/"},{"title":"线上稳定性保障","text":"监控把各个环节的业务量级、成功失败原因、活动量级上报，这些数据是有因果关系的所以我们把这些数据汇总到大盘，提高问题定位的速度。 隔离区分业务，隔离餐团与买单业务，然后区分了环节，隔离查询与交易环节最终业务与业务隔离，交易与查询隔离，保障了系统的稳定性。 降级，首先是确认场景优先级，区分核心功能非核心功能，区分核心依赖非核心依赖 系统容量问题，优先降级非核心功能，限流查询链路 功能异常问题，按业务、场景类型进行降级，避免故障影响扩大 全链路压测需要定期进行全链路压测评估链路流量负载能力。压测前，会对压测流量进行ID偏移，防止污染线上，同步压测数据并进行状态改写。压测中读写分离，读线上数据，防止污染本地缓存，写影子表防止污染线上表。压测后扫描线上数据，确保无压测数据写到线上，然后清理压测数据。 总结：事前准备，主要做链路梳理，明确强弱依赖，然后进行性能评估，主要进行容量评估和负载评估，然后完善监控，明确因果建设大盘，最后准备降级预案，区分场景，区分优先级。事中快速响应，通过监控大盘定位问题，按预案进行扩容、限流、降级、熔断等操作。事后进行性能优化，问题修复并进行复盘总结。","link":"/2021/08/23/design/stable/"},{"title":"库存服务提性能","text":"提性能#读优化#多级缓存：让数据靠近计算链路优化：缩短耗时周期库存⽅案：提⾼周期库存查询性能 写优化#流量漏⽃：缓存预扣减少数据库的⽆效访问分库分表：提升数据库的整体写⼊能⼒( 窄表设计下单分片物理机可承载4500，云服务器可承载3000，仅供参考，具体以业务测试为准 )并⾏扣减：降低库存扣减的响应时间分库存：解决单行更新能力不足问题，（一般单行更新的QPS在500以内）合并请求：异步批量，将多次扣减累计计数，集中成一次扣减，从而实现了将串行处理变成了批处理。大大减轻更新压力。 当前峰值TPS超3000，年增⻓50%，未来5年期望⽀撑量级1万+；综合以上分8库，部署2个集群，每个集群4个库 1、如果某个sku_id的库存扣减过热，单台实例支撑不了（mysql官方测评：一般单行更新的QPS在500以内），可以考虑将一个sku的大库存拆分成N份，放在不同的库中（也就是说所有子库的库存数总和才是一件sku的真实库存），由于前台的访问流量非常大，按照均分原则，每个子库分到的流量应该差不多。上层路由时只需要在sku_id后面拼接一个范围内的随机数，即可找到对应的子库，有效减轻系统压力。 2、单条sku库存记录更新过热，也可以采用批量提交方式，将多次扣减累计计数，集中成一次扣减，从而实现了将串行处理变成了批处理，也可以大大减轻数据库压力。 3、引入RocketMQ消息队列，经过前置校验后，如果有剩余库存，则把创建订单的操作封装成消息发送给MQ，订单系统从RocketMQ中以特定的频率消费，创建订单，该方案有一定的延迟性。","link":"/2021/08/01/design/stock/"},{"title":"策略模式","text":"","link":"/2019/07/09/designpatterns/strategy/"},{"title":"git常用命令","text":"总结下git通常情况下会使用的命令。 重新编辑提交信息： 1git commit --amend 恢复工作现场到某个版本 1git reset --hard [HEAD^|commit版本号] git reset命令根据–-soft –-mixed –-hard三种参数的不同进行commit层级的回滚方式，默认是–mixed方式。 git reset –soft : 不会改变stage区，仅仅将commit回退到了指定的提交。 git reset –mixed : 不会改变工作区，但是会用指定的commit覆盖stage 区。 git reset –hard : 使用指定的commit的内容覆盖stage区和工作区。 git alias而当前用户的Git配置文件放在用户主目录下的一个隐藏文件.gitconfig中： 12345678910111213141516$ cat .gitconfig[alias] co = checkout ci = commit st = status pl = pull ps = push dt = difftool l = log --stat cp = cherry-pick ca = commit -a b = branch[user] name = Your Name email = your@email.com git revert git revert相当于HEAD继续前进，提交一次新的特殊的commit，内容是与前面普通commit文本变化的反操作。比如前面commit是增加一行，那么revert就是删除一行。 git revert (commit) ： 适用于非merge操作的普通commit。git revert操作可能会遇到冲突，可以通过git revert –abort终止此次revert操作，代码还原为revert命令前。 git revert (merge) : 适用于merge操作的commit，需要加上-m 参数，该参数表述merge编号，按commit日志标记为1，2。如下图所示，一个merge操作的日志，意思是当前分支是9fa8667加上686fabf。执行git revert -m 1表示撤销到9fa8667所代表的commit；git revert -2表示撤销到686fabf所代表的commit。执行命令如：git revert 1d8afa9632120bf1a7331e6b6cf38d86d761de96 -m 1 git stash可以在切换分支的时候使用，在合并代码的时候使用，减少commit提交，使log看起来整洁。 1234567891011121314git stash //存储未提交修改到缓存区git stash save \"work in progress for foo feature\"git stash pop //pop出最新的一次修改,pop之后这次修改消失git stash apply stash@{0} //应用第一个修改，但不删除'git stash list'命令可以查看你保存的'储藏'(stashes):git stash drop stash@{0} //删除git stash clear //清空 git pull = git fetch + git merge 123456789101112131415$ git fetch &lt;远程主机名&gt;要更新所有分支，命令可以简写为：$ git fetch上面命令将某个远程主机的更新，全部取回本地。默认情况下，git fetch取回所有分支的更新。如果只想取回特定分支的更新，可以指定分支名,如下所示 -$ git fetch &lt;远程主机名&gt; &lt;分支名&gt;比如，取回origin主机的master分支。$ git fetch origin master所取回的更新，在本地主机上要用”远程主机名/分支名”的形式读取。比如origin主机的master分支，就可以用origin/master读取。","link":"/2017/10/20/git/git_common/"},{"title":"流利阅读笔记","text":"英语流利阅读 - 第一天单词笔记 reshape urban areas 重塑城市地区 urban 城市的 displacing 迫使…离开常居地 segments 部分，段 real estate 不动产 gentrification 中产阶级化 fourfold adv 四倍的 eg a fourfold increase attain 得到 获得 telltale 能说明问题的 暴露实情的 owner-occupied 业主自己使用的 occupied 被使用的 已占用的 households led by single women 户主为单身女性的住户 workforce 劳动力 全体从业人员 spectrum 频谱 范围 a broad spectrum of interests brunt 主要压力 影响最大的部分 eg: bear the brunt of sth. 英语流利阅读 - 第二天单词笔记 millennial n. 千禧世代 warehouse 仓库，大型零售商店 ironic 讽刺的 in no way 无论怎么也不 Segment 分段，部分 cornerstone 基础，支柱 profite from 从..中获取 at first glance 乍看之下 glance 扫视，匆匆一看 austerity 紧缩，严格节制消费 conspicuously 显著地，明显地 out of favor 不受欢迎不喜欢 retail 零售 slacks 裤子，宽松长裤 high-end 高档的 be sensitive to .. 体谅，体察 sensitive 敏感的；感觉的 finances 财力，财源，财务管理 alive to 意识到 aspiration 强烈愿望，志向抱负","link":"/2019/04/09/english/liuli1/"},{"title":"presto简介、与hive比较","text":"最近在查询hive数据做展示的时候，读取hive数据，一开始使用hive查询，但速度非常慢，偶然发现可以使用presto引擎，速度相比hive要快上许多，这里进行一下比较和整理下大概原因。 一、 简介# 二、与hive比较# hive查询需要把数据先map， 按照查询条件为key， 取的字段为value，得到一条条数据，然后按key分类持久化到磁盘，然后再从磁盘读出来进行 count,sum，distinct等reduce操作，每一次map reduce都要写 读磁盘. 而且 将 sql分为多个语句，分的有先后顺序，需要等前面的 算完了，再进行下一步 presto的话，是纯内存的，不是mapreduce，但也是分解sql为多个任务，但是是并发进行，最后再串联，全程都是内存操作，所以很快。 实际执行效果如下图所示:","link":"/2018/03/29/hadoop/presto/"},{"title":"Hashmap源码解析-与hashtable区别","text":"HashMap是非线程安全的，HashTable是线程安全的。 系列目录# 总览&amp;目录 链表节点NODE 构造函数 扩容函数 put remove get 遍历 &amp;hashtable hashmap &amp; hashtable#（1）HashMap是非线程安全的，HashTable是线程安全的。 （2）因为线程安全、哈希效率的问题，HashMap效率比HashTable的要高 （3）HashMap的键和值都允许有null存在，而HashTable则都不行。 （4）HashMap的迭代器(Iterator)是fail-fast迭代器，而Hashtable的enumerator迭代器不是fail-fast的","link":"/2019/05/26/hashmap/&hashtable/"},{"title":"Hashmap源码解析-get","text":"get#查找过程和删除基本差不多， 找到返回节点，否则返回null 系列目录# 总览&amp;目录 链表节点NODE 构造函数 扩容函数 put remove get 遍历 &amp;hashtable 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public V get(Object key) { Node&lt;K,V&gt; e; //传入扰动后的哈希值 和 key 找到目标节点Node return (e = getNode(hash(key), key)) == null ? null : e.value;}//传入扰动后的哈希值 和 key 找到目标节点Nodefinal Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //查找过程和删除基本差不多， 找到返回节点，否则返回null if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) { if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null;}public boolean containsKey(Object key) { return getNode(hash(key), key) != null;}public boolean containsValue(Object value) { Node&lt;K,V&gt;[] tab; V v; //遍历哈希桶上的每一个链表 if ((tab = table) != null &amp;&amp; size &gt; 0) { for (int i = 0; i &lt; tab.length; ++i) { for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) { //如果找到value一致的返回true if ((v = e.value) == value || (value != null &amp;&amp; value.equals(v))) return true; } } } return false;}","link":"/2019/05/26/hashmap/get/"},{"title":"Hashmap源码解析-put","text":"源码解析-put函数 系列目录# 总览&amp;目录 链表节点NODE 构造函数 扩容函数 put remove get 遍历 &amp;hashtable #### put 1.构造函数后的hashmap都是空的，size=0,只有在第一次put的时候，才会调resize扩容 2.index = (n - 1) &amp; hash 实际是做了一个取模, 因为n是2的n次方, 所以n-1二进制都是1 3.if index节点为空，则new Node else 哈希冲突 ​ 如果节点哈希值相等，key也相等，则是覆盖value操作 ​ 如果节点是树, 红黑树先不深入，反正就是做了查找插入或替换 ​ 如果是链表小于8，就遍历，插入或替换，注插入后如果链表长度大于8了，还要做treeifyBin转换为红黑树操作 4.然后++modCount, if (++size &gt; threshold) resize(); 5.扰动函数 ​ hashcode散列值分布再松散，要是只取最后几位的话，碰撞也会很严重. ​ 右位移16位，正好是32bit的一半，自己的高半区和低半区做异或，就是为了混合原始哈希码的高位和低位，以此来加大低位的随机性。而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留下来。 ​ Peter Lawley的一篇专栏文章《An introduction to optimising a hashing strategy》里的的一个实验，实验证明：在没有扰动函数的情况下，发生了103次碰撞，接近30%。而在使用了扰动函数之后只有92次碰撞。碰撞减少了将近10%。看来扰动函数确实还是有功效的。 源码:#123456789101112131415public V put(K key, V value) { //先根据key，取得hash值。 再调用上一节的方法插入节点 return putVal(hash(key), key, value, false, true);}static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); // 扰动函数} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { //tab存放 当前的哈希桶， p用作临时链表节点 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果当前哈希表是空的，代表是初始化 if ((tab = table) == null || (n = tab.length) == 0) //那么直接去扩容哈希表，并且将扩容后的哈希桶长度赋值给n n = (tab = resize()).length; //如果当前index的节点是空的，表示没有发生哈希碰撞。 直接构建一个新节点Node，挂载在index处即可。 //这里再啰嗦一下，index 是利用 哈希值 &amp; 哈希桶的长度-1，替代模运算 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else {//否则 发生了哈希冲突。 //e Node&lt;K,V&gt; e; K k; //如果哈希值相等，key也相等，则是覆盖value操作 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p;//将当前节点引用赋值给e else if (p instanceof TreeNode)//红黑树暂且不谈 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else {//不是覆盖操作，则插入一个普通链表节点 //遍历链表 for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) {//遍历到尾部，追加新节点到尾部 p.next = newNode(hash, key, value, null); //如果追加节点后，链表数量》=8，则转化为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } //如果找到了要覆盖的节点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } //如果e不是null，说明有需要覆盖的节点， if (e != null) { // existing mapping for key //则覆盖节点值，并返回原oldValue V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; //这是一个空实现的函数，用作LinkedHashMap重写使用。 afterNodeAccess(e); return oldValue; } } //如果执行到了这里，说明插入了一个新的节点，所以会修改modCount，以及返回null。 //修改modCount ++modCount; //更新size，并判断是否需要扩容。 if (++size &gt; threshold) resize(); //这是一个空实现的函数，用作LinkedHashMap重写使用。 afterNodeInsertion(evict); return null;} putAll 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public void putAll(Map&lt;? extends K, ? extends V&gt; m) { //将另一个Map的所有元素加入表中，参数evict初始化时为false，其他情况为true putMapEntries(m, true);}//将另一个Map的所有元素加入表中，参数evict初始化时为false，其他情况为truefinal void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) { //拿到m的元素数量 int s = m.size(); //如果数量大于0 if (s &gt; 0) { //如果当前表是空的 if (table == null) { // pre-size //根据m的元素数量和当前表的加载因子，计算出阈值 float ft = ((float)s / loadFactor) + 1.0F; //修正阈值的边界 不能超过MAXIMUM_CAPACITY int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); //如果新的阈值大于当前阈值 if (t &gt; threshold) //返回一个 》=新的阈值的 满足2的n次方的阈值 threshold = tableSizeFor(t); } //如果当前元素表不是空的，但是 m的元素数量大于阈值，说明一定要扩容。 else if (s &gt; threshold) resize(); //遍历 m 依次将元素加入当前表中。 for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) { K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); } }}","link":"/2019/05/26/hashmap/put/"},{"title":"Hashmap源码解析-remove","text":"remove#1.找到待删除节点，也是分第一个节点就是，红黑树中找该节点，普通链表中找该节点 2.删除节点，分红黑树删除，头节点删除，中间节点删除(包括尾) 3.++modCount, –size 系列目录# 总览&amp;目录 链表节点NODE 构造函数 扩容函数 put remove get 遍历 &amp;hashtable REMOVE#1.找到待删除节点，也是分第一个节点就是，红黑树中找该节点，普通链表中找该节点 2.删除节点，分红黑树删除，头节点删除，中间节点删除(包括尾) 3.++modCount, –size 12345678910111213141516171819public V remove(Object key) { Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;}@Overridepublic boolean remove(Object key, Object value) { //这里传入了value 同时matchValue为true return removeNode(hash(key), key, value, true, true) != null;} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { // p 是待删除节点的前置节点 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; //如果哈希表不为空，则根据hash值算出的index下 有节点的话。 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) { //node是待删除节点 Node&lt;K,V&gt; node = null, e; K k; V v; //如果链表头的就是需要删除的节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p;//将待删除节点引用赋给node else if ((e = p.next) != null) {//否则循环遍历 找到待删除节点，赋值给node if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else { do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { node = e; break; } p = e; } while ((e = e.next) != null); } } //如果有待删除节点node， 且 matchValue为false，或者值也相等 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) { if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p)//如果node == p，说明是链表头是待删除节点 tab[index] = node.next; else//否则待删除节点在表中间 p.next = node.next; ++modCount;//修改modCount --size;//修改size afterNodeRemoval(node);//LinkedHashMap回调函数 return node; } } return null;}","link":"/2019/05/26/hashmap/remove/"},{"title":"Hashmap源码解析-总览&目录","text":"HashMap：#它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。 HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。 结构: 数组 + 链表, 链表长度达到8转化成红黑树 扩容: hashMap的容量达到threshold会触发扩容。扩容前后，哈希桶的长度一定会是2的次方, 这样在根据key的hash值寻找对应的哈希桶时，可以用位运算替代取余操作，更加高效。 系列目录# 总览&amp;目录 链表节点NODE 构造函数 扩容函数 put remove get 遍历 &amp;hashtable ### hashmap原理、是否线程安全 HashMap 它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。 HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。 结构: 数组 + 链表, 链表长度达到8转化成红黑树 扩容: hashMap的容量达到threshold会触发扩容。扩容前后，哈希桶的长度一定会是2的次方, 这样在根据key的hash值寻找对应的哈希桶时，可以用位运算替代取余操作，更加高效。 其它特点 遍历时无序 实现 Map&lt;K,V&gt;, Cloneable, Serializable 接口 是否线程安全: 非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。 源码解析#Hashmap 链表节点NODE 构造函数 扩容函数 put remove get 遍历 &amp;hashtable 其它map#Hashtable：Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable,get方法也是同步的，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。 LinkedHashMap：LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。 TreeMap：TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。 ConcurrentHashmap: 线程安全, java7使用分段锁, java8使用cas, 取消segments字段, 待学习","link":"/2019/05/26/hashmap/总结目录/"},{"title":"Hashmap源码解析-扩容函数","text":"系列目录# 总览&amp;目录 链表节点NODE 构造函数 扩容函数 put remove get 遍历 &amp;hashtable 扩容函数#1.更新容量和阈值, ​ if cap&gt;0, 不超过上限的情况下cap、thre都乘2 ​ if cap=0, oldThr&gt;0, 说明初始化的时候赋初始容量参数了，newCap=oldThr ​ if cap=0, oldthr=0, 直接重新初始化,cap=16,thre=12 2.更新哈希桶, 遍历原桶 ​ if 只有一个节点，直接挪过去 ​ if 链表有超过8个节点，是红黑树, 复杂, 再说todo ​ if 少于8个的链表，则可能挪到低位，也可能挪到高位，看它本身hash在新容量时应在哪里，代码中巧妙通过与oldCap &amp; 的方式判断需改到高还是低，具体在代码注释中有 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237final Node&lt;K,V&gt;[] resize() { //oldTab 为当前表的哈希桶 Node&lt;K,V&gt;[] oldTab = table; //当前哈希桶的容量 length int oldCap = (oldTab == null) ? 0 : oldTab.length; //当前的阈值 int oldThr = threshold; //初始化新的容量和阈值为0 int newCap, newThr = 0; //如果当前容量大于0 if (oldCap &gt; 0) { //如果当前容量已经到达上限 if (oldCap &gt;= MAXIMUM_CAPACITY) { //则设置阈值是2的31次方-1 threshold = Integer.MAX_VALUE; //同时返回当前的哈希桶，不再扩容 return oldTab; }//否则新的容量为旧的容量的两倍。 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) //如果旧的容量大于等于默认初始容量16 //那么新的阈值也等于旧的阈值的两倍 newThr = oldThr &lt;&lt; 1; // double threshold }//如果当前表是空的，但是有阈值。代表是初始化时指定了容量、阈值的情况 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr;//那么新表的容量就等于旧的阈值 else { //如果当前表是空的，而且也没有阈值。代表是初始化时没有任何容量/阈值参数的情况 // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY;//此时新表的容量为默认的容量 16 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);//新的阈值为默认容量16 * 默认加载因子0.75f = 12 } if (newThr == 0) {//如果新的阈值是0，对应的是 当前表是空的，但是有阈值的情况 float ft = (float)newCap * loadFactor;//根据新表容量 和 加载因子 求出新的阈值 //进行越界修复 newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } //更新阈值 threshold = newThr; @SuppressWarnings({\"rawtypes\",\"unchecked\"}) //根据新的容量 构建新的哈希桶 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; //更新哈希桶引用 table = newTab; //如果以前的哈希桶中有元素 //下面开始将当前哈希桶中的所有节点转移到新的哈希桶中 if (oldTab != null) { //遍历老的哈希桶 for (int j = 0; j &lt; oldCap; ++j) { //取出当前的节点 e Node&lt;K,V&gt; e; //如果当前桶中有元素,则将链表赋值给e if ((e = oldTab[j]) != null) { //将原哈希桶置空以便GC oldTab[j] = null; //如果当前链表中就一个元素，（没有发生哈希碰撞） if (e.next == null) //直接将这个元素放置在新的哈希桶里。 //注意这里取下标 是用 哈希值 与 桶的长度-1 。 由于桶的长度是2的n次方，这么做其实是等于 一个模运算。但是效率更高 newTab[e.hash &amp; (newCap - 1)] = e; //如果发生过哈希碰撞 ,而且是节点数超过8个，转化成了红黑树（暂且不谈 避免过于复杂， 后续专门研究一下红黑树） else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //如果发生过哈希碰撞，节点数小于8个。则要根据链表上每个节点的哈希值，依次放入新哈希桶对应下标位置。 else { // preserve order //因为扩容是容量翻倍，所以原链表上的每个节点，现在可能存放在原来的下标，即low位， 或者扩容后的下标，即high位。 high位= low位+原哈希桶容量 //低位链表的头结点、尾节点 Node&lt;K,V&gt; loHead = null, loTail = null; //高位链表的头节点、尾节点 Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next;//临时节点 存放e的下一个节点 do { next = e.next; // 此处操作跟hash计算索引有关 // 在 HashMap 中,索引的计算方法为 (n - 1) &amp; hash // 所以,在进行扩容操作 (n*2) 后,该计算结果可能导致变更 // 例如 // 有一个值为 111001 的 hash // 扩容前 n=16(10000) n-1=15(1111) (n - 1) &amp; hash = 1111 &amp; 111001= 001001 // 扩容后 n=32(100000) n-1=31(11111) (n - 1) &amp; hash = 11111 &amp; 111001= 011001 // 假如 hash 值为 101001 // 那么会发现扩容前 1111 &amp; 101001 = 001001 // 扩容后 11111 &amp; 101001 = 001001 // 所以可知,在进行扩容操作时,主要按照 hash 与 原数组长度中1的对应位置有关 // 如果 hash 中对应的位置为0,扩容后索引结果不变 // 不为0,表示索引结果为原结果+原数组长度 // 而 hash 中该对应位置的值只存在俩种可能 0,1 // 所以在该节点中的数据大约有一半索引不变,一半为原索引+原数组长度 // 通过 e.hash &amp; oldCap 的方式可以得知 hash 在 oldCap 1对应的位置是否为0或1 if ((e.hash &amp; oldCap) == 0) { //给头尾节点指针赋值 if (loTail == null) loHead = e; else loTail.next = e; loTail = e; }//高位也是相同的逻辑 else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; }//循环直到链表结束 } while ((e = next) != null); //将低位链表存放在原index处， if (loTail != null) { loTail.next = null; newTab[j] = loHead; } //将高位链表存放在新index处 if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab;}","link":"/2019/05/26/hashmap/扩容函数/"},{"title":"Hashmap源码解析-构造函数","text":"系列目录# 总览&amp;目录 链表节点NODE 构造函数 扩容函数 put remove get 遍历 &amp;hashtable 构造函数#构造函数: 默认构造函数什么都不做，只是将加载因子设为默认加载因子。 有初始值大小的构造函数， ​ 会将threshold设置为大于输入参数且最近的2的整数次幂的数,比如10，设置阈值16. ​ 即使有initialCapacity参数的构造，也是设置threshold，不会现在设置cap，如要设置cap就需要new资源了，而原理是在等真的插入的时候才去通过resize操作申请内存资源, 见resize.md,put.md 重点: 1.参数最大容量,默认的加载因子,加载因子,阈值 2.哈希桶, Node&lt;K,V&gt;[] table, 是Node数组, 存放链表, 长度初始化时为0, 之后是2的N次方 3.loadFactor和threshold的关系 4.tableSizeFor函数的原理, 见下面解析 默认参数和构造函数源码: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879//最大容量 2的30次方static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//默认的加载因子static final float DEFAULT_LOAD_FACTOR = 0.75f;//哈希桶，存放链表。 长度是2的N次方，或者初始化时为0.transient Node&lt;K,V&gt;[] table;//加载因子，用于计算哈希表元素数量的阈值。 threshold = 哈希桶.length * loadFactor;final float loadFactor;//哈希表内元素数量的阈值，当哈希表内元素数量超过阈值时，会发生扩容resize()。int threshold;public HashMap() { //默认构造函数，赋值加载因子为默认的0.75f this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted}public HashMap(int initialCapacity) { //指定初始化容量的构造函数 this(initialCapacity, DEFAULT_LOAD_FACTOR);}//同时指定初始化容量 以及 加载因子， 用的很少，一般不会修改loadFactorpublic HashMap(int initialCapacity, float loadFactor) { //边界处理 if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); //初始容量最大不能超过2的30次方 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //显然加载因子不能为负数 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; //设置阈值为 &gt;= 初始化容量的最近的2的n次方的值 this.threshold = tableSizeFor(initialCapacity);}//新建一个哈希表，同时将另一个map m 里的所有元素加入表中public HashMap(Map&lt;? extends K, ? extends V&gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);} tableSizeFor函数的原理#tableSizeFor的功能（不考虑大于最大容量的情况）是返回大于输入参数且最近的2的整数次幂的数。比如10，则返回16. 1234567891011121314151617static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;} 先来分析有关n位操作部分：先来假设n的二进制为01xxx…xxx。接着 对n右移1位：001xx…xxx，再位或：011xx…xxx 对n右移2为：00011…xxx，再位或：01111…xxx 此时前面已经有四个1了，再右移4位且位或可得8个1 同理，有8个1，右移8位肯定会让后八位也为1。 综上可得，该算法让最高位的1后面的位全变为1。 最后再让结果n+1，即得到了2的整数次幂的值了。 现在回来看看第一条语句： 1int n = cap - 1; 让cap-1再赋值给n的目的是另找到的目标值大于或等于原值。例如二进制1000，十进制数值为8。如果不对它减1而直接操作，将得到答案10000，即16。显然不是结果。减1后二进制为111，再进行操作则会得到原来的数值1000，即8。 loadFactor和threshold的关系?#HashMap中size表示当前共有多少个KV对，capacity表示当前HashMap的容量是多少，默认值是16，每次扩容都是成倍的。loadFactor是装载因子，当Map中元素个数超过loadFactor* capacity的值时，会触发扩容。loadFactor* capacity可以用threshold表示。 好多地方都说threshold = loadFactor * capacity, 但有初始值的初始化的时候，threadshold由tableSizeFor函数获得，这个地方之后 threshold 是什么时间进行的调整，应该是之后调整是根据loadFactor* capacity。","link":"/2019/05/26/hashmap/构造函数/"},{"title":"Hashmap源码解析-链表节点NODE","text":"系列目录# 总览&amp;目录 链表节点NODE 构造函数 扩容函数 put remove get 遍历 &amp;hashtable 链表节点NODE#重点: 1.单链表 2.hashCode()是将key的hashCode和value的hashCode异或得到 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; //哈希值 final K key; //key V value; //value Node&lt;K,V&gt; next; //链表后置节点 Node(int hash, K key, V value, Node&lt;K,V&gt; next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + \"=\" + value; } //每一个节点的hash值，是将key的hashCode 和 value的hashCode 亦或得到的。 public final int hashCode() { return Objects.hashCode(key) ^ Objects.hashCode(value); } //设置新的value 同时返回旧value public final V setValue(V newValue) { V oldValue = value; value = newValue; return oldValue; } public final boolean equals(Object o) { if (o == this) return true; if (o instanceof Map.Entry) { Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; } return false; }}","link":"/2019/05/26/hashmap/链表节点NODE/"},{"title":"Hashmap源码解析-遍历","text":"系列目录# 总览&amp;目录 链表节点NODE 构造函数 扩容函数 put remove get 遍历 &amp;hashtable 遍历#1.Node implements Map.Entry 2.EntryIterator extends HashIterator implements Iterator&lt;Map.Entry&lt;K,V&gt;&gt; 3.迭代器HashIterator实现 expectedModCount = modCount 支持fastfail 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869//缓存 entrySettransient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; */public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() { Set&lt;Map.Entry&lt;K,V&gt;&gt; es; return (es = entrySet) == null ? (entrySet = new EntrySet()) : es;}final class EntrySet extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt; { public final int size() { return size; } public final void clear() { HashMap.this.clear(); } //一般我们用到EntrySet，都是为了获取iterator public final Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() { return new EntryIterator(); } //最终还是调用getNode方法 public final boolean contains(Object o) { if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Node&lt;K,V&gt; candidate = getNode(hash(key), key); return candidate != null &amp;&amp; candidate.equals(e); } //最终还是调用removeNode方法 public final boolean remove(Object o) { if (o instanceof Map.Entry) { Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Object value = e.getValue(); return removeNode(hash(key), key, value, true, true) != null; } return false; } //。。。} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103final class EntryIterator extends HashIterator implements Iterator&lt;Map.Entry&lt;K,V&gt;&gt; { public final Map.Entry&lt;K,V&gt; next() { return nextNode(); }}abstract class HashIterator { Node&lt;K,V&gt; next; // next entry to return Node&lt;K,V&gt; current; // current entry int expectedModCount; // for fast-fail int index; // current slot HashIterator() { //因为hashmap也是线程不安全的，所以要保存modCount。用于fail-fast策略 expectedModCount = modCount; Node&lt;K,V&gt;[] t = table; current = next = null; index = 0; //next 初始时，指向 哈希桶上第一个不为null的链表头 if (t != null &amp;&amp; size &gt; 0) { // advance to first entry do {} while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); } } public final boolean hasNext() { return next != null; } //由这个方法可以看出，遍历HashMap时，顺序是按照哈希桶从低到高，链表从前往后，依次遍历的。属于无序集合。 final Node&lt;K,V&gt; nextNode() { Node&lt;K,V&gt;[] t; Node&lt;K,V&gt; e = next; //fail-fast策略 if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (e == null) throw new NoSuchElementException(); //依次取链表下一个节点， if ((next = (current = e).next) == null &amp;&amp; (t = table) != null) { //如果当前链表节点遍历完了，则取哈希桶下一个不为null的链表头 do {} while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); } return e; } public final void remove() { Node&lt;K,V&gt; p = current; if (p == null) throw new IllegalStateException(); ////fail-fast策略 if (modCount != expectedModCount) throw new ConcurrentModificationException(); current = null; K key = p.key; //最终还是利用removeNode 删除节点 removeNode(hash(key), key, null, false, false); expectedModCount = modCount; }}","link":"/2019/05/26/hashmap/遍历/"},{"title":"系统设计","text":"- 高并发系统提性能 - 请求幂等性 - 分布式锁 - 分布式主键生成方案选择 - 如何实现延迟队列 - 高并发系统的稳定性保证 - 双写服务迁移 - 领域划分 - 高并发系统提性能#读优化多级缓存：让数据靠近计算链路优化：合并batch请求缩短整体耗时 写优化流量漏⽃：缓存预扣减少数据库的⽆效访问分库分表：提升数据库的整体写⼊能⼒( 窄表设计下单分片物理机可承载4500，云服务器可承载3000，仅供参考，具体以业务测试为准 )并⾏扣减：降低库存扣减的响应时间分库存：解决单行更新能力不足问题，（一般单行更新的QPS在500以内）合并请求：异步批量，将多次扣减累计计数，集中成一次扣减，从而实现了将串行处理变成了批处理。大大减轻更新压力。 扩展 如果某个sku_id的库存扣减过热，单台实例支撑不了（mysql官方测评：一般单行更新的QPS在500以内），可以考虑将一个sku的大库存拆分成N份，放在不同的库中（也就是说所有子库的库存数总和才是一件sku的真实库存），由于前台的访问流量非常大，按照均分原则，每个子库分到的流量应该差不多。上层路由时只需要在sku_id后面拼接一个范围内的随机数，即可找到对应的子库，有效减轻系统压力。 单条sku库存记录更新过热，也可以采用批量提交方式，将多次扣减累计计数，集中成一次扣减，从而实现了将串行处理变成了批处理，也可以大大减轻数据库压力。 引入RocketMQ消息队列，经过前置校验后，如果有剩余库存，则把创建订单的操作封装成消息发送给MQ，订单系统从RocketMQ中以特定的频率消费，创建订单，该方案有一定的延迟性。 - 请求幂等性#请求幂等性总结：1.是否需要幂等。比如查询，insert含唯一索引的表，update set数据，delete by id 等简单场景是天然幂等。不需要额外做幂等操作。无法这样的比如要做数据的累加，就要做幂等。2.如何判断重复。业务唯一键，查记录表或流水表，根据记录的有无和状态来判断。3.实现。 简单的话接口直接实现, 但通常幂等逻辑是有通用性的 如果服务多接口使用写幂等工具类 如果多服务使用一套幂等逻辑，写sdk 最复杂的多服务间幂等，还无法都获取到记录结果，就要在sdk统一读写幂等表，读写相同的幂等记录做幂等 并发处理 单机情况下，使用java锁synchronized 使用数据库锁，悲观锁：select for update，乐观锁：update set XXX and version = 2 where version = 1 使用分布式锁：redis锁：1.过期时间导致并发问题，2.主从切换时锁丢失zookeeper锁：写能力不如redis 幂等设计 - 分布式锁#方案1、基于数据库唯一主键原理：在数据库中创建一个表，表中包含方法名等字段，并在方法名字段上创建唯一索引，想要执行某个方法，就使用这个方法名向表中插入数据，成功插入则获取锁，执行完成后删除对应的行数据释放锁。 方案2、基于redis实现分布式锁原理：通过redis 中的命信setNx 来实现 （当key不存在则设置值并返回true，否则返回失败） 方案3、基于Zookeeper来实现分布式锁原理：1、先建一个目录lock 2、线程A想获取锁就在lock目录下创建一个带顺序的临时节点 3、然后获取比当前顺序号小的顺序号，获取到则获取锁失败，获取不到则获取锁成功。 4、解锁则是删除这个临时节点。 - 分布式主键生成方案选择#分布式自增ID的实现 1.uuid组成部分：当前日期和时间、时钟序列、机器识别码 缺点：UUID长度128bit，32个16进制字符，占用存储空间多，且生成的ID是无序的 对于InnoDB这种聚集主键类型的引擎来说，数据会按照主键进行排序，由于UUID的无序性，InnoDB会产生巨大的IO压力，此时不适合使用UUID做物理主键。 2.号段模式，底层proxy服务+数据库分段获取id结合数据库维护一个Sequence表，每当需要为某个表的新纪录生成ID时就从Sequence表中取出对应的nextid,将其+1后更新到数据库中以备下次使用。 缺点：由于所有的插入都要访问该表，很容易造成性能瓶颈。在高并发场景下，无法保证高性能。 3.Snowflake使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID），最后还有一个符号位，永远是0。 长度为64bit，占用存储空间多存在时钟回拨问题， leaf已解决 - 如何实现延迟队列#delaymq - 高并发系统的稳定性保证#限流，单机限流动态扩容，集群限流保护存储隔离，业务与业务隔离，避免多业务之间互相影响。读写服务隔离，关注点不一样。环节隔离，查询和交易环节在流量和响应时间上有很大差异（api, order）。监控，业务量级、成功失败原因、活动量级上报，尤其是失败原因。降级 非核心功能，容量问题，非核心功能。比如压力过大，先限流降级查询功能，减少入口流量，避免雪崩。 非核心依赖，功能异常问题，熔断降级。eg: 直播视频制作，依赖算法，mmu，ytech，音视频，区分非核心依赖：mmu，ytech，即可做区别降级处理。发第三方券。全链路压测定期进行全链路压测评估链路流量负载能力总结事前：链路梳理，明确强弱依赖 性能评估，容量评估，负载评估 完善监控，明确因果，建设大盘 降级预案，区分场景，区分等级事中：扩容、限流、降级、熔断事后：性能优化，问题修复，复盘总结 redis监控：读写qps，内存使用率，响应耗时，缓存命中率，慢查询，大keykafka监控：消费延迟量，消费失败数量，生产&amp;消费速率 - 双写服务迁移# 迁移模式：老服务代理新服务完成内部迁移，再推业务方做sdk迁移 双写操作：以谁为主，就同步写为主一侧，异步写另一侧，减少耗时 路由策略查询以灰度为准，下单以灰度为准 退款、回滚固定以下单为准。防止一单交易不同环节分别走到新老，新老数据可能不一致。 退款回滚时，请求新老流水，根据流水路由信息，判断退款路由策略 实时响应比对：双写完, 整合两侧结果上报mq, 消费mq做结果比对，打点，告警，问题及时发现 离线数据最终一致校正：离线任务跑新老流水，判断以谁为主，以谁为主就用谁的流水校正另一侧的流水 - 领域划分#营销平台领域划分业务领域：触达，感知，转化，留存。工具域：立减，拼团，积分，优惠券基础域：选品，选人，规则，库存，预算 基建平台领域划分前台: 代理商平台、crm平台、财务平台业务编排：代理商引入、广告主引入、转账充值基础域：客户域、财务域、报表分析域、销售管理域支撑域：upm、计费、dsi、passport、审核 直播剪辑的整体流程近实时、配置化、异步制作 自动剪辑配置，开启时段，剪辑时长，字幕，配乐，片头片尾 自动剪辑，定时任务时间驱动，每10min, 异步制作定时任务 -&gt; mq异步 （ 算法视频切片 -&gt; mmu语音转文字 -&gt; ytech视频特效 ）-&gt; mq复用 ( 音视频片头片尾）注：mmu、ytech、音视频可降级。","link":"/2021/07/29/interview/design/"},{"title":"分布式事务","text":"分布式事务#分布式事务，主要为了实现分布式系统下一组操作的全部成功或全部失败，主要分为数据库层的和业务层的分布式事务， 一、数据库层的主要是基于XA协议的分布式事务，实现的强一致性，基于XA模型，主要有全局的事务管理器和本地资源管理器，事务管理器会调度本地资源管理器的本地事务的提交和回滚，达到全局的强一致性 二、业务层的，基于CAP和BASE理论，实现的最终一致性，来支持的分布式事务，主要有tcc模型的补偿性事务，tcc模型主要将操作分为三个，try, confirm, cancel, try会预留该事务的资源，即使当前事务出问题，也不会影响其它事务，支持高并发， 当一组服务的try都成功，tcc会保证所有服务的confirm最终成功，如果一组服务中有try失败，tcc会保证所有的服务最终cancel成功。 事务#核心：修改多个数据时，保证对多个数据操作的一致性 如何保证一致性: 两阶段 让失败的部分操作 全部成功 ( x ) 让成功的部分操作 全部回退 ( √ ) 事务一致性的基本要求#在提交之前，要保证所有的操作都可以回滚条件： 对每个操作，要知道如何回滚 为保证能正确回滚，需要控制事务的并发 在并发场景下，不能让两条rollback之间相互影响（可以是阻塞等待，也可以是抛出异常、返回失败。只要能避免事务往不一致的方向发展就好。） tcc的一致性保证#cancel/confirm 失败怎么办？– 重试到成功为止如何重试？ – 事务协调器 tc tc#TC 是一个独立的服务，用于协调分布式事务内的多个操作一起提交或者回滚。存储了事务执行的中间状态 rocketMq事务#先执行 DB 操作，再发消息，难以保证消息一定发出去。 RocketMQ 就反过来，先发一个半消息（Half Msg，类似一个 Prepare 操作），这个半消息是不会投递给消费者的，半消息发送成功再执行 DB 操作，DB 操作成功以后，提交半消息，这个时候半消息就变成一个普通消息送到消费者那里。 对于 RocketMQ 消费者而言，事务消息和非事务消息是没有区别的。 第 1 步发生异常，半消息发送失败，那么本地 DB 事务根本就不会执行，整个操作失败了，但是 DB/消息的状态是一致的（都没有提交）。 第 2 步发生异常，或者返回超时，生产者以为失败了，因此 DB 操作不会执行，也就没有后续了。另一边 Broker 存储半消息成功了,却迟迟等不到后续的提交操作，等了好久（超时）以后，Broker 就会跑来问生产者（回查，也就是第 4 步），这个半消息到底是要提交还是回滚？此时生产者去数据库中确认本地 DB 事务的完成状态（第 6 步），给 Broker 一个回答（第 7 步），然后 Broker 就知道要怎么办。 第 3 步 DB 操作失败，生产者可在第 4 步，告知 Broker 回滚半消息。另外生产者也可以报告状态为”未知”，然后由 Broker 稍后触发回查来决定提交还是回滚半消息。 第 4 步提交/回滚半消息失败，Broker 等不到这个操作，会在一段时间以后触发回查，与上面的第 2 步异常类似。 第 5、6、7 步回查失败，如果回查发生异常或者回查仍然返回”未知”，或回查失败，RocketMQ 稍后会重新调度，最多会回查 15 次 tcc和rocketMq事务的比较#tcc优势 rpc事务，将多个rpc组合在一起 tcc可以无限去加更多的操作来判断整体的提交或回滚。事务中的操作有3个及以上，要根据其中的结果判断是否要回滚其中的前两个，这种rocketmq就无法去做。（rocketmq 比较被动，当本地事务提交了，后面的一定要提交，缺少判断多个操作的结果来判断整体是否提交的能力） rocket mq的异步消息在逻辑上一定是成功的，但tcc的其他操作也可以是失败的可以参与到整体成功与否的判断的。如果rocket mq中的异步操作不一定会成功不能使用rocket mq","link":"/2021/07/29/interview/dt/"},{"title":"java","text":"- 常见Java集合类 - ArrayList 和 LinkedList的区别 - 项目中用到过哪些数据结构 - BIO、NIO、AIO 的区別和联系 - 谈谈对Java NIO的了解 - select epoll - 谈谈对hashMap的了解 - loadFactor和threshold的关系? ### - 常见Java集合类 非线程安全ArrayList: 底层数组LinkedList: 底层双向链表HashMap: (重要必考) 数组加链表，链表长度 到 8 转化为红黑树 - ArrayList 和 LinkedList的区别# 数据结构 数组 / 双向链表 是否支持快速随机访问 随机插入删除速度, ArrayList需要整体位移 - 项目中用到过哪些数据结构#queue, map, set, list, 堆（priorityQueue） - BIO、NIO、AIO 的区別和联系#BIO：同步、阻塞。服务器实现模式为一个连接一个线程,服务器端为每一个客户端的连接请求都需要启动一个线程进行处理 NIO：多路复用技术，同步非阻塞。服务器实现模式为客户端的连接请求都会注册到多路复用器上,用同一个线程接收所有连接请求 AIO：异步非阻塞IO BIO里用户最关心“我要读”，NIO里用户最关心”我可以读了”，在AIO模型里用户更需要关注的是“读完了” - 谈谈对Java NIO的了解#NIO（Non-blocking I/O，在Java领域，也称为New I/O），是一种同步非阻塞的I/O模型，也是I/O多路复用的基础，已经成为解决高并发与大量连接、I/O处理问题的有效方式。传统的BIO模型严重依赖于线程。但线程是很”贵”的资源。创建和销毁成本很高，本身占用较大内存，切换成本是很高。 NIO由原来占用线程的阻塞读写变成了单线程轮询事件，找到可以进行读写的网络描述符进行读写。大大地节约了线程，为处理海量连接提供了可能NIO的主要事件有几个：读就绪、写就绪、有新连接到来。 首先需要注册当这几个事件到来对应的处理器。然后在合适的时机告诉事件选择器；其次，用一个死循环选择就绪的事件，会执行系统调用（Linux 2.6之前是select、poll（轮询），2.6之后是epoll（通知）） 总结NIO带来了什么： 事件驱动模型 避免多线程 单线程处理多任务 非阻塞I/O，I/O读写不再阻塞 基于block的传输，通常比基于流的传输更高效(buffer) 更高级的IO函数，zero-copy IO多路复用大大提高了Java网络应用的可伸缩性和实用性 JavaNIO使用channel、buffer传输，更高效 白话：nio 的核心在selector，相比于BIO一连接一线程，nio 一线程可以监听多个网络连接的文件描述符，监听处理其中的事件。这样很好的节省了线程资源，会增加服务端的并发能力和吞吐。 - select epoll#select 是轮询所有的文件描述符epoll 是走回调，能支持的数量更多，效率更高 - 谈谈对hashMap的了解#基本：底层数据结构, 数组 + 链表，长度到8变为红黑树，非线程安全注1：HashMap在put时, 经过了两次hash，一个是JDK自带的对对象key的hash，一个是内部扰动函数hash，做高16位与低16位异或，加大散列的效果注2：HashMap 的长度为什么是2的幂次方。1. 散列值用之前要对数组长度取模，求桶位(n - 1) &amp; hash 更高效；2. 扩容的时候也可以用 hash值与扩容后的最高位 &amp; 判断节点是在高位还是低位，更高效。注3：HashMap 非线程安全，多线程操作导致死循环问题，1.7 并发下头插形成循环链表，1.8 用尾插修复， 但仍可能造成丢失数据。 HashMap.Node&lt;K, V&gt;[] table; get是怎么做的 hash。 hashcode高低16位异或得到hash值， (h = key.hashCode()) ^ h &gt;&gt;&gt; 16 根据hash值拿到桶位第一个节点，判断是否可以直接返回 判断节点中结构类型是树还是链表，树则调用树查询方法，链表则遍历链表比较 put是怎么做的 hash。 hashcode高低16位异或得到hash值， (h = key.hashCode()) ^ h &gt;&gt;&gt; 16 根据hash值拿第一个桶位的节点，如果为空则新建节点插入 判断节点结构是树还是链表，树则调用树插入的方法, 链表则添加到表尾，如果链表节点到了8个，则触发treeifyBin() ！如果整体节点数量 &gt; threshold, 则resize() resize是怎么做的 new HashMap.Node[newCap]，遍历每一个桶位 如果只有一个节点直接赋到新桶位，新桶位计算方式：e.hash &amp; newCap - 1 如果节点数据结构为树，则走树的split() 如果节点数据结构为链表，遍历链表，判断属于新桶还是老桶，通过：e.hash &amp; oldCap(2^n), 通过最高位的0，1值 白话：hashmap是非线程安全的集合。底层是数组+链表，链表长度到8会转成红黑树。hashmap中table的长度总是2的幂次方，这样可以使用&amp;运算代替取余运算(%)来提高效率，在求桶位和扩容时获取节点新位置在左边还是右边的时候。 - loadFactor和threshold的关系?#size: 当前共有多少个KV对capacity: 当前HashMap的容量是多少, 桶位数, table大小, 默认是16loadFactor: 负载因子，默认0.75threshold: loadFactor* capacity， 白话：负载因子就是控制碰撞几率的，调的小，碰撞的概率小，调的大，碰的概率就大。阈值就是扩容时机。阈值等于负载因子乘以table大小","link":"/2021/07/29/interview/java/"},{"title":"其他","text":"- tcp如何保证可靠传输，tcp、udp区别 - 为什么要三次握手，四次挥手 - 四次挥手的closewait, timewait分别在哪，为什么timewait要等待2msl - 设计模式六大原则 - 线上需要关注哪些机器参数 - 有哪些处理线上问题的经验 - tcp如何保证可靠传输，tcp、udp区别#tcp与udp区别 是否建立连接， udp不建立连接，tcp三次握手 是否可靠，udp不需要确认， tcp会有确认、重传、窗口、拥塞等机制 应用场景， udp一般用于即时通信，qq，直播； tcp用于文件传输，收发邮件、登录等 - 为什么要三次握手，四次挥手#为什么要三次握手 确认双发收发功能都正常 为什么要四次挥手 确认双方都没有数据再发送 - 四次挥手的closewait, timewait分别在哪，为什么timewait要等待2msl#2MSL是两倍的MSL(Maximum Segment Lifetime)，MSL指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间 如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接 TIME_WAIT状态就是用来重发可能丢失的ACK报文。在Client发送出最后的ACK回复，但该ACK可能丢失。Server如果没有收到ACK，将不断重复发送FIN片段。所以Client不能立即关闭，它必须确认Server接收到了该ACK - 设计模式六大原则#其中设计模式的SOLID原则(Principles)如下： 单一职责原则（Single Responsibility）开闭原则（Open Closed）里氏代换原则（Liskov Substitution）接口隔离原原则（Interface Segregation）依赖倒置原则（Dependency Inversion） - 线上需要关注哪些机器参数#指标 阈值 cpu.iowait 所有进程因为等待IO完成而被阻塞，导致CPU idle所花的时间的百分比 disk.io.util 如果这个指标较高，代表io遇到瓶颈 cpu.busy 60 cpu.load 1以下比较好，1.5 会引起程序响应时间变慢，应触发报警 mem.swapused 一般情况下使用swap，代表物理内存已不足，当系统没有足够物理内存来应付所有请求的时候就会用到 swap 设备。使用 swap 的代价非常大，如果系统没有物理内存可用，就会频繁 swapping，如果 swap 设备和程序正要访问的数据在同一个文件系统上，那会碰到严重的 IO 问题，最终导致整个系统迟缓。 cms gc后的老年代大小 jvm.fullgc.count 5 jvm.yonggc.count 70 jvm.yonggc.meantime(一分钟内的每次年轻代gc的平均时间) 500 - 有哪些处理线上问题的经验#实际是在考雪崩，限流，降级等措施 xxx ES导致雪崩，bc端未分离，b端下游超时引发的血案事件: 调用ES持续大量超时，服务bc端都在调用，b端超时时间设置长，占用了很多线程资源，影响C端服务响应，造成C端上游雪崩，影响二十度个服务(调ES超时的原因？查询请求的返回响应太大了)事中: 无熔断降级错误，现上线加熔断ES降级，(降级措施是？返回有损服务，创建活动失败)事后: bc端分离，对下游添加熔断降级，根本上还是要让es调用查询粒度更小一点，减少es调用的返回量 xxx 慢查询引发的血案1事件：下单的时候先去删除用户未支付订单并归还库存，但未支付订单表竟然没有给orderid添加索引，导致delete操作锁全表，在当天有大量未支付订单，导致下单接口越来越慢，最终把订单db中的连接数占满，db的整体不可用。 分析原因: DB的客户端在超时的时候会断开连接，但DB服务器还是在执行该操作，或阻塞着，客户端新的调用再申请新的连接，直到把DB的连接池打满，DB完全阻塞在这个查询上，导致不可用。 事前： 1. 学习数据库知识，尤其是索引和锁相关 2. 定时检查服务的索引是否覆盖全 3. 提前做好限流熔断等降级措施事中： 1. 限流降级， 2. 问题排查，数据库压力没有增加很多，但数据库响应缓慢，应该分析出是慢查询的原因，当很多的慢sql出来时事后： 1. 对服务整体重新排查 xxx 慢查询引发问题，慢sql导致mq积压事件: 新表去更新库存，但索引创建的时候没覆盖全场景，后续开发有sql未走到索引，某个周六出现MQ积压告警，看监控发现是慢sql更新，有条update语句未使用到索引，导致更新时锁全表事中: 临时增加索引事后: 检查了新表所有设计的sql没有未使用索引的情况。（慢查询是有可能占用过多的DB资源，把整个DB打垮）（是有可能出现卖超的）","link":"/2021/07/29/interview/other/"},{"title":"MQ","text":"- mq使用场景 - 如何保证消息顺序性 - 如何保证消息可靠性（不丢） - 如何保证高可用 - 如何保证高性能 - rocketmq &amp; kafka - mq使用场景# 异步 上游不需要同步拿到结果，执行过程又耗时 好处：异步可以让服务端的线程不同步阻塞，提高服务端的吞吐量 解耦 多个下游相同依赖 好处：不与依赖方耦合，不用额外开发 削峰 请求高峰期 好处：保护下层存储 - 如何保证消息顺序性#针对消息有序的业务需求，还分为全局有序和局部有序。 全局有序：一个Topic下的所有消息都需要按照生产顺序消费。 要满足全局有序，需要1个Topic只能对应1个Partition。consumer内部单线程。 局部有序：一个Topic下的消息，只需要满足同一业务字段的要按照生产顺序消费 producer按shardingkey分片的方式发到不同的分区 consumer单线程消费分区或保证相同的sharding规则下顺序线程模型串行消费 - 如何保证消息可靠性（不丢）#刷盘+重试、确认 rocketmq 多副本机制、持久化机制 生产者发消息重试&amp;ack，生产者发送消息自动重试到最大次数，发送时可配置同步刷盘再返回ack broker发消息重试&amp;ack，消费者接收到消息后会发送ack到broker否则broker也会重试 kafka 多副本写入 + 数据持久化，通过后台线程将消息持久化到磁盘 可设置写入副本情生产者ack机制，况，ack=0 可不写入就成功，ack=1 写入leader副本，ack=all 写入全部副本 生产者重试机制，出现网络问题可自动重试，可设置重试间隔 消费者使用手动提交，可保证消费一次 - 如何保证高可用# 分布式部署多分区 主从复制, 副本机制 同步复制，可配置broker节点之间同步复制 故障切换与恢复，自动检测触发故障转移 注：kafka副本机制。Kafka在0.8版本之前是没有HA机制来确保高可用的，当某一个broker挂掉，partition就挂了。即存在单点故障。0.8之后提供了副本机制，副本机制会将 一个broker下某个topic的一个partition放入到另外一个broker里，这个备份的分区和原分区都叫做副本（replica）。在所有的副本里，只能有一个leader，其余的副本都作为follower，同一时间内只有leader负责读写，follower不起任何作用。这样做的原因是为了确保消费者单调读 且 确保能立即读取写入的信息（Read-your-writes）。其他所有的follower会异步的拉去leader消息，拉的快的会进入ISR里，拉的慢得超过replica.lag.time.max.ms 配置的超时值的，会被踢进OSR里，这个过程是动态的，如果一个follower开始没跟上leader的消息写入速度，被踢出了ISR，等到跟上后又会重新进入ISR。当leader挂掉之后，为了保证高可用性，从ISR中获取一个副本，升格为leader。如果ISR全挂了，有两种策略，一是等待ISR第一个恢复的副本，二是开启unclean从OSR中选择一个副本作为leader。为保证高可用 可以选择第二种牺牲一致性的方式。 - 如何保证高性能#kafka 顺序读写。Kafka的message是不断追加到本地磁盘文件末尾的，而不是随机的写入，这使得Kafka写入吞吐量得到了显著提升 。 页缓存。kafka重度依赖页缓存技术，kafka只是将数据写入页缓存（内存）中而不直接操作磁盘，由操作系统决定什么时候把页缓存中数据刷到磁盘上。同时写入页缓存的数据是按照磁盘顺序去写入的，因此刷到磁盘上的速度也较快。当读操作发生时，先从页缓存中查询是否有所需信息，若没有才会调度磁盘。 零拷贝。这里的零拷贝并非指一次拷贝都没有，而是避免了在内核空间和用户空间之间的拷贝。页缓存 -&gt; socket缓冲区。 分区分段 + 索引。通过这种分区分段的设计，Kafka的message消息实际上是分布式存储在一个一个小的segment中的，每次文件操作也是直接操作的segment。为了进一步的查询优化，Kafka又默认为分段后的数据文件建立了索引文件，就是文件系统上的.index文件。这种分区分段+索引的设计，不仅提升了数据读取的效率，同时也提高了数据操作的并行度。 批量压缩。批量的消息可以通过压缩的形式传输并且在日志中也可以保持压缩格式，直到被消费者解压缩，减少网络IO. rocketmq 顺序读写。 可异步刷盘 零拷贝。 高效的消息存储结构。commitlog，cq indexfile，简化了存储优化了读写 批量处理。支持批量发送和消费，减少网络交互 - rocketmq &amp; kafka#rocketmq功能性更丰富一些。kafka性能在topic不多的时候更优一些。 功能性kafka不支持延时消息，不支持消息轨迹追踪和消息过滤，最新版本才开始支持事务消息。rocketmq支持消息过滤，在broker做过滤，减少网络压力；在consumer端可自定义过滤条件。 性能kafka因为是partition维度的文件存储，当topic多的时候随机写变多，性能下滑明显；相比rocketmq因为都是顺序写入commitlog，在topic多时对性能也不会有影响。","link":"/2021/08/01/interview/mq/"},{"title":"gc调优（parnew+cms）","text":"1如何做gc调优#调优目的：减少系统停顿时间优化目标：减少younggc、减少cmsgc、减少fullgcOld GC：只清理老年代空间的 GC 事件，只有 CMS 的并发收集是这个模式。Full GC：清理整个堆的 GC 事件，包括新生代、老年代、元空间等 。 1.1younggc原因#1.请求中生成的对象多。新生代空间较小，Eden区很快被填满，就会导致频繁young GC 1.1如何减少younggc#1.增大新生代空间2.减少请求中生成对象大小1.2cmsgc原因1.有过多的对象到达了老年代，频繁触发cms gc1.2如何减少cmsgc1.增大老年代大小2.减少进入老年代的对象大小, 提高晋升年龄阈值（如果小的话，比如改成了3、4） 1.3fullgc原因#1.metaspace扩容 2.CMS GC时出现promotion failed(晋升失败)和concurrent mode failure 触发串行full gc。 promotion failed: 当新生代发生垃圾回收，老年代有足够的空间可以容纳晋升的对象，但是由于空闲空间的碎片化，导致晋升失败，此时会触发单线程且带压缩动作的Full GC concurrent mode failure: 发生的原因一般是CMS正在进行，但是由于老年代空间不足，需要尽快回收老年代里面的不再被使用的对象，这时停止所有的线程，同时终止CMS，直接进行Serial Old GC3.统计得到的Young GC晋升到老年代的平均大小大于老年代的剩余空间； 4.主动触发Full GC， 程序代码执行System.gc(); 命令行中dump整个堆: 执行jmap -histo:live [pid]1.3如何减少fullgc#原因1. 启动时设置好metaspace，避免因扩容导致fullgc “-XX:MetaspaceSize=256M”, “-XX:MaxMetaspaceSize=256M” 原因2&amp;3. 减少cms gc •降低触发CMS GC的阈值, 以保证有足够的空间。即参数-XX:CMSInitiatingOccupancyFraction的值，让CMS GC尽早执行。•增大老年代空间•让对象尽量在新生代回收，避免进入老年代 原因4. 避免使用System.gc() 2.Jvm如何内存分配#eg: 16G内存机器，9G老年代，4G新生代，3G直接内存 3.gc调优案例#3.1younggc#1.请求中生成的对象大，eg:历史数据因历史原因对应很多或很大的返回结果，频繁访问造成gc较多，可以在场景允许的情况下将这部分数据下掉或者做个截断处理。减少younggc的频率和复制对象所花费的时间。2.增大新生代大小 3.2fullgc#1.服务启动时metaspace扩容触发fullgc，导致刚启动时服务不稳定，jvm启动参数中设置好Metaspace的size和最大size。2.服务偶尔发生concurrent mode failure。服务瞬间的可用性下降严重。修改jvm参数，降低触发cms gc的阈值（90%-&gt;75%），避免触发串行full gc。 3.3cmsgc#1.增大old区。肯定是有用的，至少能减少触发的频率2.也可能是晋升年龄阈值比较小。-XX:MaxTenuringThreshold，默认15, 可能有人改小了，让年龄小的就直接到old区了，比如改成3、4。 备注：cms内存碎片问题#通常 CMS 的 GC 过程基于标记清除算法，不带压缩动作，导致越来越多的内存碎片需要压缩。常见以下场景会触发内存碎片压缩新生代 Young GC 出现新生代晋升担保失败（promotion failed)） 程序主动执行System.gc() 可通过参数 CMSFullGCsBeforeCompaction 的值，设置多少次 Full GC 触发一次压缩。默认值为 0，代表每次进入 Full GC 都会触发压缩，带压缩动作的算法为上面提到的单线程 Serial Old 算法，暂停时间（STW）时间非常长，需要尽可能减少压缩时间。","link":"/2020/04/14/jvm/gcoptimiz/"},{"title":"mute all 20190623","text":"昨晚龙哥来我家玩，游戏开始的时候使用了快捷命令，/mute all, 屏蔽所有人的语言与信号，几场有输有赢但没有发生口角，专注于游戏。龙哥在以前打游戏的时候，会经常和别人吵起来，争论到底谁才是那个sx, 但mute all之后就不会了，心情也好了，胜率也高了。 有点小感叹我的生活，毕业前，我专注于学习，每天想的就是学习找工作，因为我一无所有所以目标明确且动力十足，会有点害怕。 而现在的话，也是想学习找工作，但首先每天都会抱怨一番现在的工作，每天都会跟同事讨论下现在有多么不爽，直接把自己带到负面情绪中，日复一日，而我是那个经常去讨论的人，虽说对学习有点推进作用，但过多的时候，会越来越急躁、烦躁、甚至暴躁，我那个暴躁的自己是最该mute的人。 其次的话，现在比在学校不一样的，就是会有更多信息，更多欲望，更多的信息渠道告诉你怎么样可能满足你的desire，比如怎样能获得更多的钱，更多事情更多的人你期望获取到对应的respect。我们开始观察、着急，想快速成功也害怕错过机会，我们肯定要追寻成功，但不能一心二用，不应该是在游戏开始的时候，当游戏开始时不该分精力去管那些desire、那些respect，你需要mute all，专心起来。 每个人都有自己的主观意识，没有人即使是你对象、父母，也不完全是你，只有自己了解自己，只有自己能承担自己，不能在人群中迷失了自我，不能在人们的讨论声中忘记了自我，想法不能被别人左右，只能自己左右，跳出人群，跳出这讨论，跳出来mute all , 做自己的判断。 我会努力不带情绪工作，也会努力学习去hz，如果我做不到，我仍需进步。","link":"/2012/06/23/life/muteAll/"},{"title":"记录租房第三个住处-天通苑东三区","text":"上上周末8月24号搬到了新的租房，搬到了天通苑北一区，换了一居，也住了十几天了，感觉很不错，但之前的租房也很好，它有一个大大的天台，还可以上房顶，把照片记录下来。 上周末回去稍微收拾了下屋子，卖了东西，图中为美丽聪慧的对象 很大的地方还有个落地灯 厨房以前在这个地方，这个屋在之前一段时间我们都把垫子搬过来打地铺睡，因为有一天我发现这里比较隔猫 我的电脑桌放在这个地方 大大的厕所，目前住过最大厕所 小储藏室 通往天台的门，lily最爱去的地方，总是会在这个地方站好开叫，然后看你过来了就扒扒门，lily非常渴望自由，想出去玩 出来啦！ 有一圈的天台，第一次见时真的很惊喜 视野十分开阔，夕阳西下，喝酒吃肉，美滋滋 在小区里捡到了很能叫又贪吃的新家庭成员，小 jojo 开始小小的很可爱， 陪我玩电脑 写博客 要抱抱 举高高 与lily从打闹慢慢有点和谐相处 学lily睡窗台 和我们一起睡觉，四生物一张床 后来因为早上太闹，用梳妆台挡住这两个捣蛋鬼，jojo此时已显猪态 幸福生活未完待续..","link":"/2019/09/03/life/天通苑东三区/"},{"title":"maven脚手架","text":"新建一个建立demo工程，在demo工程下执行： mvn archetype:create-from-project -DpackageName=com.xxx.web.campaign.demo 找到 target/generated-sources/archetype 即是当前demo工程的脚手架 先安装到本地测试一下 mvn clean install cd到创建新的项目的目录下，执行 mvn archetype:generate -DarchetypeCatalog=local 输入 groupId、artifactId、version、package之后即可生成完整项目 发布 将下面的配置放到target/generated-sources/archetype/pom.xml下： 12345678910111213&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;meituan-nexus-releases&lt;/id&gt; &lt;name&gt;Meituan Nexus Repository&lt;/name&gt; &lt;url&gt;http://xxx/nexus/content/repositories/releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;meituan-nexus-snapshots&lt;/id&gt; &lt;name&gt;Meituan Nexus Repository&lt;/name&gt; &lt;url&gt;http://xxx/nexus/content/repositories/snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; 执行 mvn deploy发布到远程maven仓库 需要构建项目的时候，本地执行下面命令，选择最新版本号的脚手架 mvn archetype:generate -DarchetypeGroupId=com.xxx.web.campaign -DarchetypeArtifactId=demo-archetype -DarchetypeVersion=1.0.2","link":"/2018/05/06/maven/脚手架/"},{"title":"mybatis架构流程","text":"架构图 架构分层 主要构件 层次结构 总体流程 设计模式","link":"/2020/08/06/mybatis/arti/"},{"title":"concurrentmodificationexception源码解析","text":"Java安全开发手册中# 7. 【强制】不要在 foreach 循环里进行元素的 remove/add 操作。remove 元素请使用 Iterator 方式，如果并发操作，需要对 Iterator 对象加锁。 个人总结# 在迭代器中走list的remove大部分情况都会抛 ConcurrentModificationException 异常，从迭代器的next、remove中抛出，因new迭代器类的时候，私有变量expectedModCount会记录修改次数，当List的modCount不一致时会抛出异常，而List的add,remove等修改操作都会增加modCount 也会有在删除某些元素后导致迭代器cursor和size正好相等，hasnext返回false, 不再遍历就不抛异常，但不会遍历到后面移动到已删除位置的元素 List接口中有iterator()接口，因此List的子类都要注意这点 迭代器源码#12345a.iterator()--&gt;public Iterator&lt;E&gt; iterator() { return new Itr();} 123456789101112131415161718192021222324252627282930313233343536373839404142private class Itr implements Iterator&lt;E&gt; { int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; public boolean hasNext() { return cursor != size; } @SuppressWarnings(\"unchecked\") public E next() { checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; } public void remove() { if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try { ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } final void checkForComodification() { if (modCount != expectedModCount) throw new ConcurrentModificationException(); }} ArrayList源码#123456789101112131415161718192021222324public boolean remove(Object o) { if (o == null) { for (int index = 0; index &lt; size; index++) if (elementData[index] == null) { fastRemove(index); return true; } } else { for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) { fastRemove(index); return true; } } return false;}private void fastRemove(int index) { modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work} 情况1. 特殊情况例如删除倒数第二个元素不抛异常，但会漏遍历倒数第一个元素#下面这段代码不会出异常，异常都是走到了迭代器的 next 或 remove 方法，通过 checkForComodification 方法抛出，此例删除倒数第二个，cursor变为1 (初始0)，size也变为1，在hasNext方法中返回false，则不会走到”2”， 也不会走到next, 但这种漏了”2” ,是有很大问题的 1234567891011List&lt;String&gt; a = new ArrayList&lt;&gt;();a.add(\"1\");a.add(\"2\");Iterator&lt;String&gt; iterator = a.iterator();while (iterator.hasNext()) { String temp = iterator.next(); if(\"1\".equals(temp)){ a.remove(temp); }}System.out.println(a.toString()); 情况2.大多数情况，因为list.remove增加了modcount, 导致next中判断modcount 与 expectmodcount不相等抛异常#下面这段代码会抛异常，因为最后cursor变为了2，size经过remove变成了1，根据hasNext方法cursor!=size，会返回true，走到next方法，然后next方法中 checkForComodification 会因为modcount 与 expectmodcount不相等而抛异常 ConcurrentModificationException 1234567891011List&lt;String&gt; a = new ArrayList&lt;&gt;();a.add(\"1\");a.add(\"2\");Iterator&lt;String&gt; iterator = a.iterator();while (iterator.hasNext()) { String temp = iterator.next(); if(\"2\".equals(temp)){ a.remove(temp); }}System.out.println(a.toString());","link":"/2019/05/23/list/concurrentmodificationexception/"},{"title":"2017春季面经","text":"春季校园招聘准备内容 &amp; 两次面经总结 to学弟 2017.12.25 之前并没有注意秋招，后知后觉的我辞了实习工作，开始准备春招 开始面的一个游戏公司，较简单，然后面的好未来教育，三面的时候说招c++或php的。。后来还投了很多网申，今日头条，去哪儿，有道笔记，都进行了线上笔试，只面了美团和爱奇艺，都过了，去了美团，别的也没有信了，这个，，还是挺没准的，我建议多投简历 招聘就像一场应试，线上笔试就答线上题，面试就是当面答题。线上笔试的话多是数据库、操作系统、算法之类的。如果内推的话是最好的，属于提前批，先到先得，简历不错可能直接进入面试，或者提前批笔试，有的公司可能内推不是太多就直接进入面试吧， 不过网申也是有机会的，我就是网申的 面试内容分 知识面(一二面) &amp; 复杂面(三面) &amp; 轻松面(hr面，也有的公司没有) 知识面(一二)#除了题的知识相信面试官还比较在乎你是否思维敏捷、对不会得问题是否积极思考 知识点我非常建议去牛客网上看面经，有非常多的面经，各个公司的，如果你有意向公司可以专门找来看 https://www.nowcoder.net/discuss?type=2&amp;order=0 拉勾网 校园板块会有一些公司的校园招聘链接，不一定全，网申用 https://xiaoyuan.lagou.com/ 我当时搜集了一些知识点，包括网络、项目、java、web框架、多线程、数据库、jvm，包含了百分之6、7十的问题吧，上传到百度云。 链接:https://pan.baidu.com/s/1o9Q67lo 密码:4mhz 设计模式，当时过年看的大话设计模式，算法，看的剑指offer 走完上面的一遍应该已经不错了，如果时间短的话设计模式挑单例模式、观察者、工厂、装饰器、外观、策略，几个常用的看，单例模式尤其重要，饿汉懒汉、是否线程安全、双检锁、为什么用volatile，在爱奇艺面的时候考过 我列一下我目前还能想到的知识面的问题 类别 知识点 设计模式 单例模式 饿汉懒汉 是否线程安全 、双检锁、为什么用volatile 每次问我比较擅长的，我就说设计模式，因为读了大话设计模式还整理了下，可能问你一个模式让你答，通常都是那几个常见的，单例问的最多，自己说的话，就说两个稍复杂点的 数据库 三范式 索引类型, 结构, b树 , b+树 ，b+和 b常问 mysql的数据库隔离级别，锁机制 框架 印象深的是美团和爱奇艺都让详细讲一下spring的ioc和aop，ioc好讲，aop的两种代理要讲好需好好看 spring的事务传播机制 springmvc 消息处理流程，struts相关没有问过 mybatis，hibernate也不记得问过什么了，很少问，公司通常用mybatis，hibernate很少用 jvm 类加载机制，内存模型，内存结构(我当时就讲的7的，现在8方法区没有了，可以说下) A a = new A() 内存里发生了什么 多线程 concurrentHashmap 几乎必问 网络 osi, tcp/ip 通常问tcp/ip ，各层是做啥的，有什么协议，三次握手，四次挥手(挥手好像没问过) 算法 写两遍剑指offer，第一遍想一下看答案写，第二遍看题目写完对答案，非常锻炼写代码的能力，起码笔试的时候拿起笔不会怵，即使没见过的题，也有大概思路，脑子里想到的能写出来，不会想得到一下笔就忘，笔能跟上思路，手写 几种排序算法 美团考的剑指offer里的，好未来 考的排序算法 操作系统&amp;shell应该是没问过 复杂面(三)#三面就是你以后的直接上级面了，通常问的会随机一些，我感觉是先看看你的简历里做过的项目，挑一个你做过的，问一下某个项目的细节，问的我redis和memcache 之间的区别，和使用redis解决的一个问题的方法，感觉是会挑中间件问一下，因为中间件的使用大家都是差不多的，其它都是业务了，还有你做过最复杂的一个功能，还会给你假设一个场景，问下你怎么实现，你做过的项目你要清楚，问你其它的知识点，知道最好，但总会有不知道的，就看你是否积极思考，思维能力强不强，脑子好不好使，校招经验是小加分项，主要还是看你是否学习能力强，有潜力我觉得。 这一面主要就是从你简历里涉及到的技术知识下手，还肯定会问下你的职业规划 我有个人博客，爱奇艺面试官也是河大的，还问了下我博客上的内容，随便问了个我当时看的nio，我也答了一下，这面有一定随机性 如果你现在还没让走，就会问你对公司有什么问题需要了解吗。 可以问下加入之后的工作方向，内容、技术之类的（个人意见） 轻松面(hr)#这一面最轻松，工资参照网上资料，基本跟你聊聊性格，聊聊人生，积极阳光就好 注： 总结的是我的两次面试，只有两次，会有其特殊性，建议多上牛客网上看看大家的面经，尤其应届秋招 写面经让我想到许多往事，当时心神不定，没有足够的自信，每天心神都会慌乱，可能你也这样，希望你能坚持下去，祝顺利","link":"/2018/02/04/mj/spring/"},{"title":"tensorflow多特征预测销量demo","text":"最近一直在搞这个，终于算是跑成了，知识点掌握不全面，但坑走过一两个还是有进步。。 这个项目做得是多维度特征对于月销量的一个回归，操作主要包括两方面，训练并生成模型、 导入模型预测结果。 github地址： https://github.com/ruushwei/TensorDemo 训练#样本数据是我自己找的70行数据，放到了csv文件中，用于训练 测试数据为根据一条样本数据编的5条测试数据，只改了其中两个特征，用于预测因为这两个特征改变导致结果的变化。 样本与测试数据在github上 步骤： 从文件读取数据 —&gt; tensorflow图的构建 —&gt; 执行session进行训练 ——&gt; 通过画图观察拟合程度 code: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102from __future__ import print_functionimport tensorflow as tffrom sklearn.preprocessing import Normalizerimport matplotlib.pyplot as pltimport numpy as np### 从文件获取数据my_matrix = np.loadtxt(open(\"data2.csv\", \"rb\"), dtype=np.float, delimiter=\",\", skiprows=1)## 获取除第一列数据，第一列为结果值，写列号为笨方法，不知道该怎么写tezheng = my_matrix[:,[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52]] ## 销量结果，用于训练sale = my_matrix[:,0]## 将特征进行归一化，使训练的时候不会受大小特征影响严重，注：非scale，scale是对于列的，scale再进行预测的时候即使相同一行数据，因为其它数据变了，这一列有变，scale之后得到的值也不一样，预测结果自然也不一样了。## 下面这种是对行的归一化X_train = Normalizer().fit_transform(tezheng) ## 多维特征y_train = sale.reshape((-1,1)) ## 结果，从一维转为二维#### 开始进行图的构建## 特征与结果的替代符，声明类型，维度 ，name是用来生成模型之后，使用模型的时候调用用的inputX = tf.placeholder(shape=[None, X_train.shape[1]], dtype=tf.float32, name=\"inputX\")y_true = tf.placeholder(shape=[None,1], dtype=tf.float32, name=\"y_true\")## 丢弃样本比例，1是所有的样本使用，这个好像是自动回丢弃不靠谱的样本keep_prob_s = tf.placeholder(dtype=tf.float32, name=\"keep_prob\")### 第一层，一个隐藏层 开始## shape的第一维就是特征的数量，第二维是给下一层的输出个数, 底下的矩阵相乘实现的该转换Weights1 = tf.Variable(tf.random_normal(shape=[52, 10]), name=\"weights1\") ## 权重biases1 = tf.Variable(tf.zeros(shape=[1, 10]) + 0.1, name=\"biases1\") ## 偏置## matmul矩阵相乘，nn.dropout 丢弃部分不靠谱数据Wx_plus_b1 = tf.matmul(inputX, Weights1)Wx_plus_b1 = tf.add(Wx_plus_b1, biases1)Wx_plus_b1 = tf.nn.dropout(Wx_plus_b1, keep_prob=keep_prob_s) ## 将结果曲线化，通常说非线性化l1 = tf.nn.sigmoid(Wx_plus_b1, name=\"l1\")### 第一层结束### 第二层开始，即输出层## 上一层的10，转为1，即输出销售量Weights2 = tf.Variable(tf.random_normal(shape=[10, 1]), name=\"weights2\") ## 权重biases2 = tf.Variable(tf.zeros(shape=[1, 1]) + 0.1, name=\"biases2\") ## 偏置## matmul矩阵相乘 ,l1 为上一层的结果Wx_plus_b2 = tf.matmul(l1, Weights2)prediction = tf.add(Wx_plus_b2, biases2, name=\"pred\") ## pred用于之后使用model时进行恢复## 这里使用的这个方法还做了一个第一维结果行差别的求和，reduction_indices=1，实际这个例子每行只有一个结果,使用 loss = tf.reduce_sum(tf.square(y_true - prediction)) 即可loss = tf.reduce_mean(tf.reduce_sum(tf.square(y_true - prediction), reduction_indices=[1]))## 训练的operator，AdamOptimizer反正说是最好的训练器, 训练速率0.01train_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)#### draw pics 这里画了一个坐标图fig = plt.figure()ax = fig.add_subplot(1, 1, 1) # 第一个块里画ax.plot(range(50), y_train[0:50], 'b') # 先画出样本前50个数据的真实结果ax.set_ylim([0, 30]) # 设置纵轴的范围plt.ion() # 打开交互模式，不打开不能在训练的过程中画图plt.show() # 展示图片，现在是只有50个真实数据连成的1条线### 开始执行with tf.Session() as sess: saver = tf.train.Saver(tf.global_variables(), max_to_keep=15) # 初始化saver，用于保存模型 init = tf.global_variables_initializer() # 初始化全部变量 sess.run(init) # 初始化全部变量 ## 要给模型进行训练的数据，只有placeholder类型的需要传进去数据 feed_dict_train = {inputX: X_train, y_true: y_train, keep_prob_s: 1} for i in range(40000): _loss, _ = sess.run([loss, train_op], feed_dict=feed_dict_train) # 训练，注：loss没有训练，只是走到loss，返回值，走到train_op才会训练 if i % 1000 == 0: print(\"步数:%d\\tloss:%.5f\" % (i, _loss)) pred_feed_dict = {inputX: X_train, keep_prob_s: 1} # 用来预测的数据,不需要y pred = sess.run(prediction, feed_dict=pred_feed_dict) # 走到prediction即可 ## 将预测的结果画到图像上,与真实值做对比 try: ax.lines.remove(lines[0]) except: pass lines = ax.plot(range(50), pred[0:50], 'r--') plt.pause(1) # 保存模型 saver.save(sess=sess, save_path=\"nn_boston_model/nn_boston.model\", global_step=40000) ## done, 关闭程序后model就会出现在文件夹中 使用model预测#很简单，大概就是获取整个图结构和所有变量信息，然后走图，到prediction，就可以预测了 1234567891011121314151617181920212223242526272829303132333435363738import tensorflow as tffrom sklearn.preprocessing import Normalizerimport numpy as np### 从文件获取测试数据my_matrix2 = np.loadtxt(open(\"data3.csv\", \"rb\"), dtype=np.float, delimiter=\",\", skiprows=1)tezheng2 = my_matrix2[:, [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52]]X = Normalizer().fit_transform(tezheng2)with tf.Session() as sess: # 拿到 图的元信息 saver saver = tf.train.import_meta_graph(meta_graph_or_file=\"nn_boston_model/nn_boston.model-40000.meta\") # 这个也很重要，虽然还不知道是做什么的 model_file = tf.train.latest_checkpoint(checkpoint_dir=\"nn_boston_model\") # 执行恢复 saver.restore(sess=sess, save_path=model_file) # 此处得到的是图结构 graph = tf.get_default_graph() # get placeholder from graph 拿到两个需要输入的数据节点，预测时输入 inputX = graph.get_tensor_by_name(\"inputX:0\") keep_prob_s = graph.get_tensor_by_name(\"keep_prob:0\") # get operation from graph 拿到能输出结果的数据节点，预测时执行到这里，拿到预测结果值 prediction = graph.get_tensor_by_name(\"pred:0\") # 开始预测, 还是不用输入y , 丢弃我一直写的1，不丢弃 feed_dict = {inputX: X, keep_prob_s: 1} y_pred = sess.run(prediction, feed_dict=feed_dict) # 得到预测结果 print(y_pred) 目前所有知道的东西都在上面了。。整个实现还是面向过程的，有待升级。。","link":"/2018/01/31/ml/sale/"},{"title":"分库分表组件原理","text":"参考文档：https://github.com/Meituan-Dianping/Zebra/wiki/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E9%97%B4%E4%BB%B6%E4%B8%BB%E6%B5%81%E8%AE%BE%E8%AE%A1 数据库中间件设计方案典型的数据库中间件设计方案有2种：服务端代理(proxy：代理数据库)、客户端代理(datasource：代理数据源)。下图演示了这两种方案的架构 可以看到不论是代理数据库还是代理数据源，底层都操作了多个数据库实例。不同的是： 服务端代理(proxy：代理数据库)中： 我们独立部署一个代理服务，这个代理服务背后管理多个数据库实例。而在应用中，我们通过一个普通的数据源(c3p0、druid、dbcp等)与代理服务器建立连接，所有的sql操作语句都是发送给这个代理，由这个代理去操作底层数据库，得到结果并返回给应用。在这种方案下，分库分表和读写分离的逻辑对开发人员是完全透明的。 客户端代理(datasource：代理数据源)： 应用程序需要使用一个特定的数据源，其作用是代理，内部管理了多个普通的数据源(c3p0、druid、dbcp等)，每个普通数据源各自与不同的库建立连接。应用程序产生的sql交给数据源代理进行处理，数据源内部对sql进行必要的操作，如sql改写等，然后交给各个普通的数据源去执行，将得到的结果进行合并，返回给应用。数据源代理通常也实现了JDBC规范定义的API，因此能够直接与orm框架整合。在这种方案下，用户的代码需要修改，使用这个代理的数据源，而不是直接使用c3p0、druid、dbcp这样的连接池 主流的数据库中间件实现对比无论是代理数据库，还是代理数据源，二者的作用都是类似的。以下列出了这两种方案目前已有的实现以及各自的优缺点： 数据库代理 目前的实现方案有：阿里巴巴开源的cobar，mycat团队在cobar基础上开发的mycat，mysql官方提供的mysql-proxy，奇虎360在mysql-proxy基础开发的atlas。目前除了mycat，其他几个项目基本已经没有维护。 优点：多语言支持。也就是说，不论你用的php、java或是其他语言，都可以支持。原因在于数据库代理本身就实现了mysql的通信协议，你可以就将其看成一个mysql 服务器。mysql官方团队为不同语言提供了不同的客户端驱动，如java语言的mysql-connector-java，python语言的mysql-connector-python等等。因此不同语言的开发者都可以使用mysql官方提供的对应的驱动来与这个代理服务器建通信。 缺点：实现复杂。因为代理服务器需要实现mysql服务端的通信协议，因此实现难度较大。 数据源代理目前的实现方案有：阿里巴巴开源的tddl，大众点评开源的zebra，当当网开源的sharding-jdbc。 优点：更加轻量，可以与任何orm框架整合。这种方案不需要实现mysql的通信协议，因为底层管理的普通数据源，可以直接通过mysql-connector-java驱动与mysql服务器进行通信，因此实现相对简单。 缺点：仅支持某一种语言。例如tddl、zebra、sharding-jdbc都是使用java语言开发，因此对于使用其他语言的用户，就无法使用这些中间件。版本升级困难，因为应用使用数据源代理就是引入一个jar包的依赖，在有多个应用都对某个版本的jar包产生依赖时，一旦这个版本有bug，所有的应用都需要升级。而数据库代理升级则相对容易，因为服务是单独部署的，只要升级这个代理服务器，所有连接到这个代理的应用自然也就相当于都升级了。 ORM框架代理目前有hibernate提供的hibernate-shards，也可以通过mybatis插件的方式编写。相对于前面两种方案，这种方案可以说是只有缺点，没有优点。","link":"/2021/08/23/mysql/dbfenbiao/"},{"title":"mysql创建100张表","text":"使用存储过程，创建100张表 使用存储过程，创建100张表 12345678910111213141516171819202122232425262728293031323334DELIMITER ;;create PROCEDURE createTable(a INT)begin DECLARE i INT default 0; while i &lt; a do set @table_name = concat(&apos;xxx_log_&apos;,concat(i,&apos;&apos;)); set @sql_text=CONCAT(&apos;CREATE TABLE IF NOT EXISTS &apos;, @table_name, &apos;( id bigint(20) COMMENT &quot;主键&quot; PRIMARY KEY NOT NULL AUTO_INCREMENT, xxx_id int(10) COMMENT &quot;xxxId&quot; ) ENGINE=InnoDB DEFAULT CHARSET=utf8&apos;); PREPARE stmt FROM @sql_text; EXECUTE stmt; DEALLOCATE PREPARE stmt; set i=i+1; end while;end;;# 删除存储过程#drop PROCEDURE createTables;# 调用存储过程call createTable(100)# 列出当前的存储过程#show procedure status; # 显示存储过程的具体内容#show create procedure createTables","link":"/2019/04/02/mysql/mysql创建100张表/"},{"title":"mybatis疑问解答","text":"Mybatis的点#通过动态代理，自动生成一些参数的映射、sql的执行、结果的映射，减少了大量重复的代码，且对sqlsession，jdbc操作，事务，一二级缓存，做了很好的封装 MyBatis的工作原理# 1）读取 MyBatis 配置文件：mybatis-config.xml 为 MyBatis 的全局配置文件，配置了 MyBatis 的运行环境等信息，例如数据库连接信息。 2）加载映射文件。映射文件即 SQL 映射文件，该文件中配置了操作数据库的 SQL 语句，需要在 MyBatis 配置文件 mybatis-config.xml 中加载。mybatis-config.xml 文件可以加载多个映射文件，每个文件对应数据库中的一张表。 3）构造会话工厂：通过 MyBatis 的环境等配置信息构建会话工厂 SqlSessionFactory。 4）创建会话对象：由会话工厂创建 SqlSession 对象，该对象中包含了执行 SQL 语句的所有方法。 5）Executor 执行器：MyBatis 底层定义了一个 Executor 接口来操作数据库，它将根据 SqlSession 传递的参数动态地生成需要执行的 SQL 语句，同时负责查询缓存的维护。 6）MappedStatement 对象：在 Executor 接口的执行方法中有一个 MappedStatement 类型的参数，该参数是对映射信息的封装，用于存储要映射的 SQL 语句的 id、参数等信息。 7）输入参数映射：输入参数类型可以是 Map、List 等集合类型，也可以是基本数据类型和 POJO 类型。输入参数映射过程类似于 JDBC 对 preparedStatement 对象设置参数的过程。 8）输出结果映射：输出结果类型可以是 Map、 List 等集合类型，也可以是基本数据类型和 POJO 类型。输出结果映射过程类似于 JDBC 对结果集的解析过程。 mybaits中如何维护一级缓存、一级缓存的生命周期、一级缓存何时失效#BaseExecutor成员变量之一的PerpetualCache，是对Cache接口最基本的实现， 其实现非常简单，内部持有HashMap，对一级缓存的操作实则是对HashMap的操作。 一级缓存的生命周期和SqlSession一致，即一次会话 何时失效a. MyBatis在开启一个数据库会话时，会创建一个新的SqlSession对象，SqlSession对象中会有一个新的Executor对象，Executor对象中持有一个新的PerpetualCache对象；当会话结束时，SqlSession对象及其内部的Executor对象还有PerpetualCache对象也一并释放掉。b. 如果SqlSession调用了close()方法，会释放掉一级缓存PerpetualCache对象，一级缓存将不可用；c. 如果SqlSession调用了clearCache()，会清空PerpetualCache对象中的数据，但是该对象仍可使用；d.SqlSession中执行了任何一个update操作update()、delete()、insert() ，都会清空PerpetualCache对象的数据 一级缓存的工作流程？#a.对于某个查询，根据statementId,params,rowBounds来构建一个key值，根据这个key值去缓存Cache中取出对应的key值存储的缓存结果；b. 判断从Cache中根据特定的key值取的数据数据是否为空，即是否命中；c. 如果命中，则直接将缓存结果返回；d. 如果没命中：去数据库中查询数据，得到查询结果；将key和查询到的结果分别作为key,value对存储到Cache中；将查询结果返回. mybatis sqlsession、connection、transition的理解#一个sqlsession会话，如果是多个更新操作 自动提交： 代码层是一个connection、一个transition事务配置， db层是一个connection，多个事务 手动提交： 代码层是一个connection、一个transition事务配置，db层也是一个connection，一个事务 Mybatis动态sql是做什么的？都有哪些动态sql？简述一下动态sql的执行原理？#动态sql是用一定规则方便的拼接sql。 动态sql: 、 执行原理：获取当前节点的子节点，判断子节点的类型是否为文本或者CDATA，如果是则没有动态sql，如果节点类型为元素，则表明是动态sql，根据动态sql标签类型，给到不同的handler做处理，最终拼成一个sql Mybatis是否支持延迟加载？如果支持，它的实现原理是什么？#支持。 实现原理是动态代理。在resultSetHandler做结果集映射的时候，判断下属性是否配置了嵌套查询，如果配置了则先创建代理对象，实现代理对象的invoke方法，在对下get操作的时候，再去执行该字段的获取方法。 Mybatis都有哪些Executor执行器？它们之间的区别是什么？#SimpleExecutor, ReuseExecutor , BatchExecutor , CachingExecutor SimpleExecutor：每一次执行都会创建一个新的Statement对象. ReuseExecutor: 重复使用Statement对象 ReuseExecutor比SimpleExecutor 性能更好一些 BatchExecutor：批量statement提交。其事务无法自动提交 CachingExecutor：用来做二级缓存，装饰者模式。 实际生产环境中建议使用 ReuseExecutor 简述下Mybatis的一级、二级缓存（分别从存储结构、范围、失效场景。三个方面来作答）？#存储结构：一级、二级缓存的存储结构都为hashMap 范围：一级缓存的范围是sqlsession级别，二级缓存的范围是namespace级别 失效场景： 当sqlsession做插入、更新、删除操作时 简述Mybatis的插件运行原理，以及如何编写一个插件？#拦截器，对mybatis的四大核心对象做拦截，做功能增强，底层动态代理实现，四大对象创建时，都会走到interceptorChain.pluginAll(), 返回增强后的对象 编写插件：1.实现一个interceptor， 加上注解， @Intercepts, 配置要增强的四大对象的接口和方法名2.sqlMapperConfig中添加该自定义插件标签 参考文献：https://juejin.im/post/6844904101587714061https://www.shangmayuan.com/a/cfc40f96680e49e9b692a4e7.html","link":"/2020/08/07/mybatis/question/"},{"title":"Innodb 锁","text":"Innodb支持哪些锁#按兼容性分为 共享锁（Shared Locks，S锁）、排他锁（Exclusive Locks，X锁）按锁范围分为：表级锁、行级锁表锁：表共享读锁（Table Read Lock）、表排他写锁（Table Write Lock)、意向共享锁（intention shared lock, IS锁）、意向排他锁（intention exclusive lock, IX锁）行锁：记录锁（Record Locks）、间隙锁（Gap Locks）、临键锁（Next-Key Locks）、插入意向锁（Insert Intention Locks） 共享锁（S）、排他锁（X）#锁的模式，每种锁都有shared和exclusive两种模式。特性：X锁与其他X,S锁不兼容，S与S锁兼容 锁定读#SELECT … FOR SHARE 和 SELECT … FOR UPDATE这两种锁定读在搜索时所遇到的每一条索引记录(index record)上设置共享锁或排它锁。 意向锁（IS、IX）#意向锁，协调行锁和表锁之间的关系的，实现了“表锁是否冲突”的快速判断。协调表的读写锁和行的读写锁（不同粒度锁）之间关系。场景：获取行的S锁，需要先获取表的IS锁；获取行的X锁，需要先获取表的IX锁。注：与意向锁冲突的不是行的X锁，是表的X锁！IX 与表的 X 和 S 冲突，意思当前表有行锁X锁，不能上表的X或S锁。IS 与表的 X 冲突，意思当前表有行锁S锁，不能上表的X锁。why意向锁：“表锁是否冲突”的快速判断。否则需要遍历表去判断行锁的存在，才能判断冲突。 索引记录锁(Record Locks)#行锁，锁定的是索引记录。所谓的“锁定某个行”或“在某个行上设置锁”。就是在某个索引的特定索引记录（或称索引条目、索引项、索引入口）上设置锁。有shared或exclusive两种模式 间隙锁(Gap Locks)#锁定尚未存在的记录，即索引记录之间的间隙。有shard或exclusive两种模式，但，两种模式没有任何区别，二者等价。gap lock 之间可以共存 ! 两个事务可以共同持有。gap只阻塞插入意向锁。why gap lock: 唯一目的就是阻止其他事务向gap中插入数据行。解决 phantom row问题。gap lock与 插入意向锁冲突。rc 没有gap lock， rr使用gap与插入意向锁的冲突解决幻读。 下一个键锁(Next-Key Locks)#next-key lock 是 (索引记录上的索引记录锁) + (该索引记录前面的间隙上的锁) 二者的合体，它锁定索引记录以及该索引记录前面的间隙。有shard或exclusive两种模式。next-key lock 带的 gap lock固定锁记录前面的间隙！ 插入意向锁(Insert Intention Locks)#特殊的gap lock。插入行之前，INSERT操作会首先在索引记录之间的间隙上设置insert intention lock，该锁的范围是(插入值, 向下的一个索引值)。有shard或exclusive两种模式，但，两种模式没有任何区别，二者等价。插入意向锁 会和 gap锁冲突！插入意向锁 本身多个不会冲突！插入意向锁也不会阻塞gap锁，只有先gap, 再insert Intention Lock 会阻塞。why插入意向锁: 隔离级别为RR时正是利用插入意向锁与gap锁的冲突，来解决幻读问题。 不同索引加锁情况# 聚簇索引 索引命中：对这个 id 聚簇索引加 X 锁 索引未命中：对 id 这个聚簇索引加 GAP 锁，GAP的范围是两个索引的间隙 范围条件： 对范围区间内命中的id聚簇索引加Next-Key 锁，即左开右闭的GAP锁+X锁。eg: UPDATE student SET age = 100 WHERE id &lt; 3 唯一索引 索引命中：二级索引的叶子节点中保存了主键索引的位置，在给二级索引加锁的时候，对应聚簇索引也会一并加锁。加两个X锁。 索引未命中：只会在二级索引加GAP锁，不会在聚簇索引上加锁。 范围条件：对范围区间内命中的唯一索引加Next-Key 锁(对条件范围内的索引加GAP锁+X锁)，并且对命中索引对应的聚簇索引也会加 X锁。 非唯一索引 索引命中：对命中的非唯一索引加 Next-Key锁，在非唯一索引相邻区间加 GAP 锁。并且对命中索引对应的聚簇索引加X锁。 索引未命中: 只会在二级索引加GAP锁，不会在聚簇索引上加锁。 范围条件：与唯一索引的范围条件加锁类似，对命中的索引加Next-Key锁(对条件范围内的索引加GAP锁+X锁)，对应的聚簇索引加X锁。 无索引 在没有索引的时候，只能走聚簇索引，对表中的记录进行全表扫描。会给所有记录加行锁，所有聚簇索引之间会加上 GAP 锁。 为什么无索引更新会锁全表？#在没有索引的时候，只能走聚簇索引，对表中的记录进行全表扫描。会给所有记录加行锁，所有聚簇索引和聚簇索引之间还会加上 GAP 锁。eg: UPDATE student SET age = 100 WHERE age = 33; age无索引。why: RR 下要保证当前读时不出现幻读。需要锁全表！否则任何一个记录都可以变成age=33, 任何一个地方都可以insert一条age=33。再执行该sql的时候会发现多出记录了。 死锁场景#死锁的可能性并不受隔离级别的影响。隔离级别改变的是读操作的行为，而死锁是由于写操作产生的。 两个行锁顺序不同的获取stu_no字段 是唯一索引_1234session1 : update student set age = 88 where stu_no = 1;session2 : update student set age = 99 where stu_no = 3;session1 : update student set age = 99 where stu_no = 3;session2 : update student set age = 88 where stu_no = 1; 死锁, 一个有stu_no=1的 X RECORD锁，一个有stu_no=3的。 两个gap锁各自阻塞另一个事务的插入意向锁stu_no字段 是唯一索引_ 1234session1 : delete from student where stu_no = 8;session2 : delete from student where stu_no= 7;session1 : insert student (stu_no) values (6);session2 : insert student (stu_no) values (9); 两个insert duplicate失败会加S RECORD, 若session1 commit, 两个返回duplicate-key error，若session1 rollback, 两个都想获取X锁，但对方都不释放S锁stu_no字段是唯一索引_ 123456session1: insert student (stu_no) values (6);session2: insert student (stu_no) values (6);session3: insert student (stu_no) values (6);session1: rollback;session2: commit;session3: commit; 参考文档：https://mp.weixin.qq.com/s/IyeiP2t1TGxZlPqSPAWNZghttps://mp.weixin.qq.com/s/dRIfbVwAJfEuZ978VlyXIAhttps://mp.weixin.qq.com/s/S9Fzwu7-g81DsWgjaARHvQ","link":"/2021/09/02/mysql/innodb锁/"},{"title":"MVCC-2021","text":"总结#MVCC的核心实现主要基于两部分：多事务并发操作数据与一致性读实现。 RC的本质：每一条SELECT都可以看到其他已经提交的事务对数据的修改，只要事务提交，其结果都可见，与事务开始的先后顺序无关。RR的本质：第一条SELECT生成ReadView前，已经提交的事务的修改可见。 多事务并发操作数据#多事务并发操作数据核心基于Undo log进行实现，Undo log可以用来做事务的回滚操作，保证事务的原子性。同时可以用来构建数据修改之前的版本，支持多版本读。 InnoDB中，每一行记录都有两个隐藏列：DATA_TRX_ID和DATA_ROLL_PTR。(若没有主键，则还有一个隐藏主键)DATA_TRX_ID：记录最近更新这条记录的事务ID(6字节)DATA_ROLL_PTR：指向该行回滚段的指针，通过指针找到之前版本，通过链表形式组织(7字节)DB_ROW_ID：行标识（隐藏单增ID），没有主键时主动生成(6字节)当存在多个事务进行并发操作数据时，不同事务对同一行的更新操作产生多个版本，通过回滚指针将这些版本链接成一条Undo Log链。 操作过程如下：1、将待操作的行加排他锁。2、将该行原本的值拷贝到Undo Log中，DB_TRX_ID和DB_ROLL_PTR保持不变。（形成历史版本）3、修改该行的值，更新该行的DATA_TRX_ID为当前操作事务的事务ID，将DATA_ROLL_PTR指向第二步拷贝到Undo Log链中的旧版本记录。（通过DB_ROLL_PTR可以找到历史记录）4、记录Redo Log，包括Undo Log中的修改。INSERT操作：产生新的记录，其DATA_TRX_ID为当前插入记录的事务ID。DELETE操作：软删除，将DATA_TRX_ID记录下删除该记录的事务ID，真正删除操作在事务提交时完成。 一致性读实现#在InnoDB中，对于不同的事务隔离级别，一致性读实现均不相同，具体如下：READ UNCOMMITED隔离级别：直接读取版本的最新记录。SERIALIZABLE隔离级别：通过加锁互斥访问数据实现。READ COMMITED和REPEATABLE READ隔离级别：使用版本链实现。(ReadView，可读性视图)对于RC与RR隔离级别，实现一致性读都是通过ReadView，也就是今天的重点，什么是ReadView？ MVCC ReadViewReadView是事务开启时，当前所有活跃事务（还未提交的事务）的一个集合，ReadView数据结构决定了不同事务隔离级别下，数据的可见性。 up_limit_id：最先开始的事务，该SQL启动时，当前事务链表中最小的事务id编号，也就是当前系统中创建最早但还未提交的事务low_limit_id：最后开始的事务，该SQL启动时，当前事务链表中最大的事务id编号，也就是最近创建的除自身以外最大事务编号m_ids：当前活跃事务ID列表，所有事务链表中事务的id集合注：ID越小，事务开始的越早；ID越大，事务开始的越晚 1、下面所说的db_trx_id，是来自于数据行中的db_trx_id字段，并非开启了一个事务分配的ID，分配的事务ID只有操作了数据行，才会更新数据行中的db_trx_id字段2、ReadView是与SQL绑定的，而并不是事务，所以即使在同一个事务中，每次SQL启动时构造的ReadView的up_trx_id和low_trx_id也都是不一样的up_limit_id表示“低水位”，即当时活跃事务列表的最小事务id（最早创建的事务），如果读取出来的数据行上的的db_trx_id小于up_limit_id，则说明这条记录的最后修改在ReadView创建之前，因此这条记录可以被看见。 low_limit_id表示“高水位”，即当前活跃事务的最大id（最晚创建的事务），如果读取出来的数据行上的的db_trx_id大于low_limit_id，则说明这条记录的最后修改在ReadView创建之后，因此这条记录肯定不可以被看见。 如果读取出来的数据行上的的db_trx_id在low_limit_id和up_limit_id之间，则查找该数据上的db_trx_id是否在ReadView的m_ids列表中： 如果存在，则表示这条记录的最后修改是在ReadView创建之时，被另外一个活跃事务所修改，所以这条记录也不可以被看见。如果不存在，则表示这条记录的最后修改在ReadView创建之前，所以可以看到。 REPEATABLE READ下的ReadView生成每个事务首次执行SELECT语句时，会将当前系统所有活跃事务拷贝到一个列表中生成ReadView。 每个事务后续的SELECT操作复用其之前生成的ReadView。 UPDATE,DELETE,INSERT对一致性读snapshot无影响。 示例：事务A，B同时操作同一行数据 若事务A的第一个SELECT在事务B提交之前进行，则即使事务B修改记录后先于事务A进行提交，事务A后续的SELECT操作也无法读到事务B修改后的数据。若事务A的第一个SELECT在事务B修改数据并提交事务之后，则事务A能读到事务B的修改。针对RR隔离级别，在第一次创建ReadView后，这个ReadView就会一直持续到事务结束，也就是说在事务执行过程中，数据的可见性不会变，所以在事务内部不会出现不一致的情况。 READ COMMITED下的ReadView生成每次SELECT执行，都会重新将当前系统中的所有活跃事务拷贝到一个列表中生成ReadView。 针对RC隔离级别，事务中的每个查询语句都单独构建一个ReadView，所以如果两个查询之间有事务提交了，两个查询读出来的结果就不一样。","link":"/2021/08/01/mysql/mvcc/"},{"title":"windows安装mysql zip包","text":"1 . 先解压，修改my_default.ini 文件里 basedir 和 datadir 的路径 2 . 修改环境变量，将mysql的bin添加到path， 3 . 以管理员身份打开cmd 窗口 执行mysqld -install 4 . 将my_default.ini 复制一份到 bin ，改为my.ini ，执行 mysqld –initialize –user=mysql –console 则生成data文件夹，并生成root 账号的密码！！ 5 . 命令行下执行 net start mysql 开启mysql服务 6 . mysql -u root -p 登录 输入上图中的密码，即可登陆 7 . 修改root密码 SET PASSWORD FOR ‘root’@’localhost’ = PASSWORD(‘root’); ok","link":"/2018/04/16/mysql/windowsmysql/"},{"title":"mysql技术内幕第一章、mysql体系结构和存储引擎","text":"Mysql体系结构# MySQL由以下几部分组成： 连接池组件。 管理服务和工具组件。 SQL接口组件。 查询分析器组件。 优化器组件。 缓冲（Cache）组件。 插件式存储引擎。 物理文件。 从图1-1还可以看出，MySQL区别于其他数据库的最重要的特点就是其插件式的表存储引擎。MySQL插件式的存储引擎架构提供了一系列标准的管 理和服务支持，这些标准与存储引擎本身无关，可能是每个数据库系统本身都必需的，如SQL分析器和优化器等，而存储引擎是底层物理结构的实现，每个存储引 擎开发者都可以按照自己的意愿来进行开发。 注意：存储引擎是基于表的，而不是数据库。请牢牢记住图1-1所示的MySQL体系结构图，它对于你以后深入了解MySQL有极大的帮助 存储引擎比较#InnoDB存储引擎#InnoDB存储引擎支持事务，主要面向在线事务处理（OLTP）方面的应用。其特点是行锁设计、支持外键，并支持类似于Oracle的非锁定读，即默认情况下读取操作不会产生锁。MySQL 在Windows版本下的InnoDB是默认的存储引擎，同时InnoDB默认地被包含在所有的MySQL二进制发布版本中。 InnoDB存储引擎将数据放在一个逻辑的表空间中，这个表空间就像黑盒一样由InnoDB自身进行管理。从MySQL 4.1（包括4.1）版本开始，它可以将每个InnoDB存储引擎的表单独存放到一个独立的ibd文件中。与Oracle类似，InnoDB存储引擎同样 可以使用裸设备（row disk）来建立其表空间。InnoDB通过使用多版本并发控制（MVCC）来获得高并发性，并且实现了SQL标准的4种隔离级别，默认为REPEATABLE级别。同时使 用一种被称为next-key locking的策略来避免幻读（phantom）现象的产生。除此之外，InnoDB储存引擎还提供了插入缓冲（insert buffer）、二次写（double write）、自适应哈希索引（adaptive hash index）、预读（read ahead）等高性能和高可用的功能。对于表中数据的存储，InnoDB存储引擎采用了聚集（clustered）的方式，这种方式类似于Oracle的索引聚集表（index organized table，IOT）。每张表的存储都按主键的顺序存放，如果没有显式地在表定义时指定主键，InnoDB存储引擎会为每一行生成一个6字节的 ROWID，并以此作为主键。 MyISAM存储引擎#MyISAM存储引擎是MySQL官方提供的存储引擎。其特点是不支持事务、表锁和全文索引，对于一些OLAP（Online Analytical Processing，在线分析处理）操作速度快。除Windows版本外，是所有MySQL版本默认的存储引擎。MyISAM存储引擎表由MYD和MYI组成，MYD用来存放数据文件，MYI用来存放索引文件。可以通过使用myisampack工具来进一步 压缩数据文件，因为myisampack工具使用赫夫曼（Huffman）编码静态算法来压缩数据，因此使用myisampack工具压缩后的表是只读 的，当然你也可以通过myisampack来解压数据文件。在MySQL 5.0版本之前，MyISAM默认支持的表大小为4G，如果需要支持大于4G的MyISAM表时，则需要制定MAX_ROWS和 AVG_ROW_LENGTH属性。从MySQL 5.0版本开始，MyISAM默认支持256T的单表数据，这足够满足一般应用的需求。注意：对于MyISAM存储引擎表，MySQL数据库只缓存其索引文件，数据文件的缓存交由操作系统本身来完成，这与其他使用LRU算法缓存数据 的大部分数据库大不相同。此外，在MySQL 5.1.23版本之前，无论是在32位还是64位操作系统环境下，缓存索引的缓冲区最大只能设置为4G。在之后的版本中，64位系统可以支持大于4G的索 引缓冲区","link":"/2018/05/21/mysql/mysql技术内幕第一章/"},{"title":"undolog、redolog、binlog的用处","text":"总结：binlog 一致性。用于主从复制和数据恢复redolog 保证持久性。log用于保证持久化，恢复在内存更新后，还没来得及刷到磁盘的数据undolog 原子性。用于实现事务回滚和mvcc多版本并发控制 binlog（逻辑日志）#一致性定义：记录数据表结构和数据变更的二进制文件 redolog（物理日志）#持久性mysql不能每更新一条数据，就持久化到磁盘，因为会带来严重性能问题。所以是先更新到缓存，再特定时机下，再刷新到磁盘，为了防止内存数据丢失，会使用redolog作为事务日志，在内存更新完成后，写入redolog buffer，然后数据会写入到redolog file磁盘 redolog buffer写入磁盘的模式： 0（延迟写）每秒刷新写入磁盘，若系统崩溃，出现1s数据丢失 1（实时写）每次提交都会写入磁盘， 不会有数据丢失，但io性能差 2（实时写，延迟刷新）每次提交到os buffer, 然后每秒将os buffer日志写到磁盘 注：redolog的大小是固定的，可能被覆盖 undolog（逻辑日志）#原子性undolog存储数据的逻辑变化日志，参考：https://blog.csdn.net/Huangjiazhen711/article/details/127900821 多版本并发控制mvcc，MVCC在mysql中的实现依赖的是undo log与read viewundo log记录某行数据的多个版本的数据；read view用来判断当前版本数据的可见性。read view可以用来判断可以看到哪些事务。根据他保存的创建时活跃事务id列表，创建时的最大事务id，创建时的最小事务id。 RC在每次语句执行，都会重新创建一份ReadViewRR下，事务开始创建ReadView，一直到事务结束 undo log的删除。当该undolog没有出现在其他事务的readview时，说明事务已提交，且没有其他事务依赖，innodb后台的清除purge线程会遍历删除undolog。聚簇索引中deleted标识为1的也会被删除。均为异步操作。 注：事务隔离性是通过mvcc+排他锁实现的","link":"/2023/06/08/mysql/undo/"},{"title":"innodb事务隔离级别","text":"一、定义 二、什么是快照读，什么是当前读 三、rr级别下mvcc解决不可重复读和快照读之间的幻读 四、rr级别下next-key锁解决当前读之间的幻读 五、rr和rc区别 六、todo学习 参考文章 一、定义#未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他会话中未提交事务修改的数据提交读(Read Committed)：只能读取到已经提交的数据. 可以阻止脏读，但是可能发生幻读或不可重复读可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的. 可以阻止脏读和不可重复读，幻读通过mvcc解决了快照读，next-key锁解决了当前读. mysql默认隔离级别.串行读(Serializable)：读加共享锁，写加排他锁，读写互斥. 可重复读指的是同一行在同一个事务下无论怎么读取都是同一个结果(除非自己把它改了). 幻读指的是在同一事务下，连续执行两次同样的SQL语句第二次的SQL语句可能返回之前不存在的行； 二、什么是快照读，什么是当前读#快照读：就是select 1select * from table ….; 当前读：特殊的读操作，插入/更新/删除操作，属于当前读，处理的都是当前的数据，需要加锁。 12345select * from table where ? lock in share mode;select * from table where ? for update;insert;update ;delete; 事务的隔离级别实际上都是定义了当前读的级别，MySQL为了减少锁处理（包括等待其它锁）的时间，提升并发能力，引入了快照读的概念，使得select不用加锁。而update、insert这些“当前读”，就需要另外的模块来解决了 三、rr级别下mvcc解决不可重复读和快照读之间的幻读#一致非锁定读，也可以称为快照读，即普通SELECT语句，既然是快照读，故 SELECT 的时候，会生成一个快照。 生成快照的时机：事务中第一次调用SELECT语句的时候才会生成快照，在此之前事务中执行的update、insert、delete操作都不会生成快照 REPEATED READ 隔离级别下，快照会在事务中第一次SELECT语句执行时生成，只有在本事务中对数据进行更改才会更新快照，因此，只有第一次SELECT之前其它已提交事务所作的更改你可以看到，但是如果已执行了SELECT，那么其它事务commit数据，你SELECT是看不到的。 四、rr级别下next-key锁解决当前读之间的幻读#在当前读下rr级别使用了next-key锁（临键锁），临键锁包括行锁+间隙锁， 来避免两个当前读时有其它事务插入数据，所以当前读使用next-key锁解决的幻读。 最后备注下：如果是先快照读再当前读，影响行数不一致是否属于幻读，是有争议的但大多认为并不是幻读。 五、rr和rc区别#rc级别下的mvcc总是读取数据行的最新快照，而rr级别下的mvcc，会在事务第一次select的时候，为数据行生成一个快照，后面每次都读这个快照，除非自己更新 如果问，rr为什么是默认的隔离级别，就说rr相比rc来说没有不可重复读和幻读问题. 后面再深入研究 六、todo学习# rr为什么是默认的隔离级别 mvcc在rc隔离级别下，读最新的快照，为什么不直接读行记录呢，rc级别是怎么解决脏读的 参考文章#https://tech.meituan.com/2014/08/20/innodb-lock.html","link":"/2020/03/09/mysql/事务隔离级别2/"},{"title":"innodb事务隔离级别、MVCC","text":"隔离级别# 未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他会话中未提交事务修改的数据 提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读) 可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞 MVCC#InnoDB是一个多版本的存储引擎：为了支持事务的一些特性诸如并发和回滚，它保持着被修改行的旧版本信息。这些信息被存储在一个被叫做回滚段(rollback segment)的表空间中。InnoDB在回滚段中用这些信息来执行undo操作，以此支持事务回滚。它也用这些信息来构造行的更早的版本，以此支持一致性读（快照读）。 在内部，InnoDB为数据库中存储的每一行添加三个隐藏字段。 DB_TRX_ID：表明插入或者修改这一行的最后一个事务的事务标识符。如何查看行事务ID DB_ROLL_PTR：指向回滚段中的一个undo log记录，如果行被修改了，那么这个undo log记录包含的信息必须先于行修改被重新修改。 DB_ROW_ID：单调递增的行ID。如果InnoDB自动生成了一个聚集索引，那么这个索引包含行ID值，否则DB_ROW_ID列不会出现在任何索引中。 锁类型#共享锁（读锁，S锁）：若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放S锁。 排他锁（写锁，X锁）：若事务T对数据对象A加上X锁，则只允许T读取和修改A，其他事务不能再对A加作何类型的锁，直到T释放A上的X锁。 意向共享锁（IS锁）：事务T在对表中数据对象加S锁前，首先需要对该表加IS（或更强的IX）锁。 意向排他锁（IX锁）：事务T在对表中的数据对象加X锁前，首先需要对该表加IX锁。 意向锁补充# InnoDB 支持多粒度锁，特定场景下，行级锁可以与表级锁共存。 意向锁之间互不排斥，但除了 IS 与 S 兼容外，意向锁会与 共享锁 / 排他锁 互斥。 IX，IS是表级锁，不会和行级的X，S锁发生冲突。只会和表级的X，S发生冲突。 意向锁在保证并发性的前提下，实现了行锁和表锁共存且满足事务隔离性的要求。 2pl 两阶段锁#两段锁协议，先随便加，最后commit才能一起释放. GAP锁有何用#其实这个多出来的GAP锁，就是RR隔离级别，相对于RC隔离级别，不会出现幻读的关键。 确实，GAP锁锁住的位置，也不是记录本身，而是两条记录之间的GAP。 所谓幻读，就是同一个事务，连续做两次当前读 (例如：select * from t1 where id = 10 for update;)，那么这两次当前读返回的是完全相同的记录 (记录数量一致，记录本身也一致)，第二次的当前读，不会比第一次返回更多的记录 (幻象)。 如何保证两次当前读返回一致的记录，那就需要在第一次当前读与第二次当前读之间，其他的事务不会插入新的满足条件的记录并提交。为了实现这个功能，GAP锁应运而生 快照读 &amp; 当前读#快照读：就是select 1select * from table ….; 当前读：特殊的读操作，插入/更新/删除操作，属于当前读，处理的都是当前的数据，需要加锁。 12345select * from table where ? lock in share mode;select * from table where ? for update;insert;update ;delete; 聊天讨论#全快照、全当前，不幻读， 先快照，再当前，幻读 「 球球: 其实产生幻读的原因，就是以为读走了mvcc的副本， 」 读如果也加gap锁，就真的不会幻读了，但代价太大 「 宏伟: 张三账户余额有10000元；要转账给李四9000元，转给王五5000元；这两次转账肯定有一次因余额不足转账失败；如果在 rr 下，可重复读， 两次update 张三都会成功？ 」 这个如果两个事务并发，都先读的1w元快照读，然后第1个事务直接update张三减钱， commit， 第2个事务 接着update张三减钱，都会成功，除非1 用数据库乐观锁2 自己搞个分布式锁，将读写操作原子化3 用kafka让同一用户操作串行化 敏: 交易相关的就不要快照读了, 交易要算钱，select的时候就要锁，不然这条数据之后未必可用 总结#RR级别下，通过MVCC, 解决了两个快照读的幻读问题，通过next-key锁，解决了两个当前读的幻读问题，但是快照读后的当前读是会幻读的.","link":"/2019/07/09/mysql/隔离级别/"},{"title":"BIO NIO AIO 阻塞 非阻塞","text":"BIO:同步阻塞IO（面向流的）#特点：一个连接建立一个线程，连接如果没有IO请求时，则会浪费线程资源开销，可以通过线程池技术来改善 适用场景：连接数小，并发数小，架构固定（java1.4之前唯一的IO） NIO：同步非阻塞（面向Buffer的）#特点：客户的发送的连接请求会注册到多路复用器上，多路复用器轮询到连接存在有效请求时才会启动一个线程来进行处理适用场景：连接数目多，且连接比较短的架构，比如聊天服务器（java1.4开始支持） AIO：异步非阻塞#特点：针对客户端连接发出的IO请求，会由OS先完成IO操作后，在通知服务器启动线程进行处理适用场景：连接数目多，连接比较长，比如相册服务器，充分调用OS参与并发操作（java1.7开始支持） 同步、异步（关注点：消息通信机制、IO请求发送）#同步：发送一个请求后，会不断的去轮询、等待请求结果返回后再发送下一个请求，可以避免死锁，脏读的发生 异步：发送一个请求后，不需要等待结果返回也可以发送下一个请求，可以提高效率，保证并发，OS执行完成后会通过回调函数通知应用程序获取结果 阻塞、非阻塞（关注点：程序在等待调用结果时的状态、IO操作结果获取）#阻塞：程序在等待请求结果的时候，线程会被挂起，调用线程只有在得到结果之后才会返回 非阻塞：虽然不能立马得到结果，但是该调用不会阻塞当前线程，此线程还可以干其他事 NIO IO多路复用#NIO是概念，IO多路复用是一套方案 当某个连接发送请求到服务器，服务器把这个连接请求当作一个请求“事件”，并把这个“事件”分配给相应的函数处理。我们可以把这个处理函数放到线程中去执行，执行完就把线程归还，这样一个线程就可以异步的处理多个线程 而阻塞式 I/O 的线程的大部分时间都被浪费在等待请求上了 对于同步非阻塞，一个线程可以执行多个连接中的请求，而同步阻塞则时一个线程对应一个连接，所以阻塞会很严重, 线程浪费严重","link":"/2019/07/04/netty/BIO_NIO_AIO/"},{"title":"netty模型","text":"定义#netty是一个高性能、异步事情驱动的网络通信框架NIO IO多路复用 、事情驱动模型 1.设置主从reactor模式2.指定IO类型3.指定handler4.绑定端口 netty优点# API使用简单，开发门槛低； 功能强大，预置了多种编解码功能，支持多种主流协议； 定制能力强，可以通过ChannelHandler对通信框架进行灵活地扩展； 性能高，通过与其他业界主流的NIO框架对比，Netty的综合性能最优； 成熟、稳定，Netty修复了已经发现的所有JDK NIO BUG，业务开发人员不需要再为NIO的BUG而烦恼； 社区活跃，版本迭代周期短，发现的BUG可以被及时修复，同时，更多的新功能会加入； 经历了大规模的商业应用考验，质量得到验证。在互联网、大数据、网络游戏、企业应用、电信软件等众多行业得到成功商用，证明了它已经完全能够满足不同行业的商业应用了。 高性能三要素# reactor模型 IO多路复用 协议 reactor模型#单线程模型# 多线程模型# 主从线程模型# 组件#Bootstrap/ServerBootstrap#顾名思义就是启动类，分别负责启动客户端和服务器端。这个类用来配置相关参数，比如设置EventLoopGroup，IO类型，handler等等，Netty的一切都从这里开始 EventLoopGroup#主从多线程Reactor模型，分别有两个线程池： EventLoopGroupA和EventLoopGroupB。一个用于接收请求，另一个用于处理IO操作。 一个EventLoopGroup就相当于一个线程池，而每一个EventLoop就是一个线程，当新的Channel被创建时（有新的请求进来），就会在EventLoopGroup里注册一下，同时会分配一个EventLoop给这个Channel， 从此开始直到这个Channel被销毁，这个Channel只能被它绑定的这个EventLoop执行，这也就是为什么Netty可以不用考虑并发的原因。 EventLoop是处理各个event的具体线程。除了处理IO读写等event外，EventLoop还需要进行系统任务和定时任务进行执行 Channel#Netty的Channel接口所提供的的API，大大降低了直接使用Socket类的复杂性 ChannelPipeline &amp; ChannelHander#Netty采用了一种叫做数据流（data flow）的处理机制，类似于Unix中的管道。即每一个Channel都有一个自己的ChannelPipeline，每一个pipeline里会有多个ChannelHandler。数据会像水流一样依次通过每一个handler被逐一处理。流处理是双向混合的，分为Inbound和Outbound， 分别对应request和response。 这个handler被分成两类：ChannelOutboundHandler和ChannelInboundHandler。当服务器处理进来的请求时，则只会调用实现了ChannelInboundHandler的handler；当服务器返回信息给客户端时，则只会调用实现了ChannelOutboundHandler的handler Encoders &amp; Decoders#我们在解析处理请求时通常需要对数据格式进行转换，比如把字节变成对象，或者把对象转换为字节。针对这种常见的场景，Netty提供了编码和解码的接口：MessageToByteEncoder和ByteToMessageEncoder。 其实两个抽象类分别继承了ChannelInboundHandlerAdapter和ChannelOutboundHandlerAdapter，说白了，使用起来和普通的handler没什么区别。自己写的类只要重写decode()或者encode()方法对数据进行处理即可","link":"/2019/07/09/netty/model/"},{"title":"netty服务端启动原理","text":"Netty 是一个事件驱动模式的高性能的 NIO 框架，对内封装了 Java NIO 的大量复杂且繁琐的实现细节，对外提供了高度抽象的组件和易用的 API，提供了针对市面上大部分通信协议的支持，是当下 Java 生态中最流行的远程通信框架之一。 Netty 框架本质上是对于 Java NIO 的封装，Java NIO 本质上是对于操作系统提供的 IO 多路复用功能的封装，因此其设计思路是一脉相承的，即采取了事件驱动的 Reactor 模式。 其中的 bossGroup 就是 mainReactor 的具体实现，主要用于监听服务端口，接收客户端的 TCP 连接请求。 workerGroup 就是 subReactor 的具体实现，主要用于消息的读取发送、编解码以及其他业务逻辑的处理。 它们本质上都可以视作一个线程池，里面的每个线程（NioEventLoop）都唯一绑定了一个 Java NIO 中的 Selector 对象，用于实现 IO 多路复用的功能，来监听多个（文件描述符）客户端的输入。 启动demo 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class DiscardServer { private int port; public DiscardServer(int port) { this.port = port; } public void run() throws Exception { // mainReactor(Acceptor)线程池，主要用于监听服务端口，处理客户端连接 EventLoopGroup bossGroup = new NioEventLoopGroup(); // subReactor线程池，主要用于实现对于消息的接收发送、编解码以及其他业务处理 EventLoopGroup workerGroup = new NioEventLoopGroup(); try { // Netty的启动辅助类 ServerBootstrap b = new ServerBootstrap(); // 初始化ServerBootstrap实例 b.group(bossGroup, workerGroup) // 指定Channel类型为NioServerSocketChannel .channel(NioServerSocketChannel.class) // 添加自定义Handler，会用于workerGroup中的Channel的处理 .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new DiscardServerHandler()); } }) // 添加Channel选项 .option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true); // Bind and start to accept incoming connections. // 服务端启动核心逻辑，初始化Channel并绑定指定服务端口开始监听 ChannelFuture f = b.bind(port).sync(); // Wait until the server socket is closed. // In this example, this does not happen, but you can do that to gracefully // shut down your server. f.channel().closeFuture().sync(); } finally { // 服务端关闭 workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); } } public static void main(String[] args) throws Exception { int port = 8080; if (args.length &gt; 0) { port = Integer.parseInt(args[0]); } new DiscardServer(port).run(); }} 初始化： 创建 ServerBootstrap 实例并进行初始化 启动服务： ServerBootstrap 绑定服务端口并开始监听","link":"/2021/08/23/netty/nettyrun/"},{"title":"一次线上OOM问题排查","text":"一、问题 一个查询 服务 jvm 偶现oom，容器异常退出，过会儿自动重新拉起进程，容器不变​二、时间线20210308 怀疑是cpu飙升导致观察cpu出现飙升， 通过 top 命令查到进程 pid 通过 top -H -p , 看到下图 耗cpu的线程都为GC线程，排除是cpu飙升的原因 20210311 复现oom 分析dump文件本想通过sz 将dump文件拉到本地，但太费劲了，dump文件为16G, 即使分段也十分费劲，询问基础架构同学，提供了公司的dump文件分析工具 jifajifa 一个可以快速将dump文件快速上传到云端，且在远端使用MAT进行解析的工具，非常好使将dump文件上传到S3云端，再根据返回的链接，直接跳转到jifa 平台，默认弹出刚才文件从S3导入的选择，选择导入，即会从S3导入到公司 jifa 平台。选择对应机器的dump文件，进行在线分析，加载后即可得到线上MAT分析结果从Dominator Tree中可看到有一个线程占用了96%的内存，且是线程中的一个ArrayList 占用着几乎这96%内存，点开发现全是 DotVO实体 该ArrayList 中存在 1.4 亿 个 DotVO实体 查该问题线程的堆栈，发现停在了 AssetsSecondInfoVO.result2VO 此处的逻辑为一个时间范围的中间数据补齐 看DotVO 中的时间 竟然还有50多万s 的时间。。。 查hive表数据，确实是有很大的时长的数据，比如视频时长为28s, 但是hive表中时间数据有16亿s的。。此时做中间时间补齐，则数据量会爆炸询问数仓同学，是脏数据，是个已知问题fix: 添加对下游数据正确性的校验逻辑 &amp; 数仓同学推动上报源改造","link":"/2021/03/18/online/oom1/"},{"title":"当在浏览器输入google.com回车的时候发生了什么","text":"一、解析输入 二、建立连接 三、服务端处理请求、客户端解析 当在浏览器输入google.com回车，根据github库中的分析，会发生24个过程，我们去除其中物理电路和部分前端、windows系统等步骤，将我们关心的步骤进行分析 一、解析输入# 解析获取协议、主机名、资源地址 根据协议和主机名判断文字是URL还是搜索关键字，if url: 3, if not url: 文字传给默认的搜索引擎 如果主机名部分含有非ASCII字符, 浏览器会对主机名部分使用 Punycode 编码 二、建立连接# 检查预加载 HSTS（HTTP严格传输安全）列表# 是否必须使用https请求，避免第一次非https请求 DNS查询# 查看 Chrome 缓存是否存在 调用 gethostbyname函数 是否在本地hosts文件，是 返回，否 ii 向本地DNS服务器发送请求，使用 53 端口向 DNS 服务器发送 UDP 请求包，如果响应包太大，会使用 TCP 协议，本地DNS服务器可能是在内网中，或者是在ISP的机房中 内网中的话直接ARP就可以找到MAC地址，就可以发DNS请求过去 外网ISP机房DNS服务器的话，也需ARP找到网关的MAC, 发送到网关，源MAC地址永远为客户端MAC地址，源IP通过NAT将内网IP转为外网IP加指定端口号, 目的MAC通过路由协议转为下一跳路由MAC, 目的IP为ISP外网IP, 数据包一直路由到ISP的网关，根据目的IP和端口号经过NAT转换包目的IP为内网dns ip, 通过ARP或缓存，目的mac改为dns服务器mac，发送请求至ISP dns服务器 if 本地/ISP DNS 服务器找到结果，返回结果，if not: iv if 支持转发，它会发送一个递归查询请求，可能会一层一层向高层 DNS 服务器做查询，直到查询到起始授权机构，把结果返回 也可能本身不支持转发, 或向上查询过程中某DNS服务器不支持转发，则会开始进行迭代查询，通过先后查询根、顶级、权威dns服务获取对应ip TCP封包# 当浏览器得到了目标服务器的 IP 地址，以及 URL 中给出来端口号（http 协议默认端口号是 80， https 默认端口号是 443），它会调用系统库函数 socket ，请求一个 TCP流套接字 请求首先被交给传输层，在传输层请求被封装成 TCP segment。目标端口会被加入头部，源端口会在系统内核的动态端口范围内选取 TCP segment 被送往网络层，网络层会在其中再加入一个 IP 头部，里面包含了目标服务器的IP地址以及本机的IP地址，把它封装成一个IP packet 接下来会进入链路层，链路层会在封包中加入 frame 头部，里面包含了本地内置网卡的MAC地址以及网关（本地路由器）的 MAC 地址。如果不知道网关的 MAC 地址，需进行 ARP 广播。 路由# 数据包到路由器后会先进行NAT网络地址转换，将源内网IP转为外网IP和指定端口号，目的MAC通过路由协议转为下一跳路由MAC， 源MAC和目的IP不变 通过动态路由协议转发到下一跳路由器，直到转发到目的IP对应路由器 此时会通过NAT将数据包 目的IP地址由外网ip地址转为内网ip地址，源MAC地址转为网关MAC地址，目的MAC由网关MAC转为目标服务器MAC地址，如不知道MAC地址需要进行ARP 此为一个包路由到目标机器的过程 TCP三次握手# 你好，我是A; 你好A，我是B; 你好，B; 握手过程存在封包与路由 TLS 握手# 先非对称加密，然后对称加密，通过两边都知道的随机数和最后用服务端公钥加密的pre-master随机数，生成对称密钥，实现对称加密 数字证书是用CA私钥进行数字签名，此时如果本地的CA公钥和传过来的数字证书都是假的，是否能欺骗用户，不会，CA证书会由它的上级CA给它签名，确定它的身份，层层往上签名，一直到几个全球皆知的大CA root CA, 通过层层授信，确保传过来CA证书的正确性。同时保证了传过来的公钥的正确性 开始对称加密通信 三、服务端处理请求、客户端解析# http请求处理# 服务器拆分请求： 1.HTTP 请求方法 2.域名 3. 请求路径/页面 验证其上已经配置了 google.com 的虚拟主机 验证 google.com 接受 GET 方法 验证该用户可以使用 GET 方法 务器安装了 URL 重写模块，服务器会尝试匹配重写规则 根据请求信息获取相应的响应内容，这种情况下由于访问路径是 “/“ ,会访问首页文件， 可以重写这个规则 使用指定的处理程序分析处理这个文件，假如 Google 使用 PHP，服务器会使用 PHP 解析 index 文件，并捕获输出，把 PHP 的输出结果返回给请求者 浏览器客户端解析# 解析 —— HTML，CSS，JS 渲染 —— 构建 DOM 树 -&gt; 渲染 -&gt; 布局 -&gt; 绘制 参考文献： github: https://github.com/skyline75489/what-happens-when-zh_CN 趣谈网络协议: https://pan.baidu.com/s/1CK4a_lw_cYqpMPr186vEsQ 提取码: dydr","link":"/2019/05/19/network/whathappendswhen/"},{"title":"读《自控力》","text":"前言#看了本周”李自然说”讨论学习方法，里面有一句话非常喜欢，人和人的差距大于人和猪的差距。 这句话夸张的表达了人和人的差距会有多大，人和人理解问题的深度、处事的态度、说话的逻辑和好听程度，有趣指数，相信大家都想做人上人，百里挑一的人，不止是为了获得更多的财富，更是让自己的生活满意，做事情处事不惊，游刃有余。 今天开始阅读《自控力》，不是说这一本书能带我走向人生巅峰，只希望是个好的开始。 01 意志力是什么，为什么至关重要####意志力 就是驾驭 “我不要”， “我要做”，”我想要” 这三种力量。 “我不要” : 抵制诱惑！#抵制甜甜圈，香烟，清仓大甩卖，或一夜情等等很诱人的东西，这些东西阻碍你实现你真正想要的，比如瘦身，好的肺，幸福的家庭等，如果你一面对就会无法抵抗，那就要提升意志力，提升“我不要”的能力。 这些东西可能会带来即时的快感，但只是因为真正美好的东西暂时离你远，因为时空的距离感，让你选择了当前的选项，但如果思维清晰，目标明确，就不要为眼前的小利益而放弃大目标。 比如你想换工作、换城市，考虑清楚之后，知道换了之后的结果是好的，但过程中有困难和安逸给你选，如果选了安逸，就是当前的诱惑赢了，如果选了困难，就是意志力的体现，对当前诱惑说出 “我不要” ！ “我要做” ：今日事今日毕 ！#“明日复明日”，拖延症晚期患者有些事情可能拖到下辈子再做，是这部分意志力薄弱，我理解不可能每天真毕，但“做” 和 “拖”的差距是很大的，是“我要做”意志力的体现。 “我想要”： 真正要的是什么！#当我们在冲动的时候有时会觉得这就是自己想要的，想要玩游戏、想要喝酒、巧克力蛋糕、骂人等等，但一定得想清楚，你真正要的是什么样的身材，什么样的素养，什么样的生活，是否希望苗条、升职加薪、家庭美满，是否吃”巧克力蛋糕”, 吃多少，要在关键时刻遏制住一时冲动，明确自己的目标，强大的目标明确能力，是“我想要”意志力的体现。 小总结#个人理解意志力的体现肯定不是要让我们当机器人或当狗（加班狗、奋斗狗），而是像某口号一样，集中力量办大事，只是集中的是自己的力量，办的是“我想要”的事。 两个自我#大脑中有两个部分，一部分是控制自己，一部分是冲动的自己。冲动为原始的冲动，我们的本能; 控制自己的就是我们的前额皮质。 “两个自我发生分歧的时候，总会有一方击败另一方。决定放弃的一方并没有做错，只是双方觉得重要的东西不同而已。” 原始的本能冲动是我们必不可少的，没有欲望，人就会变得沮丧，没有恐惧，就没法保护自己，没有厌恶，就没法提高自己，我们不是要消灭冲动的自己，而是要学会利用冲动的自己，换句话就是在合适的时候冲动，合适的时候控制。 原始的冲动带着自己进步，而当冲动要带我们走向错误的时候，控制自己的能力需要体现。 自我意识#自我意识体现在做决定的时候，意识到要做自己的选择，生活才是自己的。 这里重点是意识到自己可以做的选择。一件事，我根据自己的想法做出选择，是自我意识，而我如果没思考，下意识走了简单舒适的选择时，就是自我意识的缺失，一种随波逐流，这样选的结果不一定不好，但不会一直是自己想要的。 做一个有自我的人 冥想#冥想通过坐着闭眼专注于”呼“ ”吸“， 锻炼自己的控制能力，注意力集中能力，意志力。 冥想我相信对应现实中的注意力集中能力，自控能力都会有一定提升。 今天进行了人生第一次冥想，虽然大部分时间都无法专注于呼吸，但我看到了挑战，当我能完全专注于呼吸的时候，那我的集中注意力的能力就会变得很强。 mark一篇完整冥想步骤文章 https://mp.weixin.qq.com/s/2nV2u66ScuLJEHEXcrHkMQ","link":"/2019/07/14/read/controll/"},{"title":"dns解析","text":"参考文献： https://www.zhihu.com/question/23042131/answer/66571369 https://segmentfault.com/a/1190000004127680 dns解析的过程可能是先递归再迭代，也可能是全部的递归。 本来的递归，说的是从客户端到本机的过程，一机一机的，就像层层方法调用再返回，泽旋说的应该是我图里的设置转发，本机转发到上一层，变成先递归到本机上一层，再迭代 默认都会转发，如果向上转发的过程中有，就返回，不支持，就开始迭代，支持但没有，就一直到根 只有一套，先递归再迭代，如果所有的dns服务器都设置了转发，就一直先向上转发到根，过程中可能就找到返回了，如果到根再往下找，如果过程中有dns服务器不支持转发，那这个服务器就开始迭代，直接从根往下，就相当于是先从客户端到这个不支持的dns服务器是递归。这个dns服务器的查找是迭代，如果一直都支持转发，就是全部的递归。 参考文献： https://www.zhihu.com/question/23042131/answer/66571369 https://segmentfault.com/a/1190000004127680 dns解析的过程可能是先递归再迭代，也可能是全部的递归。 本来的递归，说的是从客户端到本机的过程，一机一机的，就像层层方法调用再返回，泽旋说的应该是我图里的设置转发，本机转发到上一层，变成先递归到本机上一层，再迭代 默认都会转发，如果向上转发的过程中有，就返回，不支持，就开始迭代，支持但没有，就一直到根 只有一套，先递归再迭代，如果所有的dns服务器都设置了转发，就一直先向上转发到根，过程中可能就找到返回了，如果到根再往下找，如果过程中有dns服务器不支持转发，那这个服务器就开始迭代，直接从根往下，就相当于是先从客户端到这个不支持的dns服务器是递归。这个dns服务器的查找是迭代，如果一直都支持转发，就是全部的递归。","link":"/2019/05/14/network/dns/"},{"title":"tair & redis 的选择","text":"tair &amp; redis 的选择# 延迟敏感程度, 延迟敏感，说什么也得redis 数据量大的话，数据量超过100GB全内存太浪费资源，延迟没有那么敏感，使用tair 使用复杂数据结构 redis 容忍数据丢失","link":"/2019/07/09/redis/与tair选择/"},{"title":"redis单线程还这么快","text":"为什么Redis使用单线程模型会达到每秒万级别的处理能力呢？可以将其归结为三点使Redis具有很高的吞吐量?#1. 纯内存访问#Redis将所有数据放在内存中，内存的响应时长大约为100纳秒，这是Redis达到每秒万级别访问的重要基础。 纯内存数据库，如果只是简单的 key-value，内存不是瓶颈。一般情况下，hash 查找可以达到每秒数百万次的数量级。瓶颈在于网络 IO 上。每次请求需要通过网络把请求发送到 redis 所在的机器，然后等待 redis 返回数据。时间大部分消耗在网络传输中。如果把 redis 和客户端放在同一台机器，网络延迟会更小，一般情况下可以打到 60000 次每秒甚至更高，取决于机器性能。 2. I/O多路复用、事件驱动模型#旨在解决IO的问题。多路I/O复用模型是非阻塞IO，内部实现采用epoll和自己实现的事件分离框架。 其利用select、poll、epoll 可以同时检测多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。 “多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗）。 总结就是Redis使用epoll作为I/O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll中的连接、读写、关闭都转换为事件，不在网络I/O上浪费过多的时间，如下图所示。 3. 单线程避免了线程切换和竞态产生的消耗。#线程模型#主线程# 其它# Redis会fork得到的子进程，用来处理RDB持久化以及AOF持久化等任务 一组异步任务处理线程，即Redis异步化组件——BIO组件 BIO组件目前包括三个线程，分别处理三种类型的任务：1）文件句柄关闭任务2）AOF持久化任务3）空间懒释放 持久化#Redis 提供了两种持久化策略 RDB 持久化机制，会在一段时间内生成指定时间点的数据集快照(snapshot) AOF 持久化机制，记录 server 端收到的每一条写命令，当 server 重启时会进行重放以此来重建之前的数据集。AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加(append)到文件的末尾。 Redis 还可以在后台对 AOF 文件进行重写(rewrite) ，使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小。 如果你仅使用 Redis 作为缓存加速访问，你可以关闭这两个持久化设置 你也可以同时开启这两个持久化设置，但是在这种情况下，Redis 重启时会使用 AOF 文件来重建数据集，因为 AOF 文件保存的数据往往更加完整 单线程利弊#单线程模型能带来几个好处：第一，单线程可以简化数据结构和算法的实现。并发数据结构实现不但困难而且开发测试比较麻烦。第二，单线程避免了线程切换和竞态产生的消耗，对于服务端开发来说，锁和线程切换通常是性能杀手。 但是单线程会有一个问题：对于每个命令的执行时间是有要求的。如果某个命令执行过长，会造成其他命令的阻塞，对于Redis这种高性能的服务来说是致命的，所以Redis是面向快速执行场景的数据库。","link":"/2019/07/09/redis/单线程还快/"},{"title":"缓存穿透、击穿、雪崩","text":"缓存穿透#定义: 访问一个不存在的key，缓存不起作用，请求会穿透到DB，流量大时DB会挂掉。 解决方案： 缓存空值 （值少时） 布隆过滤器， 特性: 没有的肯定没有，有的不一定有 缓存击穿#定义：并发性,一个存在的key，在缓存过期的一刻，同时有大量的并发请求，这些请求都会击穿到DB，造成瞬时DB请求量大、压力骤增。 解决方案： 分布式锁，在访问key之前，采用分布式锁SETNX（set if not exists）来设置另一个短期key来锁住当前key的访问，访问结束再删除该短期key 缓存雪崩#定义：大量的key设置了相同的过期时间，或者某台服务器宕机，导致大量缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。 解决方案： 将key的过期时间设置时添加一个随机时间，分散过期时间 如果是热点key，可以加分布式锁，减少并发量 二级缓存（本地缓存），减少db压力","link":"/2019/11/18/redis/缓存雪崩等/"},{"title":"pageHelper-springboot","text":"springboot Mybatis 数据库分页获取 ，使用pageHelper插件 maven#123456&lt;!--pagehelper--&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt;&lt;/dependency&gt; 引用此依赖可能会与其它springboot依赖冲突，此时可手动去除其它依赖 1234compile ('com.github.pagehelper:pagehelper-spring-boot-starter:1.2.5') { exclude group: 'org.springframework.boot', module: '' exclude group: 'org.mybatis.spring.boot', module: ''} application.properties#12345#pagehelper分页插件配置pagehelper.helperDialect=mysqlpagehelper.reasonable=truepagehelper.supportMethodsArguments=truepagehelper.params=count=countSql 调用#12PageHelper.startPage(pageNum, pageSize);mapper.loadAll();","link":"/2018/02/06/springboot/pageHelper/"},{"title":"rss订阅","text":"使用 feedly 订阅 rss，实现多设备同步 教程：https://techmoon.xyz/feedly/ 目前导出的我的订阅源, Feedly订阅.opml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;opml version=\"2.0\"&gt;&lt;head&gt;&lt;title&gt;Feedly订阅&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;outline title=\"NBA\" text=\"NBA\"&gt;&lt;outline text=\"千年孤寂 的 Youtube 视频\" title=\"千年孤寂 的 Youtube 视频\" xmlUrl=\"https://rsshub.app/youtube/channel/UC6QUkl7S6AYwkpQFhmdFIoQ\" type=\"rss\" htmlUrl=\"https://www.youtube.com/channel/UC6QUkl7S6AYwkpQFhmdFIoQ\" /&gt;&lt;outline htmlUrl=\"https://space.bilibili.com/184687394/#/article\" title=\"听说不怕肚子疼 的 bilibili 专栏\" type=\"rss\" text=\"听说不怕肚子疼 的 bilibili 专栏\" xmlUrl=\"https://rsshub.app/bilibili/user/article/184687394\" /&gt;&lt;/outline&gt;&lt;outline text=\"产品\" title=\"产品\"&gt;&lt;outline title=\"李自然说 的 bilibili 空间\" xmlUrl=\"https://rsshub.app/bilibili/user/video/39089748\" type=\"rss\" htmlUrl=\"https://space.bilibili.com/39089748\" text=\"李自然说 的 bilibili 空间\" /&gt;&lt;outline htmlUrl=\"https://post.smzdm.com/hot_7\" type=\"rss\" xmlUrl=\"https://rsshub.app/smzdm/haowen/7\" text=\"周热门-什么值得买好文\" title=\"周热门-什么值得买好文\" /&gt;&lt;outline xmlUrl=\"http://fz0512.com/feed\" text=\"最好金龟换酒\" title=\"最好金龟换酒\" htmlUrl=\"http://fz0512.com\" type=\"rss\" /&gt;&lt;outline title=\"少数派\" text=\"少数派\" htmlUrl=\"https://sspai.com\" xmlUrl=\"http://sspai.com/feed\" type=\"rss\" /&gt;&lt;outline text=\"V2EX-最热主题\" xmlUrl=\"https://rsshub.app/v2ex/topics/hot\" title=\"V2EX-最热主题\" type=\"rss\" htmlUrl=\"https://www.v2ex.com/\" /&gt;&lt;outline title=\"微信公众号 - 一本黑\" text=\"微信公众号 - 一本黑\" xmlUrl=\"https://rsshub.app/wechat/csm/darkinsider\" type=\"rss\" htmlUrl=\"https://chuansongme.com/account/darkinsider\" /&gt;&lt;/outline&gt;&lt;outline text=\"图片\" title=\"图片\"&gt;&lt;outline title=\"国家地理每日一图\" text=\"国家地理每日一图\" type=\"rss\" htmlUrl=\"https://www.nationalgeographic.com\" xmlUrl=\"https://feedx.co/rss/nationalgeodayphoto.xml\" /&gt;&lt;/outline&gt;&lt;outline title=\"好友\" text=\"好友\"&gt;&lt;outline title=\"大菜猫\" htmlUrl=\"https://www.techwei.cn/\" text=\"大菜猫\" xmlUrl=\"https://techwei.cn/atom.xml\" type=\"rss\" /&gt;&lt;outline htmlUrl=\"https://jacobchang.cn/\" text=\"黄小豆的博客\" title=\"黄小豆的博客\" type=\"rss\" xmlUrl=\"https://jacobchang.cn/atom.xml\" /&gt;&lt;outline xmlUrl=\"https://rsshub.app/bilibili/user/video/11036610\" text=\"爱浪的黄小豆 的 bilibili 空间\" type=\"rss\" title=\"爱浪的黄小豆 的 bilibili 空间\" htmlUrl=\"https://space.bilibili.com/11036610\" /&gt;&lt;outline htmlUrl=\"https://www.yuanqiongqiong.cn/\" title=\"袁琼琼的博客\" xmlUrl=\"http://yuanqiongqiong.cn/atom.xml\" text=\"袁琼琼的博客\" type=\"rss\" /&gt;&lt;/outline&gt;&lt;outline text=\"技术\" title=\"技术\"&gt;&lt;outline xmlUrl=\"https://rsshub.app/juejin/category/backend\" type=\"rss\" text=\"掘金后端\" title=\"掘金后端\" htmlUrl=\"https://juejin.im/welcome/backend\" /&gt;&lt;outline type=\"rss\" text=\"美团技术团队\" htmlUrl=\"https://tech.meituan.com/feed/\" xmlUrl=\"https://rsshub.app/meituan/tech/home\" title=\"美团技术团队\" /&gt;&lt;outline htmlUrl=\"http://www.ruanyifeng.com/blog/\" xmlUrl=\"http://www.ruanyifeng.com/blog/atom.xml\" title=\"阮一峰的网络日志\" type=\"rss\" text=\"阮一峰的网络日志\" /&gt;&lt;outline htmlUrl=\"https://chuansongme.com/account/importnew\" type=\"rss\" xmlUrl=\"https://rsshub.app/wechat/csm/importnew\" text=\"微信公众号 - ImportNew\" title=\"微信公众号 - ImportNew\" /&gt;&lt;outline title=\"微信公众号 - 一本黑\" type=\"rss\" text=\"微信公众号 - 一本黑\" htmlUrl=\"https://chuansongme.com/account/darkinsider\" xmlUrl=\"https://rsshub.app/wechat/csm/darkinsider\" /&gt;&lt;/outline&gt;&lt;outline text=\"新闻\" title=\"新闻\"&gt;&lt;outline xmlUrl=\"https://rsshub.app/gov/zhengce/zuixin\" type=\"rss\" text=\"最新政策 - 中国政府网\" title=\"最新政策 - 中国政府网\" htmlUrl=\"http://www.gov.cn/zhengce/zuixin.htm\" /&gt;&lt;/outline&gt;&lt;outline text=\"生活\" title=\"生活\"&gt;&lt;outline text=\"美国日记\" title=\"美国日记\" type=\"rss\" htmlUrl=\"http://cn.derekyang.us\" xmlUrl=\"http://cn.derekyang.us/?feed=rss2\" /&gt;&lt;outline text=\"人生不过如此\" htmlUrl=\"http://nana.blog.paowang.net\" title=\"人生不过如此\" xmlUrl=\"http://nana.blog.paowang.net/feed/\" type=\"rss\" /&gt;&lt;/outline&gt;&lt;outline title=\"电影\" text=\"电影\"&gt;&lt;outline htmlUrl=\"https://www.douban.com\" type=\"rss\" xmlUrl=\"https://feedx.co/rss/doubanmvweek.xml\" text=\"豆瓣电影本周口碑榜\" title=\"豆瓣电影本周口碑榜\" /&gt;&lt;outline text=\"MovieTalk-电影七日谈 的 bilibili 空间\" title=\"MovieTalk-电影七日谈 的 bilibili 空间\" xmlUrl=\"https://rsshub.app/bilibili/user/video/10869763\" htmlUrl=\"https://space.bilibili.com/10869763\" type=\"rss\" /&gt;&lt;/outline&gt;&lt;outline title=\"艺术\" text=\"艺术\"&gt;&lt;outline type=\"rss\" htmlUrl=\"http://bing.com\" text=\"必应今日美图\" title=\"必应今日美图\" xmlUrl=\"https://feedx.co/rss/bingwallpaper.xml\" /&gt;&lt;/outline&gt;&lt;/body&gt;&lt;/opml&gt;&lt;/opml&gt;","link":"/2019/08/31/rss/rss/"},{"title":"springboot启动原理","text":"一句话#springboot在启动时除了spring context容器启动的流程，还加入了通过spi实现的根据依赖自动装配的机制。springboot容器启动的流程，先初始化事件监听器，加载环境信息，创建applicationContext容器，执行applicationInitializer的initialize方法，在容器refresh时，会通过spi机制获取到所有的autoConfiguration类（解析spring.factotries文件）并加载配置类中相关bean注入context容器，完成自动装配。 细分原理#应用启动，容器初始化#1、通过spi加载所有的springApplicationRunListener，在后续各个启动步骤中发消息2、创建环境Environment，加载属性文件配置、加载命令行参数等启动时所需的配置信息3、创建ApplicationContext,将环境Environment设置给context4、通过spi加载所有的applicationInitializer并调用其initialize方法5、【核心】将spi拿到的EnableAutoConfiguration配置类的所有bean加载到已创建好的ioc容器6、调用applicationContext的refresh方法，完成ioc容器可用 问题1：创建的环境Environment里都有什么？加载属性文件配置、加载命令行参数等启动时所需的配置信息 问题2：spi拿到全部EnableAutoConfiguration类的具体入口？refreshContext方法，bean实例化之前，执行AutoConfigurationImportSelector的selectImports方法，返回要实例化的类信息列表。 问题3：applicationContext的refresh方法主要逻辑？初始化环境、设置类加载器 -&gt; 解析加载BeanDefinition对象(应该是这里拿到的全部的EnableAutoConfiguration类) -&gt; 将BeanDefinition对象注册到BeanFactory -&gt; 实例化非懒加载的单例Bean -&gt; 注册所有BeanPostProcessor到BeanFactory中 -&gt; 初始化剩余非懒加载的Bean初始化 -&gt; 完成刷新操作，发布容器事件 -&gt; 返回刷新后的BeanFactory 自动装配#SPI(service provider interface), 定义接口后，通过读取文件配置的方式加载实现类。关键注解:@EnableAutoConfiguration, 借助@Import，SpringFactoriesLoader, 把所有spring.factories文件配置的@Configuration配置类找到并实例化，将其中bean加载到ioc容器，即实现了自动装配。","link":"/2023/06/10/springboot/springboot启动流程/"},{"title":"spring架构","text":"","link":"/2020/08/14/spring/springioc初始化/"},{"title":"mac下安装配置storm","text":"装了一天多，才装好。。主要是jzmq装不好，把它依赖卸载重新安装就好了，记下来，免得以后还得再找。。笑脸 mac上安装storm ，就是安装四个东西，zookeeper, zeromq , jzmq , storm zookeeper 1brew install zookeeper 或者自己去下载tar包解压， 修改配置文件，conf/zoo_sample.cfg 1cp zoo_sample.cfg zoo.cfg // 默认配置文件 zeromq 12345brew install zeromqcd zeromq-2.1.7./configuremakesudo make install 注意加 sudo jzmq 1234567#install jzmqgit clone https://github.com/nathanmarz/jzmq.gitcd jzmq./autogen.sh./configuremakesudo make install 注意加sudo 如果autoconf automake出问题，就全卸了重新安装一次。 brew uninstall 这两个 brew install 这两个 storm 1brew install storm 配置文件： conf/storm.yaml 注意 ‘-’ 和 ‘:’ 后面都有一个空格 12345678910111213 storm.zookeeper.servers: - &quot;localhost&quot;#storm.zookeeper.port:2181 storm.local.dir: &quot;/Users/lgrcyanny/Codelab/storm/apache-storm-1.1.0/storm-local&quot;#nimbus.seeds: [&quot;host1&quot;, &quot;host2&quot;, &quot;host3&quot;]# nimbus.host: &quot;localhost&quot; supervisor.slots.ports: - 6700 - 6701 - 6702 - 6703 启动 1234567./zkServer.sh start ./storm nimbus &amp;./storm supervisor &amp;./storm ui &amp; 注意sudo 然后就可以看到如下所示：","link":"/2017/08/02/storm/mac 下安装配置 storm/"},{"title":"2018清明杭州游记","text":"作者：小菜猫共四天时间4.4~4.7花费4000 第一天乘坐G57 7:20从北京南站出发，13:02到达杭州东车站，坐1号线到住宿的酒店，住宿的地方定在1号线乔司附件，网上预订，200多一点点，休息洗漱片刻在周边吃了碗牛肉面，卤是现做的，很香天气有一些阴沉，所以穿的还比较多一些，坐地铁大概半个多小时到凤起路站下车，下车走了十几分钟到达西湖边，顺着河边往前走就到了白堤(白堤原名“白沙堤”，是将杭州市区与风景区相连的纽带，东起“断桥残雪”，经锦带桥向西，止于“平湖秋月”，长约2里。在唐即称白沙堤、沙堤，其后在宋、明又称孤山路、十锦塘。唐代诗人白居易任杭州刺史时有诗云：“最爱湖东行不足，绿杨荫里白沙堤。”即指此堤。后人为纪念这位诗人，称为白堤。) ，人不太多，一方面当天是工作日，另一方面到白堤的时候是下午五点，经过了断桥，在断桥上拍了很多照片，风景很漂亮。顺着白堤向前走，到了中山公园，公园里有孤山，没有上去，只拍了张照片，再顺着路走，最后走到了岳庙附近，没有进去看看，坐51路去吃饭了（51路是环西湖路，很方便），在美团上看到e路吃~杭帮菜，团购了两个人的套餐，有东坡肉，西湖醋鱼，叫花鸡和酸辣土豆丝和牛肉羹，最喜欢吃的是东坡肉和鱼，酸辣土豆丝清口，牛肉羹我不太喜欢，都被对面的人喝了吃饭的地方在龙翔地铁站附近，购物中心，杭州给我的感觉是这是一个有追求有品位的城市，建筑都很漂亮，有特色，广告也很赏心悦目，晚上就在购物中心里逛了逛，坐车回酒店，休息 第二天9点出发，坐车到龙翔站，出地铁时发现下雨了，提早看过天气预报，说今天会有雨，准备了雨伞，见路边有卖泰芒的，35一个，买 了一个，除了芒果一样好吃，其他的都不好，芒果汁也不好喝，冰淇淋和芒果的量也小，相比厦门30块钱的泰芒，显得太没诚意了，今天来西湖的人明显多了好多，雨下的比较大，沿着湖边走，到了观看音乐喷泉的地方，继续向前走，看到有坐船的地方，就买票上去了，坐船到小瀛洲，看三潭印月，在船上看风景时，突然想到“水光潋滟晴方好，山色空蒙雨亦奇”然后想到这就是描写西湖的时，顿时觉得这诗写的真好，岛是田字形，人比较多，又下着雨，刮着风，拍照也不是很方便，就欣赏风景吧，转完之后，从花港坐返回的船到苏堤（），在旁边买的东坡饼吃，10元一个，不建议吃，不好吃也太贵了，又买了豆腐吃15，还可以，吃完后在雷锋塔附近吃的面和馄饨，没有进去看雷峰塔，去了对面的净慈寺，10元门票，是为了看南屏晚钟的，进去发现人超级少，很安静，进门右边的殿就是放钟的地方，可以敲钟10元一次，钟真的好大，也好厚，第一次见这么大的钟，惊呆了我，去主殿看了看，很大很高的佛祖，拜了拜，主殿后面还有两个殿，还有一个净慈寺博物馆，展示了很多艺术品。。在最后一个殿上可以很清楚的看到雷峰塔，感觉也是棒棒哒，净慈寺让整个人都静了下来从净慈寺出来去了太子湾公园，之前有人推荐来这里看樱花，没找到樱花，却碰上了郁金花展览，也不错，在亭子里休息半小时后决定撤退，公交站台挤了好多人，还好有工作人员维持秩序，等了几趟车，终于等到开往龙翔站的公交，车上真暖和，外面真冷，下车之后，直奔kfc,买东西吃，吃完后决定去看电影头号玩家，定好之后，坐车去电影院，电影很棒，看完都十点了，导航到附近的地铁站，回家。今天下雨刮风，西湖边人又多，在西湖上玩的时间比较少，反而在净慈寺和太子湾的时间比较多，人少安静，旅游重要的是感受，感受到了就行，不用每个景点都要打卡去看看，反而能欣赏到不一样的美 第三天退房去客运中心坐车去乌镇，把行李箱寄存在客运中心，一个小时十分钟到达乌镇，在乌镇附近吃了碗馄饨加发糕后，进去，因为晚上就赶火车回去了，不打算去东栅了，只买了西栅的门票，进去一会看到了乌镇大剧院和木心美术馆，很不错，拍照，再往里就是江南水乡的小房子，很好看呦，就是人有点多，挤挤的，染布厂也转了转，在香市看到好肥的鱼，太肥了，去店里逛了逛，get了一个拍照利器~小帽子，沿着湖边走，找到了坐回去船的地方，60一位，坐船欣赏美景也不错，最后从入口旁边通往大剧院的一个小道到了大剧院，在周围拍照，拍的效果很好，因为风景美，人也很少，转完之后，坐车回杭州，完美","link":"/2018/04/10/travel/hz/"},{"title":"2019国庆上海苏州四日游记","text":"9月30日 外滩 很久以前羊肉串 10月01日 武康路 10月2日 蟹面 诚品书店 金鸡湖 10月3日 怡园 留园 10月4日 归途 9月30日 外滩 很久以前羊肉串#接到小菜猫，先去旅馆放下东西，直接去外滩。 南京东路上都是武警，维持秩序，看着有点厉害。我是第二次来外滩，小菜猫是第一次，还是很好看的，人很多，当晚有灯光表演，30分钟一次，我们赶上了一半。海风很舒服。整个外滩的爱国氛围也很浓厚。 去吃了很久以前羊肉串，吃到晚上12点多，羊肉真的好嫩，当面烤也是特色，配上啤酒，舒服，长肉。 10月01日 武康路#武康路没有拍什么照片，是一条安静古老的小路，下着小雨，氛围很好 在这里出发去世界上最大的星巴克 一栋星巴克，里面两层。点了一杯奶和一杯咖啡。没有太好喝但环境很好，主要咖啡☕️咱也不懂。里面有些机器在做咖啡，全流程透明化。 下午5点多了，风雨越来越大，继续出发，去豫园&amp;城隍庙，但到了之后风雨太大，也没找到豫园在哪，哈哈，就转地铁回去了。 晚上去吃了和府捞面，办了会员，赠了个虾，嚯，真虾(瞎) 10月2日 蟹面 诚品书店 金鸡湖#上午出门去吃蟹面，尴尬的是行李太沉，不该带着行李去吃，不过蟹面还是很不错，从没吃过这样式儿的，带汤的那碗很不错，人超级多，排了好一会儿 出发去苏州~ 上海到苏州也太快了，半个小时就到了，小菜猫睡了一会儿，我还没睡就到了，放下行李先奔了金鸡湖 诚品书店太安静了，没怎么拍照片，金鸡湖还是很美的，毕竟北方湖还是很少的。见到漂亮的湖，小风一吹，还是很爽。 美美哒 晚上吃了高级台湾自助火锅，到了才发现是自助，不过还是靠实力吃回来了。 10月3日 怡园 留园#上午要去留园，然后我拉肚子，耽误了坐车，就先去了怡园，没想到怡园还不错，后来发现留园反而因为人多，毫无观赏体验。 怡园 留园就不放了，人太多了，下次不去那么多人的地方了。。 10月4日 归途# 沿途的风光也不错，回家啦","link":"/2019/10/20/travel/shsz/"},{"title":"2019国庆上海苏州四日游行程计划","text":"2019 国庆上海苏州四天旅行 行程规划 2019 国庆上海苏州四天旅行#行程规划#北京前往上海 9.30 14:10 - 20:09 G141 检票口 11 9月30日#住宿 上海家荣酒店公寓(中山公园店)21点 很久以前羊肉串(中山公园店) 10月1日#上午 9点武康路上午 11点田子坊下午1点豫园&amp;城隍庙 ，明朝时期的私人花园，拥有“城市山林”、“奇秀甲于东南”两种美称，是江南园林中的一颗明珠。下午4点东方明珠南京路步行街下午7点半外滩 外滩观光隧道 10月2日#上午9点中华艺术宫上午12点退房下午14:41 上海前往苏州 14:41 - 15:15 D3010 检票口 25A住宿 骏怡连锁酒店下午4点半诚品书店金鸡湖阳澄湖大闸蟹 10月3日#上午9点拙政园苏州博物馆下午1点虎丘留园网师园夜景 10月4日#苏州前往北京 10.4 11:40 - 17:10 G128 检票口 A1","link":"/2019/09/20/travel/shszplan/"},{"title":"vim入门","text":"最常用 1234567891011121314151617181920212223242526272829- i → Insert 模式，按 ESC 回到 Normal 模式.- x → 删当前光标所在的一个字符。- :wq → 存盘 + 退出 (:w 存盘, :q 退出) （陈皓注：:w 后可以跟文件名）- :x， ZZ 或 :wq → 保存并退出 (:x 表示仅在需要时保存，ZZ不需要输入冒号并回车)- dd → 删除当前行，并把删除的行存到剪贴板里- 2dd → 删除2行- p → 粘贴剪贴板- **/pattern** → 搜索 pattern 的字符串（陈皓注：如果搜索出多个匹配，可按n键到下一个）- 100idesu [ESC] → 会写下 “desu desu desu desu ..“- . → 重复上一个命令—— 100 “desu “.- 3. → 重复 3 次 “desu” (注意：不是 300，你看，VIM多聪明啊). - hjkl (强例推荐使用其移动光标，但不必需) →你也可以使用光标键 (←↓↑→). 注: j 就像下箭头。- :help &lt;command&gt; → 显示相关命令的帮助。你也可以就输入 :help 而不跟命令。（陈皓注：退出帮助需要输入:q）- NG → 到第 N 行 （陈皓注：注意命令中的G是大写的，**另我一般使用 : N 到第N行，如 :137 到第137行**）- gg → 到第一行。（陈皓注：相当于1G，或 :1）- G → 到最后一行。 ​ 各种插入模式 1234567- a → 在光标后插入- o → 在当前行后插入一个新行- O → 在当前行前插入一个新行- cw → 替换从光标所在位置后到一个单词结尾的字符 简单的移动光标 12345678910111213- 0 → 数字零，到行头- $ → 到本行行尾- ^ → 到本行第一个不是blank字符的位置（所谓blank字符就是空格，tab，换行，回车等）- g_ → 到本行最后一个不是blank字符的位置。- **/pattern** → 搜索 pattern 的字符串（陈皓注：如果搜索出多个匹配，可按n键到下一个）- fa → 到下一个为a的字符处，你也可以fs到下一个为s的字符。- t, → 到逗号前的第一个字符。逗号可以变成其它字符。- 3fa → 在当前行查找第三个出现的a。 拷贝/粘贴 （陈皓注：p/P都可以，p是表示在当前位置之后，P表示在当前位置之前） 1234- P → 粘贴- yy → 拷贝当前行当行于 ddP Undo/Redo 1234- u → undo- &lt;C-r&gt; → redo 打开/保存/退出/改变文件(Buffer) 12345678- :e &lt;path/to/file&gt; → 打开一个文件- :w → 存盘- :saveas &lt;path/to/file&gt; → 另存为 &lt;path/to/file&gt;- :x， ZZ 或 :wq → 保存并退出 (:x 表示仅在需要时保存，ZZ不需要输入冒号并回车)- :q! → 退出不保存 :qa! 强行退出所有的正在编辑的文件，就算别的文件有更改。- :bn 和 :bp → 你可以同时打开很多文件，使用这两个命令来切换下一个或上一个文件。（陈皓注：我喜欢使用:n到下一个文件）","link":"/2017/08/13/vim/vim入门/"},{"title":"zk2021","text":"定义&amp;特点#定义：分布式协调服务。中心化的服务，维护配置信息，命名服务，分布式同步器(锁、屏障、队列等)，分组服务(组成员检测)。抽象一下，即分布式协调服务。自己本身没有太大意义，用来协调分布式应用，类比一种进程间通信方式。 特点：纯内存结构，吞吐高，单机 1w 写qps，4w读 qps。(参考值，和配置相关) 总结: 在粗粒度分布式锁，分布式选主，主备高可用切换等不需要高 TPS 支持的场景下有不可替代的作用 数据模型# 树形结构，类文件系统。每个树节点znode，每个节点即是文件，也是文件夹，修改操作只能整体 set，不支持部分修改。 ephemeral znode. 临时节点，和 session 生命周期一致，可以用来检测机器在线状态。sequence znode. 顺序节点，自动编号，可以用来实现统一命名。(redis incr 也可以做到)watch 机制。znode 新增、删除、修改、子节点变更及时通知 client。 分布式实现方式# zk 使用 replication，统一收口写，读水平扩展。适用于读多写少场景。 zk选主#zab协议：ZooKeeper atomic broadcast，zk原子广播协议。论文规则是 majority vote，超过半数认可的 server 成为 leader。FastLeaderElection。大致过程，每台 server 初始广播 (serverEpoch, zxid, serverId)，默认选择自己为 leader。判断逻辑先比较 epoch 最大，再比较 zxid 最大，最后比较 serverId 最大。初始第一次很快是 serverId 最大的成为 leader（没有出现断网断电等异常情况时） zk主从同步#leader 连接所有的 follower，发送操作指令，2阶段提交，先 proposal 再 commit，超过半数 proposal 就进行 commit。commit 失败怎么办？2阶段提交都有的问题，概率小不做考虑。同样会有主从延迟问题，一致性保证客户端看到的数据视图一致性，变更顺序一致性，并且在有限时间内保证 server 数据达到最新状态。 zk性能瓶颈# 单机处理写请求majority vote 要求超过一半的 server 存活，server 数量 = 2*n + 2，n越大容错性越强，可以支持n台机器挂掉情况下服务依然可用。同时，n越大，写扩散越大，写能力会变弱，查询能力会线性增长。单机 5w qps级别. (1w 写qps，4w读 qps) 事务日志落盘事务日志保证 client 写成功后数据不会丢失，write ahead，最好配置单独的磁盘。顺序写，所以依然可以有 1w 级别的写 qps。 纯内存操作树结构纯内存，容纳数据有限，线上服务器内存，比如32G。不能用于通常的数据存储，主要用于元数据。单节点现在最大 1m，太大会严重影响读写 qps，对于网络压力也很大。 zk在mysql应用#mysql 主从库切换怎么做的？直接用的 zk 的能力。数据同步通过 binlog 追加，写操作必须主库完成，一台从库 binlog 完成才返回。从库应用binlog会有时延，所以会有主从延迟。日常10ms到100ms左右。后面的从库延迟更多。 zk是否适合服务注册发现# 服务注册发现规模巨大，服务规模 =F{服务 pub 数, 服务 sub 数}，几千个服务，大服务集群机器上w台，比如淘宝交易系统就2w台机器，支撑200w qps。发布过程中会有很大的写入压力和监听扩散。 注册中心不需要很强的一致性，也不需要持久的事务日志。短暂的服务列表不一致只是造成部分的负载不均衡，影响不大。另外持久化事务日志保证宕机后快速恢复对于服务发现来说没啥用，只关注实时情况。","link":"/2021/08/01/zookeeper/zk_2021/"},{"title":"常见基础算法","text":"- 单例模式 DCL - 排序算法，归并、快速 归并 快排 037-数字在排序数组中出现的次数（二分查找） 029-最小的K个数(快速排序) * 013-调整数组顺序使奇数位于偶数前面 * 028-数组中出现次数超过一半的数字 搜索旋转排序数组 最长回文子串 31. 下一个排列 34. 在排序数组中查找元素的第一个和最后一个位置 152. 乘积最大子序列 560. 和为K的子数组 347. 前 K 个高频元素 43. 字符串相乘 - 单例模式#DCL#1234567891011121314public class Singleton { private volatile static Singleton singleton; private Singleton (){} public static Singleton getSingleton() { if (singleton == null) { synchronized (Singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; } } volatile 防止指令重排序 - 排序算法，归并、快速#归并#123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Sort { public static void MergeSort(int[] arr, int low, int high) { //使用递归的方式进行归并排序，所需要的空间复杂度是O（N+logN） int mid = (low + high)/2; if(low &lt; high) { //递归地对左右两边进行排序 MergeSort(arr, low, mid); MergeSort(arr, mid+1, high); //合并 merge(arr, low, mid, high); } } //merge函数实际上是将两个有序数组合并成一个有序数组 //因为数组有序，合并很简单，只要维护几个指针就可以了 private static void merge(int[] arr, int low, int mid, int high) { //temp数组用于暂存合并的结果 int[] temp = new int[high - low + 1]; //左半边的指针 int i = low; //右半边的指针 int j = mid+1; //合并后数组的指针 int k = 0; //将记录由小到大地放进temp数组 for(; i &lt;= mid &amp;&amp; j &lt;= high; k++) { if(arr[i] &lt; arr[j]) temp[k] = arr[i++]; else temp[k] = arr[j++]; } //接下来两个while循环是为了将剩余的（比另一边多出来的个数）放到temp数组中 while(i &lt;= mid) temp[k++] = arr[i++]; while(j &lt;= high) temp[k++] = arr[j++]; //将temp数组中的元素写入到待排数组中 for(int l = 0; l &lt; temp.length; l++) arr[low + l] = temp[l]; } } 快排#123456789101112131415161718192021222324252627282930313233343536373839public class QuickSort implements IArraySort { @Override public int[] sort(int[] sourceArray) throws Exception { // 对 arr 进行拷贝，不改变参数内容 int[] arr = Arrays.copyOf(sourceArray, sourceArray.length); return quickSort(arr, 0, arr.length - 1); } private int[] quickSort(int[] arr, int left, int right) { if (left &lt; right) { int partitionIndex = partition(arr, left, right); quickSort(arr, left, partitionIndex - 1); quickSort(arr, partitionIndex + 1, right); } return arr; } private int partition(int[] arr, int left, int right) { // 设定基准值（pivot） int pivot = left; int index = pivot + 1; for (int i = index; i &lt;= right; i++) { if (arr[i] &lt; arr[pivot]) { swap(arr, i, index); index++; } } swap(arr, pivot, index - 1); return index - 1; } private void swap(int[] arr, int i, int j) { int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; }} 037-数字在排序数组中出现的次数（二分查找）#123456789101112131415161718192021222324252627282930313233343536public class Solution { public int GetNumberOfK(int [] array , int k) { int leftIndex = -1,start=0,end=array.length-1,rightIndex=-1; while(start &lt;= end) { int mid = (start+end)/2; if(array[mid] &gt; k) { end = mid-1; }else if(array[mid] &lt; k){ start = mid+1; }else{ leftIndex = mid; end = mid-1; } } start = 0; end = array.length-1; while(start &lt;= end) { int mid = (start+end)/2; if(array[mid] &gt; k) { end = mid-1; }else if(array[mid] &lt; k){ start = mid+1; }else{ rightIndex = mid; start = mid+1; } } if(array.length == 0 || rightIndex == -1) return 0; return rightIndex-leftIndex+1; }} 029-最小的K个数(快速排序) *#12345678910111213141516171819202122232425262728293031323334353637383940414243444546import java.util.ArrayList;public class Solution { public ArrayList&lt;Integer&gt; GetLeastNumbers_Solution1(int [] arr, int k) { ArrayList&lt;Integer&gt; kNumbers = new ArrayList&lt;Integer&gt;(); if (arr == null || k &lt;= 0 || k &gt; arr.length) return kNumbers; int left = 0; int right = arr.length - 1; int index = partition(arr, left, right); while(index!=k-1){ if(index&lt;k-1){ start=index+1; index=partition(arr, left, right); }else{ end=index-1; index=partition(arr, left, right); } } for(int i=0;i&lt;k;i++){ kNumbers.add(arr[i]); } return kNumbers; } private int partition(int[] arr, int left, int right) { // 设定基准值（pivot） int pivot = left; int index = pivot + 1; for (int i = index; i &lt;= right; i++) { if (arr[i] &lt; arr[pivot]) { swap(arr, i, index); index++; } } swap(arr, pivot, index - 1); return index - 1; } private void swap(int[] arr, int i, int j) { int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; }} 013-调整数组顺序使奇数位于偶数前面 *#12345678910111213141516171819public void reOrderArray(int [] array) { if (array == null || array.length &lt; 2) { return; } int n = array.length; for (int i = 1; i &lt; n; i++) { // 当前元素是奇数，就移动到奇数序列 if (array[i] % 2 != 0) { int value = array[i]; int cur = i; while (cur &gt; 0 &amp;&amp; (array[cur - 1] % 2 == 0)) { array[cur] = array[cur - 1]; cur--; } array[cur] = value; } // 当前元素是偶数，无须移动 }} 028-数组中出现次数超过一半的数字#1234567891011121314151617181920212223242526272829303132public int MoreThanHalfNum_Solution(int [] array) { if (array == null || array.length &lt;= 0) { return 0; } int num = array[0]; int count = 1; for (int i=1; i&lt;array.length; i++) { int temp = array[i]; if (temp == num) { count++; } else { count--; } if (count == 0) { num = temp; count = 1; } } count = 0; for (int i=0; i&lt;array.length; i++) { if (array[i] == num) { count++; } } int half = array.length / 2 + 1; if (count &gt;= half) { return num; } return 0;} 搜索旋转排序数组#搜索一个给定的目标值，如果数组中存在这个目标值，则返回它的索引，否则返回 -1 。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public int search(int[] nums, int target) { // 判空 if (nums.length == 0) return -1; if (nums.length == 1) return nums[0] == target ? 0 : -1; // 得到旋转点 int rotateIndex = getRotateIndex(nums); // 如果rotateIndex0, 和 if (rotateIndex == 0) { return searchTarget(nums, 0, nums.length - 1, target); } else { if (target &lt;= nums[nums.length - 1]) { return searchTarget(nums, rotateIndex, nums.length - 1, target); } else { return searchTarget(nums, 0, rotateIndex, target); } }}// 二分查找target所在位置private int searchTarget(int[] nums, int left, int right, int target) { while (left &lt;= right) { int mid = (left + right) / 2; if (nums[mid] == target) { return mid; } else { if (nums[mid] &gt; target) { right = mid -1; } else { left = mid + 1; } } } return -1;}// 获取旋转点private int getRotateIndex(int[] nums) { int left = 0; int right = nums.length - 1; if (nums[left] &lt; nums[right]) { return 0; } while (left &lt;= right) { int mid = (left + right ) / 2; if (nums[mid] &gt; nums[mid+1]) { return mid+1; } else { if (nums[mid] &lt; nums[left]) { right = mid - 1; } else { left = mid + 1; } } } return 0;} 最长回文子串#123456789101112131415161718192021222324252627public String longestPalindrome(String s) { if (s == null || s.length() == 0) return s; char[] cs = s.toCharArray(); int len = cs.length; String maxStr = \"\"; for (int i = 0; i &lt; len; i++) { String curStr = midSpreed(cs, i, i); String midStr = midSpreed(cs, i, i + 1); maxStr = curStr.length() &gt; maxStr.length() ? curStr : maxStr; maxStr = midStr.length() &gt; maxStr.length() ? midStr : maxStr; } return maxStr;}private String midSpreed(char[] cs, int index, int indexNext) { while (index &gt;=0 &amp;&amp; indexNext &lt; cs.length &amp;&amp; cs[index] == cs[indexNext]) { index--; indexNext++; } StringBuilder sb = new StringBuilder(); for (int i = index + 1; i &lt; indexNext; i++) { sb.append(cs[i]); } return sb.toString();} 31. 下一个排列#实现获取下一个排列的函数，算法需要将给定数字序列重新排列成字典序中下一个更大的排列。 如果不存在下一个更大的排列，则将数字重新排列成最小的排列（即升序排列）。 1234567891011121314151617181920212223242526public void nextPermutation(int[] nums) { if (nums.length &lt;= 0) return; int len = nums.length; for (int i = len - 1; i &gt;= 0; i--) { if (i == 0) { Arrays.sort(nums); } else { if (nums[i] &gt; nums[i-1]) { // 说明有逆序存在, 则下一个是将i-1 转变成i-1 后面比它大的数字 Arrays.sort(nums, i, len); for (int j=i;j&lt;len;j++) { if (nums[j]&gt;nums[i-1]) { swap(nums,i-1,j); return; } } } } }}private void swap(int[] nums, int i, int j) { int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp;} 34. 在排序数组中查找元素的第一个和最后一个位置#给定一个按照升序排列的整数数组 nums，和一个目标值 target。找出给定目标值在数组中的开始位置和结束位置。你的算法时间复杂度必须是 O(log n) 级别。 12345678910111213141516171819202122232425262728293031323334353637383940414243public int[] searchRange(int[] nums, int target) { if (nums.length == 0) { return new int[]{-1, -1}; } int leftIndex = -1; int rightIndex = -1; int left = 0, right = nums.length - 1, mid = 0; while (left &lt;= right) { mid = (left + right) / 2; if (nums[mid] == target &amp;&amp; (mid == 0 || nums[mid - 1] &lt; nums[mid])) { leftIndex = mid; break; } else { if (nums[mid] &lt; target) { left = mid + 1; } else { right = mid - 1; } } } left = leftIndex != -1 ? leftIndex : 0; right = nums.length - 1; while (left &lt;= right) { mid = (left + right) / 2; if (nums[mid] == target &amp;&amp; (mid == nums.length - 1 || nums[mid + 1] &gt; nums[mid])) { rightIndex = mid; break; } else { if (nums[mid] &gt; target) { right = mid - 1; } else { left = mid + 1; } } } int[] result = new int[]{leftIndex, rightIndex}; return result;} 152. 乘积最大子序列#给定一个整数数组 nums ，找出一个序列中乘积最大的连续子序列（该序列至少包含一个数）。 12345678910111213141516public int maxProduct(int[] nums) { int max = nums[0]; int min = nums[0]; int res = nums[0]; for(int i=1; i&lt;nums.length;i++) { if (nums[i] &lt; 0) { int temp = max; max = min; min = temp; } max = Integer.max(max * nums[i], nums[i]); min = Integer.min(min * nums[i], nums[i]); res = Integer.max(max, res); } return res;} 560. 和为K的子数组#12345678910111213public int subarraySum(int[] nums, int k) { int count = 0; for (int i=0; i&lt; nums.length;i++) { int sum = 0; for (int j=i;j &lt; nums.length; j++) { sum += nums[j]; if (sum == k) { count++; } } } return count;} 347. 前 K 个高频元素#1234567891011121314151617181920212223242526272829303132public List&lt;Integer&gt; topKFrequent(int[] nums, int k) { // 使用字典，统计每个元素出现的次数，元素为键，元素出现的次数为值 HashMap&lt;Integer,Integer&gt; map = new HashMap(); for(int num : nums){ if (map.containsKey(num)) { map.put(num, map.get(num) + 1); } else { map.put(num, 1); } } // 遍历map，用最小堆保存频率最大的k个元素 PriorityQueue&lt;Integer&gt; pq = new PriorityQueue&lt;&gt;(new Comparator&lt;Integer&gt;() { @Override public int compare(Integer a, Integer b) { return map.get(a) - map.get(b); } }); for (Integer key : map.keySet()) { if (pq.size() &lt; k) { pq.offer(key); } else if (map.get(key) &gt; map.get(pq.peek())) { pq.poll(); pq.offer(key); } } // 取出最小堆中的元素 List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); while (!pq.isEmpty()) { res.add(pq.poll()); } return res;} 43. 字符串相乘#两个长度分别为 n 和 m 的数相乘，长度不会超过 n + m。因此我们可以创建一个长度为 n + m 的数组 res 存储结果。nums[i] * nums[j] 的结果 位于 res[i+j+1], 如果 res[i+j+1] &gt; 10, 则进位到 res[i+j] 1234567891011121314151617181920public String multiply(String n1, String n2) { int n = n1.length(), m = n2.length(); int[] res = new int[n + m]; for (int i = n - 1; i &gt;= 0; i--) { for (int j = m - 1; j &gt;= 0; j--) { int a = n1.charAt(i) - '0'; int b = n2.charAt(j) - '0'; int r = a * b; r += res[i + j + 1]; res[i + j + 1] = r % 10; res[i + j] += r / 10; } } StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; n + m; i++) { if (sb.length() == 0 &amp;&amp; res[i] == 0) continue; sb.append(res[i]); } return sb.length() == 0 ? \"0\" : sb.toString();}","link":"/2019/09/09/arithmetic/base/"},{"title":"二叉树算法","text":"- 二叉树的打印，前中后序遍历, 递归&amp;非递归 非递归先序遍历 非递归中序遍历 非递归后序遍历 022-从上往下打印二叉树 * 060-把二叉树打印成多行 059-按之字形顺序打印二叉树 * 023-二叉搜索树的后序遍历序列 * 024-二叉树中和为某一值的路径 038-二叉树的深度 二叉树层次遍历 114. 二叉树展开为链表 236. 二叉树的最近公共祖先 105. 从前序与中序遍历序列构造二叉树 101. 对称二叉树 101. 平衡二叉树 - 二叉树的打印，前中后序遍历, 递归&amp;非递归#非递归先序遍历#1234567891011121314151617public List&lt;Integer&gt; preOrder(BinaryTree node) { List&lt;Integer&gt; list=new ArrayList&lt;Integer&gt;(); if(node==null) return list; Stack&lt;BinaryTree&gt; stack= new Stack&lt;BinaryTree&gt;(); while(node!=null || !stack.empty()) { if(node!=null){ list.add(node.val); stack.push(node); node=node.left; } else { node=stack.pop(); node=node.right; } } return list;} 非递归中序遍历#1234567891011121314151617public List&lt;Integer&gt; inOrder(BinaryTree node) { List&lt;Integer&gt; list=new ArrayList&lt;Integer&gt;(); if(node==null) return list; Stack&lt;BinaryTree&gt; stack= new Stack&lt;BinaryTree&gt;(); while(node!=null || !stack.empty()) { if(node!=null){ stack.push(node); node=node.left; } else { node=stack.pop(); list.add(node.val); node=node.right; } } return list;} 非递归后序遍历#1234567891011121314151617public List&lt;Integer&gt; postOrder(BinaryTree node) { List&lt;Integer&gt; list=new ArrayList&lt;Integer&gt;(); if(node==null) return list; Stack&lt;BinaryTree&gt; stack= new Stack&lt;BinaryTree&gt;(); while(node!=null || !stack.empty()) { if(node!=null){ list.add(0, node.val); stack.push(node); node=node.right; } else { node=stack.pop(); node=node.left; } } return list;} 022-从上往下打印二叉树 *#123456789101112131415public class Solution { public ArrayList&lt;Integer&gt; PrintFromTopToBottom(TreeNode root) { ArrayList&lt;Integer&gt; result = new ArrayList&lt;Integer&gt;(); if(root == null) return result; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;(); queue.offer(root); while(!queue.isEmpty()) { TreeNode temp = queue.poll(); result.add(temp.val); if(temp.left != null) queue.offer(temp.left); if(temp.right != null) queue.offer(temp.right); } return result; }} 060-把二叉树打印成多行#12345678910111213141516171819202122232425262728ArrayList&lt;ArrayList&lt;Integer&gt; &gt; Print(TreeNode pRoot) { ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); if(pRoot == null){ return list; } Queue&lt;TreeNode&gt; queue = new LinkedList(); //根节点入队列 queue.offer(pRoot); //当队列不是空 while(!queue.isEmpty()){ //放里面，记录当前节点个数 int size = queue.size(); ArrayList&lt;Integer&gt; temp = new ArrayList(); //遍历一次是一层 for(int i=0;i&lt;size;i++){ TreeNode node = queue.poll(); if(node.left!=null){ queue.offer(node.left); } if(node.right!=null){ queue.offer(node.right); } temp.add(node.val); } list.add(temp); } return list;} 059-按之字形顺序打印二叉树 *#按行打印的部分，按奇偶来改变头插尾插 023-二叉搜索树的后序遍历序列 *#同非递归二叉树的后序遍历， 思路: 先序是 abc, acb, 的反转 bca即需要的后序遍历。使用栈， 与先序写法差不多，只是先push right, 再left, list.add用头插. 024-二叉树中和为某一值的路径#回溯 12345678910111213141516171819202122232425262728public ArrayList&lt;ArrayList&lt;Integer&gt;&gt; FindPath(TreeNode root, int target) { ArrayList&lt;ArrayList&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); if (root == null) { return result; } find(root, target, 0, new ArrayList&lt;Integer&gt;(), result); return result;}private void find(TreeNode node, int target, int sum, ArrayList&lt;Integer&gt; path, ArrayList&lt;ArrayList&lt;Integer&gt;&gt; result) { sum += node.val; path.add(node.val); if (node.left == null &amp;&amp; node.right == null &amp;&amp; sum == target) { result.add(new ArrayList&lt;&gt;(path)); path.remove(path.size() - 1); return; } if (node.left != null) { find(node.left, target, sum, path, result); } if (node.right != null) { find(node.right, target, sum, path, result); } path.remove(path.size() - 1);} 038-二叉树的深度#递归 1234567891011121314public int TreeDepth(TreeNode root) { if (root == null) { return 0; } if (root.left == null &amp;&amp; root.right == null) { return 1; } int leftDepth = TreeDepth(root.left); int rightDepth = TreeDepth(root.right); return 1 + Integer.max(leftDepth, rightDepth);} 二叉树层次遍历#12345678910111213141516171819202122232425262728public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) { List&lt;List&lt;Integer&gt;&gt; levels = new ArrayList&lt;List&lt;Integer&gt;&gt;(); if (root == null) return levels; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;(); queue.add(root); int level = 0; while ( !queue.isEmpty() ) { // start the current level levels.add(new ArrayList&lt;Integer&gt;()); // number of elements in the current level int level_length = queue.size(); for(int i = 0; i &lt; level_length; ++i) { TreeNode node = queue.remove(); // fulfill the current level levels.get(level).add(node.val); // add child nodes of the current level // in the queue for the next level if (node.left != null) queue.add(node.left); if (node.right != null) queue.add(node.right); } // go to next level level++; } return levels;} 114. 二叉树展开为链表#直接展开 1234567891011121314151617181920212223public void flatten(TreeNode root) { TreeNode node = root; while (node != null) { // if (node.left == null) { node = node.right; continue; } // 找到左分支的最右节点 TreeNode pre = node.left; while (pre.right != null) { pre = pre.right; } // pre 替换node 右分支的位置 pre.right = node.right; node.right = node.left; node.left = null; node = node.right; }} 236. 二叉树的最近公共祖先#给定一个二叉树, 找到该树中两个指定节点的最近公共祖先。 1234567891011121314151617181920212223242526public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) { Stack&lt;TreeNode&gt; stack = new Stack(); Map&lt;TreeNode, TreeNode&gt; son2ParentMap = new HashMap(); stack.push(root); son2ParentMap.put(root, null); while (!son2ParentMap.containsKey(p) || !son2ParentMap.containsKey(q)) { TreeNode node = stack.pop(); if (node.left != null) { son2ParentMap.put(node.left, node); stack.push(node.left); } if (node.right != null) { son2ParentMap.put(node.right, node); stack.push(node.right); } } Set&lt;TreeNode&gt; sets = new HashSet(); while (p != null) { sets.add(p); p = son2ParentMap.get(p); } while (!sets.contains(q)) { q = son2ParentMap.get(q); } return q;} 105. 从前序与中序遍历序列构造二叉树#1234567891011121314151617181920212223242526public TreeNode buildTree(int[] preorder, int[] inorder) { return buildTreeHelper(preorder, 0, preorder.length, inorder, 0, inorder.length);}private TreeNode buildTreeHelper(int[] preorder, int p_start, int p_end, int[] inorder, int i_start, int i_end) { // preorder 为空，直接返回 null if (p_start == p_end) { return null; } int root_val = preorder[p_start]; TreeNode root = new TreeNode(root_val); //在中序遍历中找到根节点的位置 int i_root_index = 0; for (int i = i_start; i &lt; i_end; i++) { if (root_val == inorder[i]) { i_root_index = i; break; } } int leftNum = i_root_index - i_start; //递归的构造左子树 root.left = buildTreeHelper(preorder, p_start + 1, p_start + leftNum + 1, inorder, i_start, i_root_index); //递归的构造右子树 root.right = buildTreeHelper(preorder, p_start + leftNum + 1, p_end, inorder, i_root_index + 1, i_end); return root;} 101. 对称二叉树#123456789101112131415class Solution { public boolean isSymmetric(TreeNode root) { return check(root, root); } public boolean check(TreeNode p, TreeNode q) { if (p == null &amp;&amp; q == null) { return true; } if (p == null || q == null) { return false; } return p.val == q.val &amp;&amp; check(p.left, q.right) &amp;&amp; check(p.right, q.left); }} 101. 平衡二叉树#1234567891011121314151617class Solution { public boolean isBalanced(TreeNode root) { if (root == null) { return true; } else { return Math.abs(height(root.left) - height(root.right)) &lt;= 1 &amp;&amp; isBalanced(root.left) &amp;&amp; isBalanced(root.right); } } public int height(TreeNode root) { if (root == null) { return 0; } else { return Math.max(height(root.left), height(root.right)) + 1; } }}","link":"/2019/09/09/arithmetic/tree/"},{"title":"红黑树、AVL树、B树代价分析与比较","text":"一、各种树简介#红黑树#它可以在 O(logn) 时间内完成查找，插入和删除，这里的n是树中元素的数目. 常考五个性质 自编顺口溜：有红有黑，头黑尾黑，红后黑，任尾同黑 结点是红色或黑色 根结点始终是黑色 叶子结点（NIL 结点）都是黑色 红色结点的两个直接孩子结点都是黑色（即从叶子到根的所有路径上不存在两个连续的红色结点） 从任一结点到每个叶子的所有简单路径都包含相同数目的黑色结点 保证了红黑树在满足平衡二叉树特征的前提下，还可以做到 从根到叶子的最长路径最多不会超过最短路径的两倍。 AVL树#AVL树定义:二叉排序树，其中每一个结点的左子树和右子树的高度差不超过1（小于等于1）。 二叉树的平衡因子 （Balance Factor） 等于该结点的左子树深度减去右子树深度的值称为平衡因子。平衡因子只可能是－1，0，1。 红黑树相对于AVL树来说，牺牲了部分平衡性以换取插入/删除操作时少量的旋转操作，整体来说性能要优于AVL树。 红黑树和AVL树都是从树的平衡性出发，找到合适的平衡方式，一个通过颜色标识限定，一个通过树高差限定，使树都处于平衡状态。 AVL树由于实现比较复杂，而且插入和删除性能差，在实际环境下的应用不如红黑树。 B树#B树相对于红黑树的区别 在大规模数据存储的时候，红黑树往往出现由于树的深度过大而造成磁盘IO读写过于频繁，进而导致效率低下的情况。为什么会出现这样的情况，我们知道要获取磁盘上数据，必须先通过磁盘移动臂移动到数据所在的柱面，然后找到指定盘面，接着旋转盘面找到数据所在的磁道，最后对数据进行读写。磁盘IO代价主要花费在查找所需的柱面上，树的深度过大会造成磁盘IO频繁读写。根据磁盘查找存取的次数往往由树的高度所决定，所以，只要我们通过某种较好的树结构减少树的结构尽量减少树的高度，B树可以有多个子女，从几十到上千，可以降低树的高度。 B树的数据结构就是为内外存的数据交互准备的。外存（如硬盘）是将 所有的信息分割成相等大小的页面，每次硬盘读写的都是一个或多个完整的页面 。如果要处理的硬盘数据量很大，无法一次全部装入内存中，就要对B树进行调整，是的B树的阶数（或结点的元素）与硬盘存储的页面大小相匹配。比如一棵B树的阶为1001（1个结点可以包含1000个元素），高度为2，它可以存储超过10亿（1000X1000X1000）个关键字，我们只要让根结点持久的保留在内存中，那么在这棵树上，寻找某一个关键字至多需要两次硬盘的读取。通过这种方式，在有限内存的情况下，每一次磁盘的访问都可以获得最大数量的数据。 二、各树操作代价#整个红黑树的查找，插入和删除都是O(logN)的，原因就是整个红黑树的高度是logN，查找从根到叶，走过的路径是树的高度，删除和插入操作是从叶到根的，所以经过的路径都是logN。 RBT 的操作代价分析#(1) 查找代价：由于红黑树的性质(最长路径长度不超过最短路径长度的2倍)，可以说明红黑树虽然不像AVL一样是严格平衡的，但平衡性能还是要比BST要好。其查找代价基本维持在O(logN)左右，但在最差情况下(最长路径是最短路径的2倍少1)，比AVL要略逊色一点。 (2) 插入代价：RBT插入结点时，需要旋转操作和变色操作。但由于只需要保证RBT基本平衡就可以了。因此插入结点最多只需要2次旋转，这一点和AVL的插入操作一样。虽然变色操作需要O(logN)，但是变色操作十分简单，代价很小。 (3) 删除代价：RBT的删除操作代价要比AVL要好的多，删除一个结点最多只需要3次旋转操作。 RBT 效率总结 : 查找 效率最好情况下时间复杂度为O(logN)，但在最坏情况下比AVL要差一些，但也远远好于BST。插入和删除操作改变树的平衡性的概率要远远小于AVL（RBT不是高度平衡的）。因此需要的旋转操作的可能性要小，而且一旦需要旋转，插入一个结点最多只需要旋转2次，删除最多只需要旋转3次(小于AVL的删除操作所需要的旋转次数)。虽然变色操作的时间复杂度在O(logN)，但是实际上，这种操作由于简单所需要的代价很小。 AVL 的操作代价分析#(1) 查找代价： AVL是严格平衡的BST（平衡因子不超过1）。那么查找过程与BST一样，只是AVL不会出现最差情况的BST(单支树)。因此查找效率最好，最坏情况都是O(logN)数量级的。 (2) 插入代价： AVL必须要保证严格平衡(|bf|&lt;=1)，那么每一次插入数据使得AVL中某些结点的平衡因子超过1就必须进行旋转操作。事实上，AVL的每一次插入结点操作最多只需要旋转1次(单旋转或双旋转)。因此，总体上插入操作的代价仍然在O(logN)级别上(插入结点需要首先查找插入的位置)。 (3) 删除代价：AVL删除结点的算法可以参见BST的删除结点，但是删除之后必须检查从删除结点开始到根结点路径上的所有结点的平衡因子。因此删除的代价稍微要大一些。每一次删除操作最多需要O(logN)次旋转。因此，删除操作的时间复杂度为O(logN)+O(logN)=O(2logN) AVL 效率总结 查找的时间复杂度维持在O(logN)，不会出现最差情况AVL树在执行每个插入操作时最多需要1次旋转，其时间复杂度在O(logN)左右。 AVL树在执行删除时代价稍大，执行每个删除操作的时间复杂度需要O(2logN)。 B树的操作代价分析#(1) 查找代价： B-Tree作为一个平衡多路查找树(m-叉)。B树的查找分成两种：一种是从一个结点查找另一结点的地址的时候，需要定位磁盘地址(查找地址)，查找代价极高。另一种是将结点中的有序关键字序列放入内存，进行优化查找(可以用折半)，相比查找代价极低。而B树的高度很小，因此在这一背景下，B树比任何二叉结构查找树的效率都要高很多。而且B+树作为B树的变种，其查找效率更高。 (2)插入代价： B-Tree的插入会发生结点的分裂操作。当插入操作引起了s个节点的分裂时，磁盘访问的次数为h(读取搜索路径上的节点)＋2s(回写两个分裂出的新节点)＋1（回写新的根节点或插入后没有导致分裂的节点）。因此，所需要的磁盘访问次数是h+2s+1，最多可达到3h+1。因此插入的代价是很大的。 (3)删除代价：B-Tree的删除会发生结点合并操作。最坏情况下磁盘访问次数是3h＝（找到包含被删除元素需要h次读访问）+（获取第2至h层的最相邻兄弟需要h-1次读访问）+（在第3至h层的合并需要h-2次写访问）+（对修改过的根节点和第2层的两个节点进行3次写访问） B-Tree效率总结： 由于考虑磁盘储存结构，B树的查找、删除、插入的代价都远远要小于任何二叉结构树(读写磁盘次数的降低)。 三、AVL与红黑树的对比#AVL 和RBT 都是二叉查找树的优化。其性能要远远好于二叉查找树。他们之间都有自己的优势，其应用上也有不同。 结构对比： AVL的结构高度平衡，RBT的结构基本平衡。平衡度AVL &gt; RBT. 查找对比： AVL 查找时间复杂度最好，最坏情况都是O(logN)。 RBT 查找时间复杂度最好为O(logN)，最坏情况下比AVL略差。 插入删除对比： 1. AVL的插入和删除结点很容易造成树结构的不平衡，而RBT的平衡度要求较低。因此在大量数据插入的情况下，RBT需要通过旋转变色操作来重新达到平衡的频度要小于AVL。 如果需要平衡处理时，RBT比AVL多一种变色操作，而且变色的时间复杂度在O(logN)数量级上。但是由于操作简单，所以在实践中这种变色仍然是非常快速的。 当插入一个结点都引起了树的不平衡，AVL和RBT都最多需要2次旋转操作。但删除一个结点引起不平衡后，AVL最多需要logN 次旋转操作，而RBT最多只需要3次。因此两者插入一个结点的代价差不多，但删除一个结点的代价RBT要低一些。 AVL和RBT的插入删除代价主要还是消耗在查找待操作的结点上。因此时间复杂度基本上都是与O(logN) 成正比的。 总体评价：大量数据实践证明，RBT的总体统计性能要好于平衡二叉树。","link":"/2019/06/13/dataStructure/tree/"},{"title":"gfs分享","text":"Google file system 问题#问题： 如何高效可靠地存储如此大规模的数据 ？ GFS是Google为其内部应用设计的分布式存储系统 问题的关键点是 高效 、 可靠、规模巨大 传统操作系统的问题在于 1. 硬盘不够大，存不了那么多 2. 数据不安全，传上去，硬盘瞬间损坏了，数据就没了 方法： 对于硬盘不够大 (规模巨大)： 多加几块硬盘， 最好就是无限加硬盘，让空间接近无限大，也就是可扩展、可伸缩 对于数据不安全 (可靠)： 冗余，数据备份，默认是3份, 写好三份，再返回完成 高效： 写时多server数据水平复制 读时就近读取 等 面向应用： 数据规模巨大，不要求低延迟 架构#组件: master, chunkserver, client Master： 存储系统元数据信息，主要包括namespace、文件chunk信息以及chunk多副本位置信息。Master是系统的中心节点，所有客户端的元数据访问，如列举目录下文件，获取文件属性等操作都是直接访问Master。除此之外，还承担了系统诸多的管理工作 Chunkserver: 是文件chunk的存储位置。每个数据节点挂载多个磁盘设备并将其格式化为本地文件系统, 将客户端写入数据以Chunk为单位存储，存储形式为本地文件 Client: 提供类POSIX文件接口，应用程序使用客户端与GFS交互 （POSIX表示可移植操作系统接口（Portable Operating System Interface of UNIX，缩写为 POSIX ），POSIX标准定义了操作系统应该为应用程序提供的接口标准），就是说操作gfs和操作本地文件系统的接口没太大区别 Chunk#GFS以64MB为Chunk大小来划分文件，每一个Chunk又以Block为单位进行划分，大小为64KB，每一个Block对应一个32位的校验和。当读取一个Chunk副本时，Chunk Server会将读取的数据和校验和进行比较，如果不匹配，就会返回错误，客户端将选择其它Chunk Server上的副本。 Master#不进行文件数据读写 文件元数据# 文件系统的目录树 ， 存储为B树， 叶子节点代表普通文件，中间节点则代表目录文件 文件元数据信息 ，包括：id、文件大小、创建时间、文件的chunk信息等，Master会将这些元数据信息进行持久化存储， 每一次元数据的更新操作都会先写日志，再应用到内存的B树 ，Master启动时会将所有元数据加载至内存中， 优点是元数据操作速度很快，缺点是限制了文件系统的可扩展性，如64GB内存的服务器最多可支持的文件数量约为 64GB/64B = 10亿 定期进行日志回收， 将当前内存状态冻结并持久化存储到磁盘上，称为Checkpoint；然后，回收该时刻之前的所有日志。若系统此时重启，只需要：1. 将Checkpoint加载入内存；2. 重放Checkpoint点之后的日志即可在内存中重构最新状态。 #### #####Chunk管理 文件元数据中存储了file id至chunk映射关系。Chunk以多副本方式存储，Master还需要维护Chunk位置信息。Chunk的位置信息ChunkServer周期性汇报，Master只在内存中维护该信息，无需持久化。如果master挂掉，新master启动的时候，会询问chunkserver，拿到各个chunk的位置信息 注： Master授予一个副本租约，这个副本成为primary副本, 租约在修改操作的顺序上起到重要作用。 租约#保证多个副本变更顺序的一致性 租约（Lease）是由GFS中心节点Master分配给chunk的某个副本的锁。持有租约的副本方可处理客户端的更新请求，客户端更新数据前会从Master获取该chunk持有租约的副本并向该副本发送更新请求。 通过主副本将并发的更新操作串行化 租约本质上是一种有时间限制的锁：租约的持有者（chunk的某个副本）需要定期向Master申请续约。如果超过租约的期限，那么该租约会被强制收回并重新分配给其他副本。 注：读操作不涉及租约 读# 块句柄（chunk handle）全局唯一的64bit标识 chunk index 是客户端计算出来的 写# 客户端向Master查询待写入的chunk的副本信息， Master返回副本列表，第一项为主副本，即当前持有租约的副本； 客户端将数据发送至chunk多副本，chunkserver会缓存这些数据，此时数据并不落盘； 客户端向主副本发起Sync请求； 主副本将数据写入本地的同时通知其他副本将数据写入各自节点，此时数据方才落盘； 主副本等待所有从副本的sync响应； 主副本给客户端返回写入成功响应 数据推送过程，客户端可以根据网络拓扑情况进行推送路径优化：客户端可以选择距离自己最近的副本推送数据，然后再由该副本选择下一个距离自己最近的副本进行数据推送，直到数据被扩散至所有副本，由于该过程仅仅是将数据推送给chunkserver并保存在内存缓冲区中，因此，无需保证数据推送顺序； sync (5) 是将上面推送的数据落盘，需要保证多副本上数据写入序列的一致性, 该指令必须由主副本来确定数据更新顺序然后将该顺序通知给其他从副本。 主副本先执行sync操作，成功的话再为这个操作分配一个序列号，给其他副本发写入请求，如果不成功，则直接返回客户端失败。 主副本失败或部分副本失败会返回给客户端失败，客户端会进行重发 数据一致性#GFS定义了几种一致性： defined：状态已定义，从客户端角度来看，客户端完全了解已写入集群的数据，例如，客户端串行写入且成功，此时的状态是definedconsistent：客户端来看chunk多副本的数据完全一致，但不一定defined，如下图2，一般发生在多客户端并发更新时unconsistent：多副本数据不一致undefined：数据未定义 状态# 上图其实从左到右，从上到下分别是 串行写成功、 并发写成功、追加成功(包含重试情况)、 各种失败 串行写只要成功就不会有一致性问题，因为offset是确定的，只要写成功各个副本就是一样的，只是并发的话单个客户端不知道真实的数据情况 write#串行Over-Write over-write由客户端指定文件更新offset。当客户端是串行更新时，客户端自己知道写入文件范围以及写入数据内容，且本次写入在数据服务器的多副本上均执行成功， 即使第一次不成功，重试之后成功因为写入位置偏移固定，也没有并发客户端跟你抢，所以，结果对于客户端来说就是明确的，且多副本上数据一致，故而结果是defined。 并行Over-Write 并行写入时多个客户端由于写入范围可能交叉而形成交织写。这时候，由于单个客户端无法决定写入顺序（只有主副本才能决定谁先写谁后写），因此，即使写入成功，客户端仍无法确定在并发写入时交叉部分最终写入结果，但是因为写入成功，所以多副本数据必然一致 图中红色部分代表并发追加的部分，这部分数据由于无法确定谁先谁后执行，因此结果不确定。但由于更新成功，因此，副本间数据是一致的，这就是consistent but undefined。 无论是穿行还是并行over-write，一旦失败，多个chunk副本上的数据可能都不一致了，其次，客户端从不同的副本上读出的数据也不一样（可能某些副本成功而某些副本失败），因此，必然也是undefined，也是inconsistent。 append#客户端append操作无需指定offset，由chunk主副本根据当前文件大小决定写入offset，在写入成功后将该offset返回给客户端。因此，客户端能够根据offset确切知道写入结果，无论是串行写入还是并发写入，其行为是defined。如下： append并重试 假设上面的append经历了一次重试，那可能实际chunk的布局如下： 重试：由于第一次写失败（错误可能发生在任意一个副本），导致了多副本之间从50至80的数据可能不一致。但接下来重试成功，从80至110之间的数据一致，因此，其状态是interspersed with inconsistent。 snapshot 快照#Snapshot是对系统当前状态进行的一次拍照。用户可以在任意时刻回滚到快照的状态。GFS使用COW技术实现Snapshot。 COW原理是如果被Snapshot的文件有更新操作时，就将文件的要被更新的chunk复制一份，然后对复制的chunk进行更新，而原来的chunk作为快照数据被保留，以后要恢复到该快照时，直接将该chunk读出即可。 当GFS的Master节点收到Snapshot请求时： 回收Snapshot请求覆盖的文件chunks上的租约，这样，接下来客户端要对文件修改时，就必须向Master申请，而此时master就可以对chunk进行复制； Master在日志中记录本次Snapshot操作，然后在内存中执行Snapshot动作，具体是将被Snapshot的文件或目录的元数据复制一份，被复制出的文件与原始文件指向相同的chunk； 假如客户端申请更新被Snapshot的文件内容，那么找到需要更新的Chunk，向其多个副本发送拷贝命令，在其本地创建出Chunk的副本Chunk’，之所以本地创建是因为可以避免跨节点之间的数据拷贝，节省网络带宽； 客户端收到Master的响应后，表示该Chunk已经COW结束，接下来客户端的更新流程与正常的没有区别。 Master容错# GFS Master的修改操作总是先记录操作日志，然后再修改内存，当Master发生故障重启时，可以通过磁盘中的操作日志恢复内存数据结构； 为了减少Master宕机恢复时间，Master会定期将内存中的数据以checkpoint文件的形式转储到磁盘中，从而减少回放的日志量。为了进一步提高Master的可靠性和可用性，GFS中还会执行实时热备，所有的元数据修改操作都必须保证发送到实时热备才算成功。 远程的实时热备将实时接收Master发送的操作日志并在内存中回放这些元数据操作。如果Master宕机，还可以秒级切换到实时备机继续提供服务。为了保证同一时刻只有一个Master，GFS依赖Google内部的Chubby服务进行选主操作。 Master需要持久化前两种元数据，即命令空间及文件到chunk之间的映射关系；对于第三种元数据，即Chunk副本的位置信息，Master可以选择不进行持久化，这是因为ChunkServer维护了这些信息，即使Master发生故障，也可以在重启时通过ChunkServer汇报来获取。 相关链接#http://www.uml.org.cn/zjjs/201202172.asp http://blog.luoyuanhang.com/2017/05/15/gfs-reading-notes/ https://www.youtube.com/watch?v=WLad7CCexo8 https://zhuanlan.zhihu.com/p/28155582 http://blog.csdn.net/zhangpan19910604/article/details/51271943","link":"/2017/12/02/hadoop/gfs论文分享/"},{"title":"jvm","text":"- Java内存区域 - 谈谈java的类加载机制 - gc对象存活判定算法 - gc垃圾收集器及其优缺点 - 标记算法和复制算法的区別，用在什么场合 - cms垃圾收集器的回收步骤及其优缺点？ - G1回收器的特点 - G1执行步骤 - 内存泄漏与内存溢出的区别 - 有几种gc fail？ - 什么情况会触发fullgc？ - 栈内存溢出 - 系统内存多大，留给操作系统2G，够吗？ - Java内存区域# 线程私有的 程序计数器存放当前线程所执行的字节码的行号指示器。如果线程执行的是一个Java程序，计数器记录正在执行的虚拟机字节码指令地址；正在执行的是native方法，则计数器的值为空 Java虚拟机栈 描述Java方法执行的内存模型，每个方法执行的同时都会创建一个栈帧来存储局部变量表（编译期可知的各种基本数据类型，对象引用【reference类型】，内存空间的分配是在编译期完成的，方法运行期间不会改变局部变量表的大小）、操作数栈、动态链接、方法出口等。 本地方法栈 为虚拟机使用到的native方法服务 线程公有的 Java堆（GC堆） 存放对象实例，所有的对象实例和数组都在堆上分配。程序运行时分支可能不一样，只有运行期间才能知道创建哪些对象，这部分内存的分配和回收是动态的 metaspace 存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码 直接内存 不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存。NIO使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作，避免了Java堆和Native堆来回复制数据。直接内存的回收是在虚拟机进行full gc的时候顺带进行的，并不会自己触发垃圾回收 - 谈谈java的类加载机制# 过程 加载 通过全类名获取定义此类的二进制字节流 将字节流所代表的静态存储结构转换为方法区的运行时数据结构 在内存中生成一个代表该类的 Class 对象,作为方法区这些数据的访问入口 连接 验证文件格式、元数据、字节码、符号引用验证 准备 正式为类变量分配内存并设置类变量初始值的阶段，设置数据类型默认的零值 解析 解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程 初始化 真正执行类中定义的 Java 程序代码初始化阶段是执行类构造器 ()方法的过程 双亲委派模式Java的类加载使用双亲委派模式，即一个类加载器在加载类时，先把这个请求委托给自己的父类加载器去执行，如果父类加载器还存在父类加载器，就继续向上委托，直到顶层的启动类加载器。如果父类加载器能够完成类加载，就成功返回，如果父类加载器无法完成加载，那么子加载器才会尝试自己去加载。这种双亲委派模式的好处，一个可以避免类的重复加载，另外也避免了java的核心API被篡改。 BootstrapClassLoader ExtensionClassLoader AppClassLoader(应用程序类加载器) - gc对象存活判定算法#1.1引用计数算法 给对象添加一个引用计数器，当有地方引用它时加1，当引用失效时计数减1，任何时刻计数器为0时的对象都不会再被引用。 缺点：存在两个对象不会被继续访问，但是两者循环调用的情况，由于存在循环调用导致两个对象都不会被回收。 1.2可达性分析算法 通过一系列被称作gc roots对象作为起点，从这些起点向下搜索，搜索所走过的路径成为引用链，当一个对象到gc roots没有任何引用链时证明此对象不可用。 Java中gc roots的对象包括： 虚拟机栈中引用的对象native方法中引用的对象类静态属性、常量中引用的对象 对于一个 Java 程序而言，对象都位于堆内存块中，存活的那些对象都被根节点引用着，即根节点 GC Roots 是一些引用类型，自然不在堆里，那它们位于哪呢？它们能放在哪呢？答案是放在栈里，包括：Local variables 本地变量Static variables 静态变量JNI References JNI引用等 - gc垃圾收集器及其优缺点#垃圾回收器种类:Serial、ParNew、Parallel Scavenge、Serial Old、Parallel Old、CMS(ConCurrent Mark Sweep)、G1(Garbage First) - 标记算法和复制算法的区別，用在什么场合#CMS 标记清除、Serial Old，Parallel old 标记整理：适用于存活对象比较多的场景Serial、ParNew、PS 收集器 复制算法：用在那种不可达对象比较多的场合 - cms垃圾收集器的回收步骤及其优缺点？# cms回收器的标记过程: CMS以获取最短回收停顿时间为目标的收集器,使用“标记-清除”算法,分为以下6个步骤 1.STW initial mark:第一次暂停,初始化标记,从root标记old space存活对象(the set of objects reachable from roots (application code)) 2.Concurrent marking:运行时标记,从上一步得到的集合出发,遍历old space,标记存活对象 (all live objects that are transitively reachable from previous set) 3.Concurrent precleaning:并发的标记前一阶段被修改的对象(card table) 4.STW remark:第二次暂停,检查,标记,检查脏页的对象,标记前一阶段被修改的对象 (revisiting any objects that were modified during the concurrent marking phase) 5.Concurrent sweeping:运行过程中清理,扫描old space,释放不可到达对象占用的空间 6.Concurrent reset:此次CMS结束后,重设CMS状态等待下次CMS的触发 或者4个大步骤:1,initial mark 2,concurrent mark 3,remark 4,concurrent sweep CMS缺点：cpu敏感，浮动垃圾，空间碎片 1.CMS收集器对cpu资源非常敏感，在并发阶段对染不会导致用户线程停顿，但是会因为占用一部分线程导致应用程序变慢，总吞吐量会降低。CMS默认启动的收集线程数=(CPU数量+3)/4，在cpu数比较少的情况下，对性能影响较大。 2.CMS收集器无法处理浮动垃圾，可能会出现“Concurrent Mode Failure”失败而导致另一次Full GC，原因是CMS的并发清除阶段用户线程还是在运行，所以还会有新的垃圾不断产生，这些垃圾CMS只能在下次GC时再清理掉，这部分垃圾被称为“浮动垃圾”。所以CMS不能像其他收集器那样在老年代几乎完全被填满了在开始收集，需要预留一部分空间。JDK1.6中CMS将这个阈值提高到了92%，要是CMS运行期间预留的内存不足，会出现一次“Concurrent Mode Failure”，这是虚拟机启动备用方案，临时启用Serial Old收集器充满新进行老年代垃圾收集，所以这个阈值不宜设置的过高 3.CMS基于标记-清除算法，这意味着垃圾收集结束后会有大量的空间碎片，空间碎片过多会造成老年代有很大空间空余但是无法存放大对象的情况。通过参数UseCMSCompactAtFullCollection(默认开启)开关参数来开启内存碎片的合并整理。 - G1回收器的特点#G1的出现就是为了替换jdk1.5种出现的CMS,这一点已经在jdk9的时候实现了，jdk9默认使用了G1回收器，移除了所有CMS相关的内容。G1和CMS相比，有几个特点： G1把内存划分为多个独立的区域Region G1仍然保留分代思想,保留了新生代和老年代,但他们不再是物理隔离,而是一部分Region的集合 G1能够充分利用多CPU、多核环境硬件优势，尽量缩短STW G1整体采用标记整理算法,局部是采用复制算法,不会产生内存碎片 控制回收垃圾的时间：这个是G1的优势，可以控制回收垃圾的时间，还可以建立停顿的时间模型，选择一组合适的Regions作为回收目标，达到实时收集的目的。控制G1回收垃圾的时间 -XX:MaxGCPauseMillis=200 （默认200ms） G1跟踪各个Region里面垃圾的价值大小,会维护一个优先列表,每次根据允许的时间来回收价值最大的区域,从而保证在有限事件内高效的收集垃圾 大对象的处理: 在CMS内存中，如果一个对象过大，进入S1、S2区域的时候大于改分配的区域，对象会直接进入老年代。G1处理大对象时会判断对象是否大于一个Region大小的50%，如果大于50%就会横跨多个Region进行存放 - G1执行步骤# 初始标记阶段：暂停应用程序，标记可由根直接引用的对象。 并发标记阶段：与应用程序并发进行，扫描 1 中标记的对象所引用的对象。 最终标记阶段：暂停应用程序，扫描 2 中没有标记的对象。本步骤结束后，堆内所有存活对象都会被标记。 筛选回收（首先对各个Regin的回收价值和成本进行排序，根据用户所期待的GC停顿时间指定回收计划，回收一部分Region） - 内存泄漏与内存溢出的区别# 溢出： OOM，除了 PC 剩下的区域都会发生 OOM，是由于内存不够，或者是代码中错误的分配太多对象导致的。 泄漏：是指 内存分配后没有回收，导致内存占有一直增加，最后会导致溢出。 - 有几种gc fail？#Allocation Failure 新生代没有足够的空间分配对象 Young GC GCLocker Initiated GC 如果线程执行在JNI临界区时，刚好需要进行GC，此时GC locker将会阻止GC的发生，同时阻止其他线程进入JNI临界区，直到最后一个线程退出临界区时触发一次GC。 GCLocker Initiated GC Promotion Failure 老年代没有足够的连续空间分配给晋升的对象（即使总可用内存足够大） Concurrent Mode Failure CMS GC运行期间，老年代预留的空间不足以分配给新的对象 - 什么情况会触发fullgc？#1.metaspace空间不足 2.Promotion Failure 老年代没有足够的连续空间分配给晋升的对象（即使总可用内存足够大） 3.Concurrent Mode Failure CMS GC运行期间，老年代预留的空间不足以分配给新的对象 4.System.gc 5.jmap -histo:live [pid] - 栈内存溢出#对虚拟机栈这个区域规定了两种异常状况： （1）如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError 异常；（2）如果虚拟机栈可以动态扩展（当前大部分的 Java 虚拟机都可动态扩展，只不过 Java 虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出 OutOfMemoryError 异常。（3）与虚拟机栈一样，本地方法栈区域也会抛出 StackOverflowError 和OutOfMemoryError 异常。 - 系统内存多大，留给操作系统2G，够吗？#16G内存 虚拟机 推荐配置12G堆， 更大的堆容易引起SWAP，SWAP使用过多会造成宕机 各分区的大小对GC的性能影响很大。如何将各分区调整到合适的大小，分析活跃数据的大小是很好的切入点。 活跃数据的大小是指，应用程序稳定运行时长期存活对象在堆中占用的空间大小，也就是Full GC后堆中老年代占用空间的大小 例如，根据GC日志获得老年代的活跃数据大小为300M， 总堆：1200MB = 300MB × 4 新生代：450MB = 300MB × 1.5 老年代： 750MB = 1200MB - 450MB https://tech.meituan.com/2017/12/29/jvm-optimize.html","link":"/2021/07/29/interview/jvm/"},{"title":"mysql","text":"- 什么情况下索引失效 - InnoDB 支持的索引类型 - innodb 锁 - 平时怎么创建索引的 - B+树和 B 树的区别，和红黑树的区别 - 如何优化sql - 什么是覆盖索引 - 为什么尽量不要用select *？ - 百万级数据分页查询优化 mysql隔离级别 - MVCC, 什么是快照读，什么是当前读 - 什么是当前读 - mysql数据库事务隔离级别，分別解決什么问题，next-key锁原理、如何解决幻读？ - RR RC区别 mysql其他 - 分库分表 - mysql的乐观锁、悲观锁实现 - 主从延迟怎么办 - binlog、redolog、undolog - 什么情况下索引失效# 不符合联合最左匹配 like前导模糊查询 （可以通过 REVERSE()函数来创建一个函数索引解决） 字段类型不匹配 索引字段施加函数 or的多个字段都要索引（只要有一个没有索引，就无法使用索引） != , &lt;&gt; is null, is not null, not in都会使索引失效 索引情况不好（索引列数据区分度太小，例如性别列），范围太大，扫表. - InnoDB 支持的索引类型# B+树索引： 全文索引：就是倒排索引仅能再char、varchar、text类型的列上面创建全文索引但是面对高级的搜索还是略显简陋，且性能问题也是担忧。 哈希索引：哈希索引在InnoDB中只是一种系统自动优化的功能Hash 索引仅仅能满足”=”,”IN”和”&lt;&gt;”查询，不能使用范围查询。Hash 索引无法被用来避免数据的排序操作。在MySQL运行的过程中，如果InnoDB发现，有很多SQL存在这类很长的寻路，并且有很多SQL会命中相同的页面(page)，InnoDB会在自己的内存缓冲区(Buffer)里，开辟一块区域，建立自适应哈希所有AHI，以加速查询。InnoDB的自使用哈希索引，更像“索引的索引” - innodb 锁#innodb 锁 - 平时怎么创建索引的# 选择区分度高的列做索引 根据查询场景、查询语句的查询条件设计索引 如果要为多列去创建索引，遵循最左匹配原则使用联合索引去创建 在长字符类型的字段上使用前缀索引，减少空间占用 扩展索引的时候尽量做追加，不是新建 - B+树和 B 树的区别，和红黑树的区别#为什么不用B树?:因为B树的所有节点都是包含键和值的,这就导致了每个几点可以存储的内容就变少了,出度就少了,树的高度会增高,查询的 时候磁盘I/O会增多,影响性能。由于B+Tree内节点去掉了data域,因此可以拥有更大的出度,拥有更好的性能。 和红黑树:B+树跟红黑树不用比，B+树的高很低，红黑树比不了。 - 如何优化sql# 让sql使用索引，如果查看sql使用索引情况，explain查看执行计划通过explain命令可以得到下面这些信息: 表的读取顺序，数据读取操作的操作类型哪些索引可以使用哪些索引被实际使用，表之间的引用，每张表有多少行被优化器查询等信息。 rows是核心指标，绝大部分rows小的语句执行一定很快。Extra字段几种需要优化的情况Using filesort 需要优化，MYSQL需要进行额外的步骤来对返回的行排序。Using temporary需要优化，发生这种情况一般都是需要进行优化的。mysql需要创建一张临时表用来处理此类查询Using where 表示 MySQL 服务器从存储引擎收到行后再进行“后过滤” 如果让sql使用到索引（符合建索引的几个原则） 最左前缀匹配原则 选择区分度高的列作为索引，区分度的公式是count(distinct col)/count(*) 索引列不能参与计算，保持列“干净”， 原因很简单，b+树中存的都是数据表中的字段值 尽量的扩展索引，不要新建索引 =和in可以乱序 - 什么是覆盖索引#覆盖索引就是把要查询出的列和索引是对应的，不做回表操作 - 为什么尽量不要用select *？# 返回了太多不需要的数据 无法覆盖索引（select * 走的是聚簇索引），需要回表 一个好的应用程序设计应当能够在 sql 中有准确的定义，从而减少歧义或者不必要的更改 - 百万级数据分页查询优化# 纯扫表：记录主键游标，记录上次最大主键Id，从该Id处开始扫 1select * from t where id &gt; max_id limit 100; 不记录游标只根据主键扫库, 不带where条件, 主键覆盖索引 + 子查询 1select * from t where id in (select id from usertb limit 7000000,100); 带where条件，联合覆盖索引 key(type, id) + 子查询 1select * from t where id in (select id from usertb where type=1 limit 7000000,100); 带where和orderby条件，联合覆盖索引key(a, b) + 子查询 1select * from t where id in (select id from usertb where a=1 order by b limit 7000000,100); 尽量保证不要出现大的offset，加一些条件过滤一，不应该使用limit跳过已查询到的数据，offset做无用功。实际工程中，要避免出现大页码的情况，尽量引导用户做条件过滤。 mysql隔离级别#- MVCC, 什么是快照读，什么是当前读#快照读: 即普通SELECT语句，既然是快照读，故 SELECT 的时候，会生成一个快照。 生成快照的时机：事务中第一次调用SELECT语句的时候才会生成快照，在此之前事务中执行的update、insert、delete操作都不会生成快照。 不同事务隔离级别下，快照读的区别： READ COMMITTED 隔离级别下，每次读取都会重新生成一个快照，所以每次快照都是最新的，也因此事务中每次SELECT也可以看到其它已commit事务所作的更改； REPEATED READ 隔离级别下，快照会在事务中第一次SELECT语句执行时生成，只有在本事务中对数据进行更改才会更新快照，因此，只有第一次SELECT之前其它已提交事务所作的更改你可以看到，但是如果已执行了SELECT，那么其它事务commit数据，你SELECT是看不到的。 RC的本质：每一条SELECT都可以看到其他已经提交的事务对数据的修改，只要事务提交，其结果都可见，与事务开始的先后顺序无关。RR的本质：第一条SELECT生成ReadView前，已经提交的事务的修改可见。 - 什么是当前读#https://mp.weixin.qq.com/s/w1DwsDDSxKfmFxcLOgG3Dw - mysql数据库事务隔离级别，分別解決什么问题，next-key锁原理、如何解决幻读？#READ-UNCOMMITTED(未提交读): 可能会导致脏读、幻读或不可重复读READ-COMMITTED(提交读): 可以阻止脏读，但是幻读或不可重复读仍有可能发生REPEATABLE-READ(可重复读，mysql默认隔离级别): 可以阻止脏读和不可重复读，幻读通过mvcc解决了快照读，next-key锁解决了当前读SERIALIZABLE(串行化读): 该级别可以防止脏读、不可重复读以及幻读 - RR RC区别#区别就在于rr解决了不可重复读和幻读，怎么解决的，通过MVCC和next-key锁. 不可重复读：rc级别下的mvcc总是读取数据行的最新快照，而rr级别下的mvcc，会在事务第一次select的时候，为数据行生成一个快照，后面每次都读这个快照，除非自己更新，所以rr下是可重复读，别的事务提交也无法影响你的事务。 幻读：快照读下rr级别不会出现幻读，因为rr级别的mvcc读的是事务第一次读取时的快照；在当前读下rr级别使用了next-key锁（临键锁），临键锁包括行锁+间隙锁， 来避免两个当前读时有其它事务插入数据，所以当前读使用next-key锁解决的幻读。 最后备注下：如果是先快照读再当前读，影响行数不一致是否属于幻读，是有争议的但大多认为并不是幻读。 RC的本质：每一条SELECT都可以看到其他已经提交的事务对数据的修改，只要事务提交，其结果都可见，与事务开始的先后顺序无关。RR的本质：第一条SELECT生成ReadView前，已经提交的事务的修改可见。 mysql其他#- 分库分表#根据userid取模做的分库分表 两个场景，业务解耦垂直拆分，读写性能瓶颈做水平拆分。 垂直切分 业务维度切分，解耦 水平切分 读写性能遇到瓶颈，分库分表 - mysql的乐观锁、悲观锁实现#MySQL乐观锁的实现完全是逻辑的，也就是自己去实现。 比如给每条数据附带版本号或者timestamp。更新引起数据的版本号改变，两次select判断版本号是否一致可以判断是否发生改变 MySQL悲观锁的实现需要借助于MySQL的锁机制。行锁常见的增删改（INSERT、DELETE、UPDATE）语句会自动对操作的数据行加写锁，查询的时候也可以明确指定锁的类型，SELECT … LOCK IN SHARE MODE 语句加的是读锁，SELECT … FOR UPDATE 语句加的是写锁行锁的实现方式1) Record lock 锁记录2) Gap lock 锁两个记录之间的 GAP，防止记录插入3) Next-key lock 锁一条记录及其之前的间隙 - 主从延迟怎么办#主从延迟的原因：主库写入数据并且生成binlog文件， 从库异步读取更新 解决方案：一、更新操作，做SQL优化，减少批量更新操作二、查询场景， 强制读主，对主库压力大，谨慎使用 延迟读从, 将要更新的key先放到一个本地延迟队列中，做延迟处理。 聚合表, 如果是1:1的两张数据，可以先订阅更新到一张聚合表，再订阅聚合表的binlog 订阅全部从库的binlog, todo - binlog、redolog、undolog#binlog 一致性。用于主从复制和指定时间范围的数据恢复redolog 保证持久性。log用于保证持久化，恢复在内存更新后，还没来得及刷到磁盘的数据undolog 原子性。用于实现事务回滚和mvcc多版本并发控制","link":"/2021/07/29/interview/mysql/"},{"title":"gc日志","text":"一、gc日志#虽然有falcon，但gc日志在查问题时对一次gc更加直观 1、初步观察#略 2、简单聊下 ParNew and CMS#我们使用的垃圾收集器是 parnew + cms ， 使用参数 -XX:+UseConcMarkSweepGC 配置不同的垃圾收集器：经典回顾：JVM-探究（二）：JVM实验和 GC 日志解读 ParNew and CMS 响应时间优先的选择 “Concurrent Mark and Sweep” 是CMS的全称 年轻代：采用 stop-the-world mark-copy 算法； 年老代：采用 Mostly Concurrent mark-sweep 算法； 设计目标：年老代收集的时候避免长时间的暂停， 响应时间优先。 吞吐量 VS 暂停时间 7种垃圾收集器比较 能够达成该目标主要因为以下两个原因： 1 它不会花时间整理压缩年老代，而是维护了一个叫做 free-lists 的数据结构，该数据结构用来管理那些回收再利用的内存空间； 2 mark-sweep分为多个阶段，其中一大部分阶段GC的工作是和Application threads的工作同时进行的（当然，gc线程会和用户线程竞争CPU的时间），默认的GC的工作线程为你服务器物理CPU核数的1/4； 补充：当你的服务器是多核同时你的目标是低延时，那该GC的搭配则是你的不二选择。 3、打印gc日志命令# 命令 作用（默认都为关闭） -XX:+PrintGCDetails 1打印GC的详细信息 -XX:+PrintHeapAtGC 2在GC前后输出GC堆的概要状况 -XX:+PrintTenuringDistribution 3打印GC后新生代各个年龄对象的大小 -XX:+PrintGCTimeStamps 4输出GC的时间戳（以基准时间的形式） -XX:+PrintGCDateStamps 5输出GC的时间戳（以日期的形式） 示例: 4、younggc# 2016-08-23T02:23:07.219-02001: 64.3222:[GC3(Allocation Failure4) 64.322: [ParNew5: 613404K-&gt;68068K6(613440K)7, 0.1020465 secs8] 10885349K-&gt;10880154K9(12514816K)10, 0.1021309 secs11][Times: user=0.78 sys=0.01, real=0.11 secs]12 2016-08-23T02:23:07.219-0200 – GC发生的时间； 64.322 – GC开始，相对JVM启动的相对时间，单位是秒； GC – 区别MinorGC和FullGC的标识，这次代表的是MinorGC; Allocation Failure – MinorGC的原因，在这个case里边，由于年轻代不满足申请的空间，因此触发了MinorGC; minor gc的原因都有什么？ ParNew – 收集器的名称，它预示了年轻代使用一个并行的 mark-copy stop-the-world 垃圾收集器； 613404K-&gt;68068K – 收集前后年轻代的使用情况； (613440K) – 整个年轻代的容量； 0.1020465 secs – 表示该区域这次 GC 使用的时间 10885349K-&gt;10880154K – 收集前后整个堆的使用情况； (12514816K) – 整个堆的容量； 0.1021309 secs – 表示 Java堆 这次 GC 使用的时间. ParNew收集器标记和复制年轻代活着的对象所花费的时间（包括和老年代通信的开销、对象晋升到老年代时间、垃圾收集周期结束一些最后的清理对象等的花销）； [Times: user=0.78 sys=0.01, real=0.11 secs] – GC事件在不同维度的耗时，具体的用英文解释起来更加合理: user – Total CPU time that was consumed by Garbage Collector threads during this collection sys – Time spent in OS calls or waiting for system event real – Clock time for which your application was stopped. With Parallel GC this number should be close to (user time + system time) divided by the number of threads used by the Garbage Collector. In this particular case 8 threads were used. Note that due to some activities not being parallelizable, it always exceeds the ratio by a certain amount. younggc的原因： Allocation Failure 新生代没有足够的空间分配对象 GCLocker Initiated GC 如果线程执行在JNI临界区时，刚好需要进行GC，此时GC locker将会阻止GC的发生，同时阻止其他线程进入JNI临界区，直到最后一个线程退出临界区时触发一次GC 5、cmsgc &amp; fullgc#12345678910111213142013-11-27T04:00:12.819+0800: 38892.743: [GC [1 CMS-initial-mark: 1547313K(2146304K)] 1734957K(4023680K), 0.1390860 secs] [Times: user=0.14 sys=0.00, real=0.14 secs]2013-11-27T04:00:12.958+0800: 38892.883: [CMS-concurrent-mark-start]2013-11-27T04:00:19.231+0800: 38899.155: [CMS-concurrent-mark: 6.255/6.272 secs] [Times: user=8.49 sys=1.57, real=6.27 secs]2013-11-27T04:00:19.231+0800: 38899.155: [CMS-concurrent-preclean-start]2013-11-27T04:00:19.250+0800: 38899.175: [CMS-concurrent-preclean: 0.018/0.019 secs] [Times: user=0.02 sys=0.00, real=0.02 secs]2013-11-27T04:00:19.250+0800: 38899.175: [CMS-concurrent-abortable-preclean-start] CMS: abort preclean due to time 2013-11-27T04:00:25.252+0800: 38905.176: [CMS-concurrent-abortable-preclean: 5.993/6.002 secs] [Times: user=6.97 sys=2.16, real=6.00 secs]2013-11-27T04:00:25.253+0800: 38905.177: [GC[YG occupancy: 573705 K (1877376 K)]38905.177: [Rescan (parallel) , 0.3685690 secs]38905.546: [weak refs processing, 0.0024100 secs]38905.548: [class unloading, 0.0177600 secs]38905.566: [scrub symbol &amp; string tables, 0.0154090 secs] [1 CMS-remark: 1547313K(2146304K)] 2121018K(4023680K), 0.4229380 secs] [Times: user=1.41 sys=0.01, real=0.43 secs]2013-11-27T04:00:25.676+0800: 38905.601: [CMS-concurrent-sweep-start]2013-11-27T04:00:26.436+0800: 38906.360: [CMS-concurrent-sweep: 0.759/0.760 secs] [Times: user=1.06 sys=0.48, real=0.76 secs]2013-11-27T04:00:26.436+0800: 38906.360: [CMS-concurrent-reset-start]2013-11-27T04:00:26.441+0800: 38906.365: [CMS-concurrent-reset: 0.005/0.005 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] cms gc 过程 cms gc 和 full gc的关系 新生代老年代gc日志 foreground collect fullgc 的原因 没有配置 -XX:+DisableExplicitGC情况下System.gc()可能会触发FullGC； Promotion failed； （cms下会触发cms gc, 非full gc） concurrent mode failure； Metaspace Space使用达到MaxMetaspace阈值； (cms 下回触发cms gc, 非full gc) 执行jmap -histo:live或者jmap -dump:live Promoration failure 有足够的空间，但是由于碎片化严重，无法容纳新生代中晋升的对象，发生晋升失败， 触发cms gc的foreground cmsgc CMS提供了两个参数来对碎片进行整理和压缩 -XX:+UseCMSCompactAtFullCollection这个设置的作用是在进行FullGC的时候对碎片进行整理和压缩。 -XX:CMSFullGCsBeforeCompaction=*这个参数是设置在进行多少次FullGC的时候对老年代的内存进行一次碎片整理压缩. 122013-11-27T03:00:53.638+0800: 35333.562: [GC 35333.562: [ParNew (promotion failed): 1877376K-&gt;1877376K(1877376K), 15.7989680 secs]35349.361: [CMS: 2144171K-&gt;2129287K(2146304K), 10.4200280 secs] 3514052K-&gt;2129287K(4023680K), [CMS Perm : 119979K-&gt;118652K(190132K)], 26.2193500 secs] [Times: user=30.35 sys=5.19, real=26.22 secs] Concurrent Mode Failure 此错误就是在CMS GC的过程中，又有对象需要放到old区，但是old区空间不足了，放不下了就报了此错误。 导致concurrent mode failure的原因有是： there was not enough space in the CMS generation to promote the worst case surviving young generation objects. We name this failure as “full promotion guarantee failure” 解决的方案有： The concurrent mode failure can either be avoided increasing the tenured generation size or initiating the CMS collection at a lesser heap occupancy by setting CMSInitiatingOccupancyFraction to a lower value and setting UseCMSInitiatingOccupancyOnly to true. systm.gc 12013-07-21T17:44:01.554+0800: 50.568: [Full GC (System) 50.568: [CMS: 943772K-&gt;220K(2596864K), 2.3424070 secs] 1477000K-&gt;220K(4061184K), [CMS Perm : 3361K-&gt;3361K(98304K)], 2.3425410 secs] [Times: user=2.33 sys=0.01, real=2.34 secs]","link":"/2019/02/14/jvm/gclog/"},{"title":"redis_2021","text":"- redis支持的基础数据类型 - redis支持的对象及实现方式 - rediis 为什么快 - redis的过期删除策略 - 跳表 - redis的内存淘汰机制 - 如果redis有热点key怎么解决 - redis缓存击穿、缓存穿透、缓存雪崩怎么解决 - redis执行一条命令的过程 - select epoll - redis主从同步过程 - redis主从 故障转移 failover sentinel Raft协议 - redis高可用 - RDB 和 AOF - AOF重写机制 - redis支持的基础数据类型#SDS （Simple Dynamic String）是 Redis 最基础的数据结构。直译过来就是”简单的动态字符串“。链表：自定义双向链表：listNode跳跃表：skipList. 链表的一种，是一种利用空间换时间的数据结构。跳表平均支持 O(logN)，最坏O(N)复杂度的查找。压缩链表：为了尽可能节约内存设计出来的双向链表。字典： hashint, intset: 数字集合 - redis支持的对象及实现方式#String 最常规的get/set操作，value可以是数字和string 一般做一些复杂的计数功能的缓存sds string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000 hash value存放的是结构化的对象比较方便的就是操作其中的某个字段在做单点登录的时候，就是用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果 Redis 的 hash 表 使用 ziplist 和 字典 实现的。键值对的键和值都小于 64 个字节, 键值对的数量小于 512。都满足的时候使用 ziplist，否则使用字典。 list 使用List的数据结构，可以做简单的消息队列的功能还有一个是，利用lrange命令，做基于redis的分页功能，性能极佳，用户体验好一个场景，很合适—取行情信息。就也是个生产者和消费者的场景。LIST可以很好的完成排队，先进先出的原则。 底层是一个 ziplist 或者 linkedlist。当列表对象保存的字符串元素的长度都小于64字节。保存的元素数量小于512个。 set set堆放的是一堆不重复值的集合。所以可以做全局去重的功能为什么不用JVM自带的Set进行去重？因为我们的系统一般都是集群部署，使用JVM自带的Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能 Redis 的集合底层是一个 intset 或者 一个字典（hashtable）。这个比较容易理解：当集合都是整数且不超过512个的时候，就使用intset。剩下都是用字典。 zset (sorted set) sorted set多了一个权重参数score,集合中的元素能够按score进行排列。可以做排行榜应用，取TOP N操作。 Redis 的有序集合使用 ziplist 或者 skiplist 实现的。元素小于 128 个每个元素长度 小于 64 字节。同时满足以上条件使用ziplist，否则使用skiplist。 - rediis 为什么快#官方给出的数字是读写性能可以打到10W/秒 Redis所有数据都是放在内存中的 Redis使用了单线程架构，预防了多线程可能产生的竞争问题 Redis的IO多路复用，实现Reactor模型 - redis的过期删除策略#定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略. 定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除 于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。 - 跳表#https://blog.csdn.net/qq_34412579/article/details/101731935 - redis的内存淘汰机制#在Redis内存使用达到设定上限时，触发满容淘汰策略释放内存 Redis 目前提供8种策略： volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 volatile-random：从已设置过期时间的数据集中任意选择数据淘汰 volatile-lfu：从已设置过期时间的数据集中挑选最不经常使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的） allkeys-random：从数据集中任意选择数据淘汰 allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！ - 如果redis有热点key怎么解决#本地缓存, 拆分：eg: 按日期拆分、根据业务拆分 - redis缓存击穿、缓存穿透、缓存雪崩怎么解决#缓存穿透 定义: 访问一个不存在的key，缓存不起作用，请求会穿透到DB，流量大时DB会挂掉。 解决方案： 缓存空值 （值少时） 布隆过滤器， 特性: 没有的肯定没有，有的不一定有 缓存击穿 定义：并发性,一个存在的key，在缓存过期的一刻，同时有大量的并发请求，这些请求都会击穿到DB，造成瞬时DB请求量大、压力骤增。 解决方案： 分布式锁，在访问key之前，采用分布式锁SETNX（set if not exists）来设置另一个短期key来锁住当前key的访问，访问结束再删除该短期key 双重缓存，设置不同过期，其实同时解决了key过热 和 缓存击穿问题，如果更新的操作确实很耗时，返回的有损请求比较多，那确实需要双重缓存了，再放一份到本地、分布式缓存的另一个key 缓存雪崩 定义：大量的key设置了相同的过期时间，或者某台服务器宕机，导致大量缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。 解决方案： 提前预防，主从加集群，主从可以一个实例挂了，另一个可以顶上。集群数据分片，即使一个分片上的主从都挂了，打到db的量也不会是全部 将key的过期时间设置时添加一个随机时间，分散过期时间 如果是热点key，可以加分布式锁，减少并发量 二级缓存（本地缓存），减少db压力 击穿是单个，必定是热点key，雪崩是很多，不一定是热点key，对应的解决方案也有不一样的地方，雪崩有一个设置过期时间加随机数，雪崩用二级缓存比较好使，但击穿就没太大必要 - redis执行一条命令的过程#整体： 第一步是建立连接阶段，响应了socket的建立，并且创建了client对象； 第二步是处理阶段，从socket读取数据到输入缓冲区，然后解析并获得命令，执行命令并将返回值存储到输出缓冲区中； 第三步是数据返回阶段，将返回值从输出缓冲区写到socket中，返回给客户端，最后关闭client 细节： 客户端向服务端发起建立 socket 连接的请求，那么监听套接字将产生 AE_READABLE 事件，触发连接应答处理器执行。处理器会对客户端的连接请求进行应答，然后创建客户端套接字，以及客户端状态，并将客户端套接字的 AE_READABLE 事件与命令请求处理器关联。 客户端建立连接后，向服务器发送命令，那么客户端套接字将产生 AE_READABLE 事件，触发命令请求处理器执行，处理器读取客户端命令，然后传递给相关程序去执行。 执行命令获得相应的命令回复，为了将命令回复传递给客户端，服务器将客户端套接字的 AE_WRITEABLE 事件与命令回复处理器关联。当客户端试图读取命令回复时，客户端套接字产生 AE_WRITEABLE 事件，触发命令回复处理器将命令回复全部写入到套接字中 个人理解： 所有事件都是注册在一个aeEventLoop上，aeEventLoop里面是事件数组 事件监听的是socket的文件描述符，socket分server和client，连接事件监听serversocket, 建立client之后注册读事件监听clientsocket, 执行完之后注册写事件监听clientsocket 每个client有个输入输出缓冲区方便数据就绪关键点就是他娘的用了IO多路复用，提升执行效率 - select epoll#select 是轮询所有的文件描述符epoll 是走回调，能支持的数量更多，效率更高 - redis主从同步过程# 对于master 首先slave向master发起sync同步命令，这一步在slave启动后触发，master被动的将新的salve加入到自己的主备复制集群。 master在收到sync后开启BGSAVE命令，BGSAVE是Redis的一种全量模式的持久化机制 BGSAVE完成后，master将快照信息发给salve。 发送期间，master收到来自客户端新的写命令，除了正常的响应之外，都存入一份back-log队列 快照信息发送完成后，master继续发送backlog命令 backlog发送完成后，后续的写操作同时发送给salve，保持实时的异步复制 对于slave 发送完sync命令后，继续对外提供服务。 开始接收master的快照信息，此时，slave将现有数据清空，并将master快照写入内存 接收backlog内容并执行，也就是回放，期间对外提供读请求 继续接收后续来自master的命令副本，并继续回放，保持数据和master数据一致。 如果有多个slave节点并发发送sync命令给master，企图建立主备关系，只要第二个salve的sync命令发生在master完成BGSAVE之前，第二个salve将收到和第一个salve相同的快照和后续backlog，否则第二个salve的sync将触发master的第二次BGSAVE 断点续传 (部分重同步)Redis支持PSYNC用于替代SYNC，做到基于断点续传的主备同步协议，master和slave两端通过维护一个offset记录当前已经同步过的命令，slave断开期间，master的客户端命令保存在缓存中，salve重连之后，告知master断开时的最新offset，master则将缓存中大于offset的数据发送给slave。 - redis主从 故障转移 failover sentinel Raft协议#failover决策当一台master宕机后，要发起failover流程。其中只有一个sentinel节点可以作为failover的发起者，让他作为leader主导选举。Redis的sentinel leader选举机制采用类似raft协议实现这个选举算法。 sentinelState的epoch变量类似于raft协议中的term（选举回合） 每一个确认了master“客观不可用”的sentinel节点都会向周围广播自己的参选请求 每一个收到参选请求的sentinel节点如果还没人向他发送过参选请求，它就将本回合的意向置为第一个参选sentinel并回复他，如果本回合内回复过意向，那么拒绝所有参选请求，并将已有意向回复给参选的的sentinel 每个发送参选请求的sentinel节点，如果收到了超过一半的意向同意某个的sentinel参选（可能是本人），那么将成为leader，如果回合内进行了长时间还没有选出leader，那么进行下一个回合。 leader sentinel确定了之后，从所有的slave中依据一定的规则选一个新的master，并告知其他slave连接这个新的master。新master的选举规则 过滤不健康（主观下线，断线），5秒内没有回复过sentinel节点ping相应，与主节点失联超过down-after-millisecond*10 时间的 选择slave-priority最高的从节点列表，如果存在返回，否则继续 选择复制偏移量最大的从节点， 选择runid最小的从节点 如果多个回合还没有选出leader sentinel，怎么办？选举过程非常快，一般谁先判断出主观下线谁就是leader - redis高可用#高可用（主从、哨兵、集群） - RDB 和 AOF#RDB 将数据库的快照（snapshot）以二进制的方式保存到磁盘中。AOF 则以协议文本的方式，将所有对数据库进行过写入的命令（及其参数）记录到 AOF 文件，以此达到记录数据库状态的目的。 AOF参数设置，通过appendonly参数设置为yes开启AOF，同步策略参数默认是appendfsync everysec每秒将aof缓冲区的内容同步到磁盘的aof文件中。也可以配置参数apendfsync为always，这样每次写入都会立即同步磁盘，但是性能影响大，我们使用的是默认的everysec每秒。 RDB快照默认是开启的，默认每15分钟进行一次快照。快照的实现是通过fork父进程，生成一个子进程，父进程继续处理client请求，子进程把内存数据写到临时rdb文件，因为os的copy on write, 父子进程共享物理页面，父进程写的时候会为父进程创建副本去写，子进程的地址空间内数据是fork时刻的整个数据库的一个快照。当写入完毕后，用临时文件替换原文件，子进程退出。 so，rdb快照生成是不影响master处理client请求的，是通过fork子进程的方式操作的，aof的重写也是用了这种fork子进程的方式，最后将临时文件替换原文件。 - AOF重写机制#what: 创建一个新的 AOF 文件来代替原有的 AOF 文件， 新 AOF 文件和原有 AOF 文件保存的数据库状态完全一样， 但新 AOF 文件的体积小于等于原有 AOF 文件的体积。why: 有些被频繁操作的键， 对它们所调用的命令可能有成百上千、甚至上万条， 如果这样被频繁操作的键有很多的话， AOF 文件的体积就会急速膨胀， 对 Redis 、甚至整个系统的造成影响how:AOF 重写并不需要对原有的 AOF 文件进行任何写入和读取， 它针对的是数据库中键的当前值。 重写使用子进程子进程进行 AOF 重写期间，主进程可以继续处理命令请求。子进程带有主进程的数据副本，使用子进程而不是线程，可以在避免锁的情况下，保证数据的安全性。 主进程工作 处理命令请求。 将写命令追加到现有的 AOF 文件中。 将写命令追加到 AOF 重写缓存中。 当子进程完成 AOF 重写之后， 它会向父进程发送一个完成信号， 父进程在接到完成信号之后， 会调用一个信号处理函数， 并完成以下工作： 将 AOF 重写缓存中的内容全部写入到新 AOF 文件中。 对新的 AOF 文件进行改名，覆盖原有的 AOF 文件。","link":"/2021/07/31/interview/redis/"},{"title":"spring","text":"- 谈谈对springIoc的了解 - 谈谈对springAop的了解 - 动态代理和静态代理的区别 - Java反射的原理 - spring中的设计模式 简单工厂模式 工厂方法模式 单例模式 代理设计模式 适配器模式 模板方法模式 - spring aspect advice pointcut理解 Springboot启动原理 Springioc解决循环依赖问题 - 谈谈对springIoc的了解# 如何完美阐述你对IOC的理解？ // 最底层map: Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap(256); 个人理解： 1.控制反转是一种设计思想，将对象生命周期和依赖的控制由对象转给了ioc容器，对象由主动创建其它对象变为被动由ioc容器注入 2.springioc容器控制了对象的创建、销毁及整个生命周期，，可以动态注入依赖的对象 3.将对象与对象间解耦，对象不再直接创建依赖其它对象，都依赖springioc容器 扩展：springIoc的初始化过程 它负责业务对象的构建管理和业务对象间的依赖绑定。 - 谈谈对springAop的了解# AOP为面向切面编程，底层是通过动态代理实现，实质上就是将相同逻辑的重复代码横向抽取出来, 拦截对象方法，对方法进行改造、增强！比如在 方法执行前、方法返回后、方法前后、方法抛出异常后 等地方进行一定的增强处理，应用场景： 事务、日志、权限、监控打点 基于动态代理来实现，在容器启动的时候生成代理实例。默认地，如果使用接口的，用 JDK 提供的动态代理实现，如果没有接口，使用 CGLIB 实现 优点：每个关注点现在都集中于一处，而不是分散到多处代码中；服务模块更简洁，服务模块只需关注核心代码 @Pointcut(切点)：用于定义哪些方法需要被增强或者说需要被拦截 @Before、@After、@Around、@AfterReturning、@AfterThrowing（增强）: 添加到切点指定位置的一段逻辑代码 注：@AfterReturning 比 @After 的方法参数多被代理方法的返回值 参考： Spring AOP 使用介绍，从前世到今生 Spring AOP就是这么简单啦 - 动态代理和静态代理的区别#静态代理在运行之前就已经存在代理类的字节码文件了（.class文件），而动态代理是在运行时通过反射技术来实现的 静态代理，如果不同接口的类想使用代理模式来实现相同的功能，将要实现多个代理类，但在动态代理中，只需要一个代理类就好了。 只有实现了某个接口的类可以使用Java动态代理机制，对于没有实现接口的类，就不能使用该机制。使用cglib。 静态代理：代理类与委托类实现同一接口，并且在代理类中需要硬编码接口 JDK动态代理：代理类与委托类实现同一接口，主要是通过代理类实现InvocationHandler并重写invoke方法来进行动态代理的，在invoke方法中将对方法进行增强处理 CGLIB动态代理：代理类将委托类作为自己的父类并为其中的非final委托方法创建两个方法，一个是与委托方法签名相同的方法，它在方法中会通过super调用委托方法；另一个是代理类独有的方法。在代理方法中，它会判断是否存在实现了MethodInterceptor接口的对象，若存在则将调用intercept方法对委托方法进行代理 - Java反射的原理#反射就是在运行时才知道要操作的类是什么，并且可以在运行时获取类的完整构造，并调用对应的方法 Java反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能就称为反射机制。 通俗一点反射就是把Java类中的各种成分映射成一个个的Java对象。 操作步骤: 获取类的 Class 对象实例 根据 Class 对象实例获取 Constructor 对象 使用 Constructor 对象的 newInstance 方法获取反射类对象 获取方法的 Method 对象 利用 invoke 方法调用方法 为什么类可以动态的生成？这就涉及到Java虚拟机的类加载机制了，推荐翻看《深入理解Java虚拟机》7.3节 类加载的过程。Java虚拟机类加载过程主要分为五个阶段：加载、验证、准备、解析、初始化。其中加载阶段需要完成以下3件事情： 通过一个类的全限定名来获取定义此类的二进制字节流将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类的各种数据访问入口 关于第1点，获取类的二进制字节流（class字节码）就有很多途径动态代理就是想办法，根据接口或目标对象，计算出代理类的字节码，然后再加载到JVM中使用。但是如何计算？如何生成？情况也许比想象的复杂得多，我们需要借助现有的方案 通常使用反射，是想灵活的获取或操作obj的属性或方法信息，而不和具体的某个类耦合。这个时候，只要拿到类的Class对象，就可以获取对象的属性，和执行方法，或者new一个instance。eg: excel导出， 泛型属性解析。 - spring中的设计模式#简单工厂模式#简单工厂模式的实质是由一个工厂类根据传入的参数，动态决定应该创建哪一个产品类。spring中的BeanFactory就是简单工厂模式的体现，根据传入一个唯一的标识来获得bean对象，但是否是在传入参数后创建还是传入参数前创建这个要根据具体情况来定。 工厂方法模式#工厂方法将创建产品的代码与实际使用产品的代码分离， 从而能在不影响其他代码的情况下扩展产品创建部分代码。例如， 如果需要向应用中添加一种新产品， 你只需要开发新的创建者子类， 然后重写其工厂方法即可。 一般情况下,应用程序有自己的工厂对象来创建bean.如果将应用程序自己的工厂对象交给Spring管理, 那么Spring管理的就不是普通的bean,而是工厂Bean。理解：通过扩展工厂子类的方式，调用其工厂方法创建新对象。 单例模式#保证一个类仅有一个实例，并提供一个访问它的全局访问点。spring中的单例模式完成了后半句话，即提供了全局的访问点BeanFactory。但没有从构造器级别去控制单例，这是因为spring管理的是是任意的java对象。 Spring下默认的bean均为singleton，可以通过singleton=“true|false” 或者 scope=”?”来指定。 代理设计模式#Spring AOP 功能的实现。 适配器模式#springaop中的advice，需要适配成 MethodInterceptor 接口，才能组成一条拦截器链，做依次的织入。不同的Advice需要通过 不同适配器（XXXAdviceInterceptor） 适配成一个个 MethodInterceptor。使用适配器模式，持有advice实例，实现MethodInterceptor 接口。 我们知道 Spring AOP 的实现是基于代理模式，但是 Spring AOP 的增强或通知(Advice)使用到了适配器模式，与之相关的接口是AdvisorAdapter 。Advice 常用的类型有：BeforeAdvice（目标方法调用前,前置通知）、AfterAdvice（目标方法调用后,后置通知）、AfterReturningAdvice(目标方法执行结束后，return之前)等等。每个类型Advice（通知）都有对应的拦截器:MethodBeforeAdviceInterceptor、AfterReturningAdviceAdapter、AfterReturningAdviceInterceptor。Spring预定义的通知要通过对应的适配器，适配成 MethodInterceptor接口(方法拦截器)类型的对象（如：MethodBeforeAdviceInterceptor 负责适配 MethodBeforeAdvice）。 参考文档：https://www.jianshu.com/p/57d3d1beeb62 模板方法模式#JDBCTemplate使用了模板方法 + 回调模式。把直接执行statment的操作延迟到子类实现，通过回调函数的方式传递进来，父类实现对连接和异常的处理等操作。execute中接收一个 StatementCallback 的回调函数，子类只要传递自己处理statment获取结果的回调函数即可，不需要再写过多的重复代码。 12345@FunctionalInterfacepublic interface StatementCallback&lt;T&gt; { @Nullable T doInStatement(Statement var1) throws SQLException, DataAccessException;} execute实现（调用回调函数StatementCallback#doInStatement） 1234567891011121314151617181920212223242526272829303132@Nullablepublic &lt;T&gt; T execute(StatementCallback&lt;T&gt; action) throws DataAccessException { //参数检查 Assert.notNull(action, \"Callback object must not be null\"); //获取连接 Connection con = DataSourceUtils.getConnection(this.obtainDataSource()); Statement stmt = null; Object var11; try { //创建一个Statement stmt = con.createStatement(); //设置查询超时时间，最大行等参数（就是一开始那些成员变量） this.applyStatementSettings(stmt); //执行回调方法获取结果集 T result = action.doInStatement(stmt); //处理警告 this.handleWarnings(stmt); var11 = result; } catch (SQLException var9) { //出现错误优雅退出 String sql = getSql(action); JdbcUtils.closeStatement(stmt); stmt = null; DataSourceUtils.releaseConnection(con, this.getDataSource()); con = null; throw this.translateException(\"StatementCallback\", sql, var9); } finally { JdbcUtils.closeStatement(stmt); DataSourceUtils.releaseConnection(con, this.getDataSource()); } return var11;} update方法详解（使用lambda函数传递更新的实现操作） 123456789101112131415161718192021protected int update(PreparedStatementCreator psc, @Nullable PreparedStatementSetter pss) throws DataAccessException { this.logger.debug(\"Executing prepared SQL update\"); return updateCount((Integer)this.execute(psc, (ps) -&gt; { Integer var4; try { if (pss != null) { pss.setValues(ps); } int rows = ps.executeUpdate(); if (this.logger.isTraceEnabled()) { this.logger.trace(\"SQL update affected \" + rows + \" rows\"); } var4 = rows; } finally { if (pss instanceof ParameterDisposer) { ((ParameterDisposer)pss).cleanupParameters(); } } return var4; })); } JDBCTemplate使用了很多回调。为什么要用回调（Callback)?如果父类有多个抽象方法，子类需要全部实现这样特别麻烦，而有时候某个子类只需要定制父类中的某一个方法该怎么办呢？这个时候就要用到Callback回调了就可以完美解决这个问题，可以发现JDBCTemplate并没有完全拘泥于模板方法，非常灵活。我们在实际开发中也可以借鉴这种方法。 参考文档：https://juejin.cn/post/6844903847966703624#heading-5 - spring aspect advice pointcut理解#1、adivisor是一种特殊的Aspect，Advisor代表spring中的Aspect2、区别：advisor只持有一个Pointcut和一个advice，而aspect可以多个pointcut和多个advice 方/切 面（Aspect）：一个关注点的模块化，这个关注点实现可能另外横切多个对象。事务管理是J2EE应用中一个很好的横切关注点例子。方面用Spring的Advisor或拦截器实现。 连接点/织入点（Joinpoint）：程序执行过程中明确的点，如方法的调用或特定的异常被抛出。 通知（Advice）：在特定的连接点，AOP框架执行的动作。各种类型的通知包括“around”、“before”和“throws”通知。 切入点（Pointcut）：指定一个通知将被引发的一系列连接点的集合。AOP框架必须允许开发者指定切入点，例如，使用正则表达式。 Springboot启动原理#springboot在启动时除了spring context容器启动的流程，还加入了通过spi实现的根据依赖自动装配的机制。springboot容器启动的流程，先初始化事件监听器，加载环境信息，创建applicationContext容器，执行applicationInitializer的initialize方法，在容器refresh时，会通过spi机制获取到所有的autoConfiguration类（解析spring.factotries文件）并加载配置类中相关bean注入context容器，完成自动装配。 Springioc解决循环依赖问题#使用中间缓存，使用二级缓存earlySingletonObjects，三级缓存singletonFactories一起解决的循环依赖问题。earlySingletonObjects就是一个临时存放初始bean的缓存。singletonFactories是会在获取依赖的A时，调用一个wrapIfNessasory来获得一个aop后的A, 从而解决循环依赖aop bean的问题。注：springioc只能解决set注入的循环依赖问题，无法解决构造方法注入的循环依赖问题，因为A在构造时依赖B，B在构造获取A的时候，A都还没有创建出来，没有能放到一个中间缓存解决循环依赖的机会。","link":"/2021/07/29/interview/spring/"},{"title":"Innodb索引原理及其优化","text":"一、目的#了解索引结构，explain方法，优化原理 二、索引名词#2.1 聚簇索引# 聚簇索引也称为聚集索引，聚类索引，簇集索引，聚簇索引的顺序就是数据的物理存储顺序。 由于聚簇索引规定数据在表中的物理存储顺序，因此一个表只能包含一个聚簇索引。 Innodb聚簇索引根据每张表的主键构造一棵B+树，叶子节点中存放的即为整张表的行记录数据，也称为数据页。 对于主键的排序查找和范围查找速度非常快。叶子节点的数据就是用户所要查询的数据 把非顺序的字段当主键，肯定会因为插入，删除，造成数据位置的更新，插入可能会页分裂，留下碎片，浪费资源空间。 我们都是自增id当主键，把时间当做主键呢？ 1、自增id占用存储空间小，一索引页可存更多 2、时间会有并发问题，时间+随机数也行，但占的空间会更大，会增加读取索引页数，增加io 3、如果该表的需求主要就是按时间查找，用时间(+随机数)的方式也不错。 如果时间不常变化的话。 2.2 非聚簇索引#非聚簇索引记录的物理顺序和索引的顺序无关。（MyISAM存储引擎） 非聚簇索引和聚簇索引的优缺点？ 聚簇索引，主键的插入速度要比非聚簇索引主键的插入速度慢很多，要维护数据的位置。 聚簇索引数据根据主键聚成堆了适合排序，非聚簇索引则没有按序存放，需要额外消耗资源来排序。 我们其实很少用主键做范围查询 2.3 辅助索引#也称二级索引，叶子节点并不包含行记录的全部数据 辅助索引的书签就是相应行数据的聚集索引键 辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引。 为什么辅助索引叶子节点不直接指向数据页，还要走一遍主键索引？ 这样的策略减少了当出现行移动或者数据页分裂时二级索引的维护工作 2.4 覆盖索引#回表：就是在使用辅助索引时，因为辅助索引只存储了部分数据，如果根据键值查找到的数据不能包括全部目标数据时（就是无法使用到覆盖索引），就需要通过二级索引的指针，也就是键值对中的值，来找到聚簇索引的全部数据，然后根据完整的数据取出所需要的列的过程就称之为回表。这种在二级索引中不能找到所有需要的数据列的现象，被称为非覆盖索引，反之称为覆盖索引。 因为回表本身是需要去另一个索引（聚簇索引）中查找数据的，性能必然会受到影响，那为了尽可能的提高性能就需要尽量的减少回表次数，所以可以试着将出现频率非常高的语句中所有使用到的列以合适的顺序建一个二级索引，这样所有需要的列都被这个二级索引覆盖了，就不需要回表了，从而一定程度上提高了性能 2.5 联合索引#也叫复合索引，多个字段组成的索引 有时和覆盖索引连用，强行联合，也可提高效率。 三、索引结构B+树#B+树的高度一般都在2-4层，这也就是说查找某一键值的行记录最多只需要2-4次IO。 四、网上一些优化建议分析#1、前导模糊查询不能使用索引。 select * from doc where title like ‘%XX’; 很明显，’%lice’ 是不可能能使用到索引的 2、在字段上进行计算不能命中索引 3、强制类型转换会全表扫描 explain select * *from campaignxxx *where creator=22; // 无法使用索引 ​ 字段定义字符串用数字查询无法使用索引，定义数字用字符串查询可以使用。 explain select * *from campaignxxx *where status=‘32as’; // 可以使用索引 4、更新十分频繁字段上不宜建立索引 更新会变更 B+ 树，更新频繁的字段建立索引会大大降低数据库性能。 5、数据区分度不高的字段上不宜建立索引 “性别”这种区分度不大的属性，建立索引是没有什么意义的，不能有效过滤数据，性能与全表扫描类似。 一般区分度在80%以上的时候就可以建立索引，区分度可以使用 count(distinct(列名))/count(*) 来计算。 意思我们campaignxxx表的business和status字段也没必要建索引吗 没必要的关键还是索引要回表，但索引过滤这一层如果确实筛掉很多，肯定还是有用的，还是要看业务场景，比如status字段，查64的和查32的， 64的活动数据库 2912w， 32的活动 41w， 就算多回了表也是快的，而我们主要是查32活动。 select count(1) from campaignxxx where status=32; select count(1) from campaignxxx where discounttype=4; explain select * *from campaignxxx *where status=32 limit 10000000;explain select * *from campaignxxx *where discounttype=4 limit 10000000; explain select * *from campaignxxx *where status=64 limit 10000000;explain select * *from campaignxxx *where discounttype=3 limit 10000000; 对于占比多的部分，查询速度会慢。 区分度不高但你查的是少的那部分，建索引也很有效。 性别这种可能确实不适合。 6、利用延迟关联或者子查询优化超多分页场景 一般分页：explain select * *from campaignxxx *order by modtime limit 300000, 20; 优化分页:explain select * *from campaignxxx cb *join (select id from campaignxxx order by modtime limit 300000, 20) a on cb.id=a.id; 五、索引使用的地方和值得优化的地方#1、where select xxx from order where userid=123; 2、order by select * from user where departmentid=1 order by userid ; 不给order by加索引，就需要mysql server层自己去排序，explain Extra会得到using filesort 当使用排序的空间超过sort_buffer_size的时候，会使用临时表，explain Extra会得到using temporary 3、group by group by 操作在没有合适的索引可用的时候，通常先扫描整个表提取数据并创建一个临时表，然后按照group by 指定的列进行排序 在执行计划中通常可以看到 using temporary; using filesort explain select discounttype, count(1) as num from campaignxxx group by discounttype; explain select status, count(1) as num from campaignxxx group by status; 4、join on 不用说，明显是要再on的关联字段上加索引，但是感觉肯定是要加，但加了具体是如何作用的 join的原理 MySQL是只支持一种JOIN算法Nested-Loop Join（嵌套循环链接） Simple Nested-Loop Join （最初始的方法）： 通常两表关联，数量少的表为驱动表。（其实就是求交集） 从驱动表中取出R1匹配S表所有列，然后R2，R3,直到将R表中的所有数据匹配完，然后合并数据，可以看到这种算法要对S表进行RN次访问，虽然简单，但是相对来说开销还是太大了 Index Nested-Loop Join（有索引的情况， Table S有索引） 索引嵌套联系由于非驱动表上有索引，所以比较的时候不再需要一条条记录进行比较，而可以通过索引来减少比较，从而加速查询。这也就是平时我们在做关联查询的时候必须要求关联字段有索引的一个主要原因。R*logS Block Nested-Loop Join（没有索引的时候） 使用join buffer将驱动表的查询JOIN相关列都给缓冲到了JOIN BUFFER当中，然后批量与非驱动表进行比较，这也来实现的话，可以将多次比较合并到一次，降低了非驱动表的访问频率。也就是只需要访问一次S表。这样来说的话，就不会出现多次访问非驱动表的情况了，也只有这种情况下才会访问join buffer。R + Slogr 六、如何查看sql索引使用情况，Explain性能分析#当想知道sql的真实执行情况，用explain获取执行计划。 6.1、列信息# 列 含义 id SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符. select_type SELECT 查询的类型. table 查询的是哪个表 partitions 匹配的分区 type 表参与类型 possible_keys 此次查询中可能选用的索引 key 此次查询中确切使用到的索引 key_len 索引使用的长度, 可以看使用了复合索引的哪部分 ref 哪个字段或常数与 key 一起被使用 rows 显示此查询一共扫描了多少行. 这个是一个估计值 filtered 表示此查询条件所过滤的数据的百分比 extra 额外的信息 6.2、type 表参与类型#官方给的定义是 join type 级别: ALL &lt; index &lt; range &lt; ref &lt; eq_ref &lt; const &lt; system system: 表中只有一条数据. 这个类型是特殊的 const 类型 const: 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据 explain select * *from campaignxxx *where id=269382403; eq_ref： 使用了唯一或主键关联 explain select * *from campaignxxx cb *join campaignobx co on cb.id=co.campaignid; ref: 使用了非唯一或非主键关联 explain select * *from campaignxxx cb *join campaignobx co on cb.id=co.campaignid where cb.status=32; range: 索引范围查找 explain select * *from campaignxxx *where modtime&gt;1535425311; index: 全索引扫描 explain select modtime from campaignxxx order by modtime limit 10000000; ALL: 全表扫描 explain select * *from campaignxxx *order by modtime limit 10000000; 6.3、extra: 额外信息#using where： 代表发生了过滤 using index：覆盖索引, 表示查询在索引树中就可查找所需数据, 不用扫描表数据文件, 往往说明性能不错 using filesort : 需额外的排序操作, 不能通过索引顺序达到排序效果 explain select * *from campaignxxx *order by addtime; using temporary ： 有使用临时表, 一般出现于排序, 分组和多表 join 的情况, 查询效率不高, 建议优化 explain select * *from campaignxxx *group by addtime; 七、总结#使用explain命令、综合业务添加合适的索引 八、参考文献#http://www.ywnds.com/?p=5202 https://segmentfault.com/a/1190000008131735#articleHeader6 https://www.cnblogs.com/shengdimaya/p/7123069.html","link":"/2018/08/31/mysql/innodb索引/"},{"title":"kafka基本概念、原理","text":"今天公司内部琼琼分享了kafka，也是我一直想听的，本文主要资料来源于该同学的分享，稍作整理，重点的个人理解，留作记录，否则怕过几天就忘记了。。 一、简介# 概念 定义 理解 kafka 分布式，基于发布/订阅的消息系统 集群，时间驱动 使用语言 scala scala可能确实不错 特点 快速, 可扩展, 可持久化, 高吞吐量, 近实时, 支持消息分区, 批量读写消息 设计目标 高吞吐率 利用磁盘顺序读写的特性；topic可以划分为多个partition，提高并发性；支持数据批量发送和拉取 访问与持久化常数时间复杂度 未得证 同步和异步复制两种HA HA: 高可用性 分布式消费 ,保证每个Partition消息顺序传输 一个group里不会有多个consumer消费一个partition，所以可以保证一个partition消息顺序性 支持在线水平扩展 二、基础概念# 概念 理解 消息 数据单元， 一串字节构成，其中主要由key和value， 通过key将消息路由到指定分区，value是消息的有效负载 topic 一个主题，可以看作是一系列消息的集合 partition topic可以划分多个分区，每个分区自己是有序的，但整个topic无法保证有序性 broker Kafka集群中的一个节点, 一台机器 副本 每个partition可以有多个副本， 分为Leader副本和Follower副本，所有的读写请求都由Leader副本进行，Follower副本仅仅从Leader副本把数据同步到本地 HW （HightWatermark）标记一个特殊的offset，当消费者处理消息时只能拉到HW之前的消息 ISR集合 表示目前可用，且消息量与Leader副本相差不多的副本集合。满足（1）该副本所在的节点与zk保持连接；（2）副本最后一条消息的offset与Leader副本的offset之间的差值不能超过指定的阈值。 生产者 生产消息，并将消息按照一定规则推送到topic所在的分区 消费者 从topic中拉取消息，并对消息进行消费 Consumer Group 1个 Consumer Group 有 n个 consumer , 1个 consumer 有 1个 Consumer Group, 如果 n partition and n+1 consumer ,then 1 consumer don’t work 三、demo#1、producer 一个异步发送消息的例子 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class myProducer { public static void main(String [] args) { Properties props = new Properties(); props.put(\"bootstrap.servers\", \"127.0.0.1:9092\"); props.put(\"client.id\", \"myProducer\"); props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.IntegerSerializer\"); props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); KafkaProducer producer = new KafkaProducer&lt;&gt;(props); String topic = \"myTest\"; boolean isAsync = true;//异步发送 int messageNo = 1; while (true) { String messageStr = \"Message_\" + messageNo; long startTime = System.currentTimeMillis(); if (isAsync) { ProducerRecord&lt;Integer, String&gt; record = new ProducerRecord(topic, messageNo, messageStr); producer.send(record, new myProducerCallBack(startTime, messageNo, messageStr)); } messageNo ++; try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } }}class myProducerCallBack implements Callback { private final long startTime; private final int key; private final String message; public myProducerCallBack(long startTime, int key, String message) { this.startTime = startTime; this.key = key; this.message = message; } @Override public void onCompletion(RecordMetadata recordMetadata, Exception e) { long time = System.currentTimeMillis() - startTime; if (Objects.nonNull(recordMetadata)) { System.out.println(\"message key=\" + key + \", message=\" + message + \", send to partition=\" + recordMetadata .partition() + \", offset=\" + recordMetadata.offset() + \", cost time=\" + time); } else { e.printStackTrace(); } }} 这里异步发送和同步发送的区别？ 如果是同步的话，发送速度慢，且异步不会有顺序性问题，我觉得都用异步就好了。 2、consumer 一个同步接收消息的例子 1234567891011121314151617181920public class myConsumer { public static void main(String[] args) { Properties props = new Properties(); props.put(\"bootstrap.servers\", \"127.0.0.1:9092\"); props.put(\"group.id\", \"test\"); props.put(\"enable.auto.commit\", \"true\"); props.put(\"auto.commit.interval.ms\", \"1000\"); props.put(\"session.timeout.ms\", \"30000\"); props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.IntegerDeserializer\"); props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props); consumer.subscribe(Arrays.asList(\"myTest\")); while (true) { ConsumerRecords&lt;String, String&gt; records = consumer.poll(100); for (ConsumerRecord&lt;String, String&gt; record : records) { System.out.println(\"myConsumer record = \" + record); } } }} 如果是异步呢？ 如果多个partition的话，肯定要异步多线程起多个consumer去拉和处理。 四、原理解析#我以 生产者 -&gt; 服务器 -&gt; 消费者 的顺序写 1、生产者原理#我们主要就是要知道他的 设计架构 和 如何保证的发送到同一分区消息的顺序性, (1)设计架构#生产者工作主要涉及两个线程协同工作，主线程将数据封装为ProducerRecord并通过send()方法将消息放入RecordAccumulator中暂存，sender线程负责将消息构成请求，并最终执行网络I/O线程，将RecordAccumulator暂存的消息发送出去。 partition 选择： 当调用send()方法发消息但没有在ProducerRecord中指定partition字段时，KafkaProducer就会调用Partitioner.partition()方法进行选择。默认的实现类DefaultPartitioner会按照key的哈希值取模分区的个数来确定分区；如果没有指定key，会将消息均匀分配到topic对应的分区中，具体的根据内部一个counter取模。 图上的长条都是队列，而且是Deque，可头插的队列. RecordAccumulator作为主线程和Sender线程之间的缓冲必须是线程安全的，其主要字段是一个以TopicPartition为key，ArrayDeque为value的ConcurrentMap，用于存放暂存的消息。Send()方法会调用RecordAccumulator.append()方法将消息放入batchs中。暂存在batchs中的RecordBatch在被Sender线程发送到服务器之前会调用RecordAccumulator.ready()方法获取符合发送消息条件的节点结合，具体条件为： （1）Deque中有多个RecordBatch或者第一个RecordBatch是否满了； （2）是否超时，RecordBatch缓存时间超过了设置的时间； （3）BufferPool的空间耗尽了； （4）Sender线程准备关闭； InFlightRequests是NetWorkClient中的一个字段，只要作用是缓存已经发送出去单没有收到响应的ClientRequest，底层通过Map&lt;String, Deque&lt;NetworkClient.InFlightRequest&gt;&gt;来实现，已经成功处理的请求会从该字段中删除。下面就简单讲解一下Kafka如何利用RecordAccumulatorm， InFlightRequests等实现发送到同一分区消息的顺序性。 （1）调用RecordAccumulator.ready()方法获取可以发送到指定分区的RecordBatch时，只会获取Deque中的第一个RecordBatch; （2）经过（1）中得到的RecordBatch通过NetWorkClient发向Kafka服务器指定Node之前会检查Metadata是否需要更新，连接是否成功，以及调用InFlightRequests.canSendMore()方法判断是否发送改请求。InFlightRequests.canSendMore() 只有在队列为空，或者队列的头部的请求已经完成完成的条件下才返回true。 （3）在NetWorkClient成功收到Kafka集群中的响应后。如果是成功响应，会遍历ClientRequest中的RecordBatch，执行RecordBatch.done()方法，并释放RecordBatch底层的ByteBuffer空间。RecordBatch.done()会执行Recordbatch中每条消息对应的callback函数。如果是异常响应，则尝试将RecordBatch放入RecordAccumulator中重新发送。如果重试次数已经达到上限，或者不允许重试，则直接调用RecordBatch.done()进行异常完成callback处理。 (2)同一分区消息的顺序性（重点）# 同步发送 同步发送的话， 中间的缓存里一定是只有一个的，下次send是在确定发送到kafka服务器成功之后才会进行，相当于整个topic是同步的，所以partition也肯定是同步的。 异步发送 中间缓存里的队列是partition队列，这个队列里只有上一个recordBatch结束了，才会走下一个，保证顺序性， 如果失败，会插回partition队列的头部，详情尽在图中 2、kafka集群原理#kafka并不是分片的，是主从架构 (1)leader副本选举#如果某个分区的leader挂了，那么Follewer副本将会进行选举产生一个新的leader来进行读写操作。kafka中leader的选举是从该topic的ISR列表中进行挑选。通常，先使用ISR里的第一个副本，如果不行依次类推。如果ISR集合中的Follower全部宕机，会选择第一个恢复的副本（不一定是ISR）作为leader。通过ISR，kafka需要的冗余度较低，可以容忍的失败数较高。 (2)高性能策略#（1）顺序读写磁盘 ​ Kafka的设计充分利用了磁盘顺序读写的性能，Partition相当于一个数据，Broker顺序Partition进行读写。同时，Consumer在进行消费时也顺序的读取这些数据。Kafka官方给出了顺序读写磁盘和随机读取磁盘的性能测试数据（Raid-5，7200rpm）：Sequence I/O: 600MB/s， Random I/O: 100KB/s。并且据资料显示，顺序读写磁盘很多时候比随机访问内存快的多。当对Partition没必要的数据进行删除时，Kafka也是通过整个文件的方式进行删除。具体的，Kafka将Partition分为多个Segment，每个Segment对应一个物理文件，删除是删除整个Segment文件。 ​ Kafka也对Page Cache进行了充分的利用，写磁盘时只是将数据写入Page Cache，并不保证数据一定完全写入磁盘。当读操作发生时，先从PageCache中查找，如果发生缺页才进行磁盘调度，最终返回需要的数据。 （2）数据文件的索引 ​ 如上所述，Kafka将Partition分为多个Segment，每个Segment以该文件中最小的offset命令。这样在查找指定offset的Message的时候，用二分查找就可以定位到该Message在哪个Segment中。同时，为了进一步提高查找的效率，Kafka为每个分段后的数据文件建立了索引文件，文件名与数据文件的名字是一样的，只是文件扩展名为.index。索引文件索引的方式采用了稀疏存储的方式，每隔一定字节的数据建立一条索引。这样避免了索引文件占用过多的空间，从而可以将索引文件保留在内存中。 3、消费者原理#(1)客户端#Consumer接口的是实现类是KafkaConsumer类，其工作流程大致如下图所示。可以看出KafkaConsumer通过SubscriptionState来管理订阅的topic集合及Partition的消费状态，通过ConsumerCoordinator与Kafka服务端的GroupCoordinator完成Rebalance操作及offset提交操作，Fetcher负责从Kafka中拉取数据并进行解析。上述操作的所有操作都是通过ConsumerNetworkClient进行缓存并发送的，在该类中还维护了定时任务队列用来完成心跳发送及AutoCommitTask任务。 这部分我理解的还不是很好，都是客户端的一些操作。 (2)offset - partition偏移管理 (重要)#新版的consumer为了缓解zk集群的压力，将consumer的offset信息保存在上述GroupCoordinator维护的内部主题中。该主题中保存了每个Consumer Group某一时刻提交的offset信息，其数据格式大致入下图所示，key为groupid,topic,partition组成，value为offset信息。并且通过配置compact策略，使得每个key对应的offset总是最新的。同时，kafka通过Math.abs(groupId.hashCode()) % numPartitions确定某个Consumer Group的partition offset信息存储的分区. 也就是consumer如果是更新的话，就会更新对应partition中对应key的value即offset数据，下次consumer再读的时候，返回consumer该offset 如果是consumer第一次获取数据的话，就需要服务端对这个新consumer的到来做一次rebalance了(重分配)，需要把partition再尽量均分给不同的consumer (3)rebalance (重要)#在同一个Consumer Group中同一个topic的不同分区会被不同的消费者消费，并且当新的消费者加入或者离开时，会对消费的分区进行重分配，这个工作是由Rebalance操作完成。在开始对Rebalance操作进行介绍前，先说明 Rebalance操作发生的时机： 有新的消费者加入Consumer Group; Consumer Group中的消费者宕机下线； 有消费者主动退出Consumer Group； Consumer Group订阅的任一topic出现分区变化； 消费者调用unsubscribe取消对某一个topic的订阅； ​ Rebalance操作主要包括三个阶段： （1）消费者查找管理当前Consumer Group的GroupCoordinator ​ 该阶段会向Kafka集群中负载最小的Broker发送GroupCoordinatorRequest，并处理响应找到其所对应的GroupCoordinator的网络位置。 （2）Join Group阶段 ​ 在该阶段Consumer会向GroupCoordinator发送JoinGroupRequest，并处理各自的JoinGroupResponse。JoinGroupResponse的处理逻辑如下： 解析JoinGroupResponse，获取GroupCoordinator分配的memberId,generation等信息，更新到本地； 消费者根据leadId检测自己是不是Leader。如果是leader则进入onJoinLeader()，否者进入onJoinFollower()方法； leader根据group_protocol字段指定的Partition分配策略，查找响应的PartitionAssignor对象； leader会得到全部消费者订阅的topic，并将其添加到其SubscriptionState.groupSubscription集合中。Follower则只关心自己订阅的topic; 更新metadata; leader调用PartiionAssignor.assign()方法进行分区分配； （3）Sync Group阶段 ​ 在该阶段leader会将其分配的结果封装为SyncGroupRequest发送给GroupCoordinator进行处理，并处理SyncGroupResponse。 具体实现大概就是GroupCoordinator之间一顿操作，将partition分配，具体的分配策略如下： 在Rebalance操作的Join Group阶段leader会调用PartiionAssignor.assign()进行分区分配。开发者可以通过继承PartiionAssignor接口自己实现分区分配策略，Kaka提供了两个默认实现RangeAssignor和RoundRobinAssignor。 (1) RangeAssignor ​ 对于一个topic，n = 分区数/消费者数量，m=分区数%消费者数量，前m个消费者每个分配n+1个分区，后面的 （消费者数量-m）个消费者每个分配n个分区。比如有两个消费者c1,c2，有topic t1,t2，分别有三个分区。那么，按这种方式的分配结果是c1t1p1,c1t1p2,c2t1p3,c1t2p1,c1t2p2,c2t2p3。显然，这种方式在一定程度上是不公平的。 (2) RoundRobinAssignor ​ 该分配器会把这个group订阅的所有TopicPartition排序，排序是先按topic排序，同一个topic的分区按partition id排序。然后，依次分配给消费者。上述例子利用RoundRobinAssignor的分配结果是：c1t1p1,c2t1p2,c1t1p3,c1t2p1,c2t2p2,c1t2p3 五、消息队列对比# Kafka RabbitMQ ZeroMQ ActiveMQ RocketMQ 吞吐量 高（17.3W/s） 低 (2.6W/s) 高（“史上最快”） (29W/s) 低（比RabbitMQ低） 高（11.6w/s） 可靠性 保证 保证 不保证 不保证 保证 持久化 支持(大量) 支持（少量） 不支持 支持（少量） 支持（大量） 消息回溯 支持 不支持 不支持 不支持 支持 只要开发语言 Scala/Java Erlang C Java Java 性能稳定性 较差 好 很好 好 一般 六、配置信息#1、producer# 配置项 默认值 作用 batch.num.messages 200 一个batch发送消息的数量 batch.num.messages 200 采用异步模式时，一个batch缓存的消息数量。达到这个数量值时producer才会发送消息。 batch.size 16384 批量提交的batch字节大小 buffer.memory 33554432 BufferPool缓存大小 client.id 生成一个id 标识生产者的一个字符串 compression.type none Producer用于压缩数据的压缩类型,默认是无压缩。正确的选项值是none、gzip、snappy。 interceptor.classes 消息拦截类的list linger.ms 0 数据缓存的最大延迟时间 message.send.max.retries 3 消息发送失败后重试次数 metadata.broker.list 生产者获取元数据地址 partitioner.class DefaultPartitioner 分区分配策略，默认是kafka.producer.DefaultPartitioner，取模 queue.buffering.max.messages 10000 异步模式下缓冲的消息的最大数量 queue.buffering.max.ms 5000 异步模式下缓冲数据的最大时间 queue.enqueue.timeout.ms -1 异步模式下，消息进入队列的等待时间。若是设置为0，则消息不等待，如果进入不了队列，则直接被抛弃 request.required.acks 0 消息确认模式，0：不保证消息到达确认；1：发送消息，等待leader收到确认；-1：发送消息，等待leader收到确认，并进行复制操作后才返回。 request.timeout.ms 10000 发送消息最长等待时间 send.buffer.bytes 100*1024 socket的缓存大小 topic.metadata.refresh.interval.ms 600*1000 生产者定时更新topic元信息的时间间隔 2、consumer# 配置项 默认值 作用 batch.num.messages 200 一个batch发送消息的数量 batch.num.messages 200 采用异步模式时，一个batch缓存的消息数量。达到这个数量值时producer才会发送消息。 batch.size 16384 批量提交的batch字节大小 buffer.memory 33554432 BufferPool缓存大小 client.id 生成一个id 标识生产者的一个字符串 compression.type none Producer用于压缩数据的压缩类型,默认是无压缩。正确的选项值是none、gzip、snappy。 interceptor.classes 消息拦截类的list linger.ms 0 数据缓存的最大延迟时间 message.send.max.retries 3 消息发送失败后重试次数 metadata.broker.list 生产者获取元数据地址 partitioner.class DefaultPartitioner 分区分配策略，默认是kafka.producer.DefaultPartitioner，取模 queue.buffering.max.messages 10000 异步模式下缓冲的消息的最大数量 queue.buffering.max.ms 5000 异步模式下缓冲数据的最大时间 queue.enqueue.timeout.ms -1 异步模式下，消息进入队列的等待时间。若是设置为0，则消息不等待，如果进入不了队列，则直接被抛弃 request.required.acks 0 消息确认模式，0：不保证消息到达确认；1：发送消息，等待leader收到确认；-1：发送消息，等待leader收到确认，并进行复制操作后才返回。 request.timeout.ms 10000 发送消息最长等待时间 send.buffer.bytes 100*1024 socket的缓存大小 topic.metadata.refresh.interval.ms 600*1000 生产者定时更新topic元信息的时间间隔","link":"/2018/02/09/kafka/kafka/"},{"title":"mysql技术内幕第二章、Innodb存储引擎","text":"Innodb#Innodb体系结构# InnoDB 存储引擎有多个内存块,这些内存块组成了一个大的内存池,主要负责如下工作: 维护所有进程/线程需要访问的多个内部数据结构 缓存磁盘上的数据, 方便快速读取, 同时在对磁盘文件修改之前进行缓存 重做日志(redo log)缓冲 后台线程的主要作用是负责刷新内存池中的数据,保证缓冲池中的内存缓存的是最新数据;将已修改数据文件刷新到磁盘文件;保证数据库发生异常时 InnoDB 能恢复到正常运行的状态. 后台线程#InnoDB 使用的是多线程模型, 其后台有多个不同的线程负责处理不同的任务 Master Thread 这是最核心的一个线程,主要负责将缓冲池中的数据异步刷新到磁盘,保证数据的一致性,包括赃页的刷新、合并插入缓冲、UNDO 页的回收等. IO Thread 在 InnoDB 存储引擎中大量使用了异步 IO 来处理写 IO 请求, IO Thread 的工作主要是负责这些 IO 请求的回调. 可以通过命令来观察 InnoDB 中的 IO Thread: 12345678910111213141516171819202122232425mysql&gt; SHOW ENGINE INNODB STATUS\\G*************************** 1. row *************************** Type: InnoDB Name:Status:=====================================2016-03-23 20:19:53 0x700000d51000 INNODB MONITOR OUTPUT.......--------FILE I/O--------I/O thread 0 state: waiting for i/o request (insert buffer thread)I/O thread 1 state: waiting for i/o request (log thread)I/O thread 2 state: waiting for i/o request (read thread)I/O thread 3 state: waiting for i/o request (read thread)I/O thread 4 state: waiting for i/o request (read thread)I/O thread 5 state: waiting for i/o request (read thread)I/O thread 6 state: waiting for i/o request (write thread)I/O thread 7 state: waiting for i/o request (write thread)I/O thread 8 state: waiting for i/o request (write thread)I/O thread 9 state: waiting for i/o request (write thread)......----------------------------END OF INNODB MONITOR OUTPUT 可以看到, InnoDB 共有10个 IO Thread, 分别是 4个 write、4个 read、1个 insert buffer和1个 log thread. Perge Thread 事物被提交之后, undo log 可能不再需要,因此需要 Purge Thread 来回收已经使用比分配的 undo页. InnoDB 支持多个 Purge Thread, 这样做可以加快 undo 页的回收InnoDB 引擎默认设置为4个 Purge Thread: 12345mysql&gt; SHOW VARIABLES LIKE &quot;innodb_purge_threads&quot;\\G*************************** 1. row ***************************Variable_name: innodb_purge_threads Value: 41 row in set (0.00 sec) undo日志用于存放数据修改被修改前的值. Page Cleaner Thread Page Cleaner Thread 是新引入的,其作用是将之前版本中脏页的刷新操作都放入单独的线程中来完成,这样减轻了 Master Thread 的工作及对于用户查询线程的阻塞 内存# 缓冲池 InnoDB 存储引擎是基于磁盘存储的,其中的记录按照页的方式进行管理,由于 CPU 速度和磁盘速度之间的鸿沟, InnoDB 引擎使用缓冲池技术来提高数据库的整体性能. 缓冲池简单来说就是一块内存区域.在数据库中进行读取页的操作,首先将从磁盘读到的页存放在缓冲池中,下一次读取相同的页时,首先判断该页是不是在缓冲池中,若在,称该页在缓冲池中被命中,直接读取该页.否则,读取磁盘上的页. 对于数据库中页的修改操作,首先修改在缓冲池中页,然后再以一定的频率刷新到磁盘,并不是每次页发生改变就刷新回磁盘. 缓冲池的大小直接影响数据库的整体性能,对于 InnoDB 存储引擎而言,缓冲池配置通过参数 innodb_buffer_pool_size 来设置. 缓冲池中缓存的数据页类型有:索引页、数据页、 undo 页、插入缓冲、自适应哈希索引、 InnoDB 的锁信息、数据字典信息等.索引页和数据页占缓冲池的很大一部分. 下图显示 InnoDB 存储引擎总内存的结构情况. 重做日志缓冲 redo log InnoDB 存储引擎先将重做日志信息放入这个缓冲区,然后以一定频率将其刷新到重做日志文件.重做日志文件一般不需要设置得很大,因为在下列三种情况下重做日志缓冲中的内容会刷新到磁盘的重做日志文件中. Master Thread 每一秒将重做日志缓冲刷新到重做日志文件 每个事物提交时会将重做日志缓冲刷新到重做日志文件 当重做日志缓冲剩余空间小于1/2时,重做日志缓冲刷新到重做日志文件 redo log: 当数据库对数据做修改的时候，需要把数据页从磁盘读到buffer pool中，然后在buffer pool中进行修改，那么这个时候buffer pool中的数据页就与磁盘上的数据页内容不一致，称buffer pool的数据页为dirty page 脏数据，如果这个时候发生非正常的DB服务重启，那么这些数据还没在内存，并没有同步到磁盘文件中（注意，同步到磁盘文件是个随机IO），也就是会发生数据丢失，如果这个时候，能够在有一个文件，当buffer pool 中的data page变更结束后，把相应修改记录记录到这个文件（注意，记录日志是顺序IO），那么当DB服务发生crash的情况，恢复DB的时候，也可以根据这个文件的记录内容，重新应用到磁盘文件，数据保持一致. 额外的内存池 在 InnoDB 存储引擎中, 对一些数据结构本身的内存进行分配时,需要从额外的内存池中进行申请.例如,分配了缓冲池,但是每个缓冲池中的帧缓冲还有对应的缓冲控制对象,这些对象记录以一些诸如 LRU, 锁,等待等信息,而这个对象的内存需要从额外的内存池中申请. 2、Checkpoint技术#如果 redo log 可以无限地增大，同时缓冲池也足够大，是不是就意味着可以不将缓冲池中的脏页刷新回磁盘上？宕机时，完全可以通过 redo log 来恢复整个数据库系统中的数据。 显然，上述的前提条件是不满足的，这也就引入了 checkpoint 技术 我理解就是将脏页定时不断的刷新到磁盘，或触发它刷新到磁盘，让他下回崩溃时恢复的时候，可以通过读更少的redolog来恢复数据库系统。 在InnoDB存储引擎内部，有两种Checkpoint，分别为：Sharp Checkpoint、Fuzzy Checkpoint Sharp Checkpoint 发生在数据库关闭时将所有的脏页都刷新回磁盘，这是默认的工作方式，即参数innodb_fast_shutdown=1。但是若数据库在运行时也使用Sharp Checkpoint，那么数据库的可用性就会受到很大的影响。故在InnoDB存储引擎内部使用Fuzzy Checkpoint进行页的刷新，即只刷新一部分脏页，而不是刷新所有的脏页回磁盘。 Fuzzy Checkpoint：1、Master Thread Checkpoint；2、FLUSH_LRU_LIST Checkpoint；3、Async/Sync Flush Checkpoint；4、Dirty Page too much Checkpoint 1、Master Thread Checkpoint 以每秒或每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回磁盘，这个过程是异步的，此时InnoDB存储引擎可以进行其他的操作，用户查询线程不会阻塞。 2、FLUSH_LRU_LIST Checkpoint 因为InnoDB存储引擎需要保证LRU列表中需要有差不多100个空闲页可供使用。 3、Async/Sync Flush Checkpoint 指的是重做日志文件不可用的情况，这时需要强制将一些页刷新回磁盘，而此时脏页是从脏页列表中选取的。 4、Dirty Page too much 即脏页的数量太多，导致InnoDB存储引擎强制进行Checkpoint。 3、Master Thread#工作原理 1234567891011121314151617181920212223242526272829303132333435363738394041424344void master_thread(){ goto loop;loop:for (int i=0;i&lt;10;i++){ thread_sleep(1) //sleep 1 second--&gt;每秒执行操作(负载在情况下会延迟) do log buffer flush to disk //重做日志缓冲刷新到磁盘，即使这个事务没有提交(总是) if ( last_ten_second_ios &lt; 5% innodb_io_capacity) //如果当前的10次数小于(5% * 200=10)(innodb_io_capacity默认值是200) do merger 5% innodb_io_capacity insert buffer //执行10个合并插入缓冲的操作(5% * 200=10) if ( buf_get_modified_ratio_pct &gt; innodb_max_dirty_pages_pct ) //如果缓冲池中的脏页比例大于innodb_max_dirty_pages_pct(默认是75时) do buffer pool plush 100% innodb_io_capacity dirty page //刷新200个脏页到磁盘 else if enable adaptive flush //如果开户了自适应刷新 do buffer pool flush desired amount dirty page //通过判断产生redo log的速度决定最合适的刷新脏页的数量 if ( no user activity ) //如果当前没有用户活动 goto backgroud loop //跳到后台循环}//每10秒执行的操作if ( last_ten_second_ios &lt; innodb_io_capacity) //如果过去10内磁盘IO次数小于设置的innodb_io_capacity的值（默认是200） do buffer pool flush 100% innodb_io_capacity dirty page //刷新脏页的数量为innodb_io_capacity的值（默认是200）do merger 5% innodb_io_capacity insert buffer //合并插入缓冲是innodb_io_capacity的5%（10）（总是）do log buffer flush to disk //重做日志缓冲刷新到磁盘，即使这个事务没有提交（总是）do full purge //删除无用的undo页 （总是）if (buf_get_modified_ratio_pct &gt; 70%) //如果缓冲池中的胜页比例大于70% do buffer pool flush 100% innodb_io_capacity dirty page //刷新200个脏页到磁盘else do buffer pool flush 10% innodb_io_capacity dirty page //否则刷新20个脏页到磁盘goto loopbackgroud loop: //后台循环do full purge //删除无用的undo页 （总是）do merger 5% innodb_io_capacity insert buffer //合并插入缓冲是innodb_io_capacity的5%（10）（总是）if not idle: //如果不空闲，就跳回主循环，如果空闲就跳入flush loopgoto loop: //跳到主循环else: goto flush loopflush loop: //刷新循环do buf_get_modified_ratio_pct pool flush 100% innodb_io_capacity dirty page //刷新200个脏页到磁盘if ( buf_get_modified_ratio_pct &gt; innodb_max_dirty_pages_pct ) //如果缓冲池中的脏页比例大于innodb_max_dirty_pages_pct的值（默认75%） goto flush loop //跳到刷新循环，不断刷新脏页，直到符合条件 goto suspend loop //完成刷新脏页的任务后，跳入suspend loopsuspend loop:suspend_thread() //master线程挂起，等待事件发生waiting eventgoto loop;} 4、Innodb 关键特性#(1)、insert buffer#insert buffer是一种特殊的数据结构（B+ tree）并不是缓存的一部分，而是物理页，当受影响的索引页不在buffer pool时缓存 secondary index pages的变化，当buffer page读入buffer pool时，进行合并操作，这些操作可以是 INSERT, UPDATE, or DELETE operations (DML) 最开始的时候只能是insert操作，所以叫做insert buffer，现在已经改叫做change buffer了 insert buffer 只适用于 non-unique secondary indexes 也就是说只能用在非唯一的索引上，原因如下 1、primary key 是按照递增的顺序进行插入的，异常插入聚族索引一般也顺序的，非随机IO 2 写唯一索引要检查记录是不是存在，所以在修改唯一索引之前,必须把修改的记录相关的索引页读出来才知道是不是唯一、这样Insert buffer就没意义了，要读出来(随机IO) 所以只对非唯一索引有效 对于为非唯一索引，辅助索引的修改操作并非实时更新索引的叶子页，而是把若干对同一页面的更新缓存起来做，合并为一次性更新操 作，减少IO，转随机IO为顺序IO,这样可以避免随机IO带来性能损耗，提高数据库的写性能 具体流程 先判断要更新的这一页在不在缓冲池中 a、若在，则直接插入； b、若不在，则将index page 存入Insert Buffer，按照Master Thread的调度规则来合并非唯一索引和索引页中的叶子结点 (2)、double write#double write工作流程如下： 当一系列机制（main函数触发、checkpoint等）触发数据缓冲池中的脏页进行刷新到data file的时候，并不直接写磁盘，而是会通过memcpy函数将脏页先复制到内存中的double write buffer，之后通过double write buffer再分两次、每次1MB顺序写入共享表空间的物理磁盘上。然后马上调用fsync函数，同步脏页进磁盘上。由于在这个过程中，double write页的存储时连续的，因此写入磁盘为顺序写，性能很高；完成double write后，再将脏页写入实际的各个表空间文件，这时写入就是离散的了。各模块协作情况如下图（第一步应为脏页产生的redo记录log buffer，然后log buffer写入redo log file，为简化次要步骤直接连线表示）： double write工作流程如下： 当一系列机制（main函数触发、checkpoint等）触发数据缓冲池中的脏页进行刷新到data file的时候，并不直接写磁盘，而是会通过memcpy函数将脏页先复制到内存中的double write buffer，之后通过double write buffer再分两次、每次1MB顺序写入共享表空间的物理磁盘上。然后马上调用fsync函数，同步脏页进磁盘上。由于在这个过程中，double write页的存储时连续的，因此写入磁盘为顺序写，性能很高；完成double write后，再将脏页写入实际的各个表空间文件，这时写入就是离散的了。各模块协作情况如下图（第一步应为脏页产生的redo记录log buffer，然后log buffer写入redo log file，为简化次要步骤直接连线表示）： double write在恢复的时候是如何工作的？ 如果是写double write buffer本身失败，那么这些数据不会被写到磁盘，InnoDB此时会从磁盘载入原始的数据，然后通过InnoDB的事务日志来计算出正确的数据，重新写入到double write buffer。 如果double write buffer写成功的话，但是写磁盘失败，InnoDB就不用通过事务日志来计算了，而是直接用buffer的数据再写一遍。如上图中显示，在恢复的时候，InnoDB直接比较页面的checksum，如果不对的话，Innodb存储引擎可以从共享表空间的double write中找到该页的一个最近的副本，将其复制到表空间文件，再应用redo log，就完成了恢复过程。因为有副本所以也不担心表空间中数据页是否损坏，但InnoDB的恢复通常需要较长的时间 (3)、自适应哈希索引#InnoDB存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度提升，则建立哈希索引，称之为自适应哈希索引(Adaptive Hash Index, AHI)。AHI是通过缓冲池的B+树页构造而来，因此建立的速度很快，而且不需要对整张表构建哈希索引。InnoDB存储引擎会自动根据访问的频率和模式来自动地为某些热点页建立哈希索引。 AHI有一个要求，对这个页的连续访问模式必须是一样的。例如对于(a,b)这样的联合索引页，其访问模式可以是下面情况：1）where a=xxx2）where a =xxx and b=xxx访问模式一样是指查询的条件是一样的，若交替进行上述两种查询，那么InnoDB存储引擎不会对该页构造AHI。AHI还有下面几个要求：1)以该模式访问了100次2)页通过该模式访问了N次，其中N=页中记录*1/16 InnoDB存储引擎官方文档显示，启用AHI后，读取和写入速度可以提高2倍，辅助索引的连接操作性能可以提高5倍。AHI的设计思想是数据库自优化，不需要DBA对数据库进行手动调整。 1234567mysql&gt; show variables like 'innodb_adaptive_hash_index';+----------------------------+-------+| Variable_name | Value |+----------------------------+-------+| innodb_adaptive_hash_index | ON |+----------------------------+-------+1 row in set (0.00 sec) (4)、异步IO#与AIO对应的Sync IO，即每进行一次IO操作，需要等待此操作结束才能继续接下来的操作。但是如果用户发出的是一条索引扫描的查询，那么这条SQL查询语句可能需要扫描多个索引页，也就是需要进行多次的IO操作。在每扫描一个页并等待其完成后再进行下一次的扫描，这是没有必要的。用户可以在发出一个IO请求后立即再发出另一个IO请求，当全部IO请求发送完毕后，等待所有IO操作的完成，这就是AIO。 1234567mysql&gt; show variables like 'innodb_use_native_aio';+-----------------------+-------+| Variable_name | Value |+-----------------------+-------+| innodb_use_native_aio | ON |+-----------------------+-------+1 row in set (0.00 sec) (5)、刷新临接页#AIO另一个优势是进行IO Merge操作，也就是将多个IO合并为1个IO,这样可以提高IOPS的性能。 例如用户需要访问页的（space, offset）为：(8,6),(8,7),(8,8)每个页的大小为16KB，那么同步IO需要进行3次IO操作。而AIO会判断到这三个页是连续的（可以通过(space,offset)知道）。因此AIO底层会发送一个IO请求，从(8,6)开始，读取48KB的页。 1234567mysql&gt; show variables like 'innodb_flush_neighbors';+------------------------+-------+| Variable_name | Value |+------------------------+-------+| innodb_flush_neighbors | 1 |+------------------------+-------+1 row in set (0.00 sec) 若是固态硬盘，有超高的IOPS，建议设置为0. 5、启动、关闭、恢复#InnoDB存储引擎是MySQL的存储引擎之一，因此InnoDB存储引擎的启动和关闭更准确地是指在MySQL实例的启动过程中对InnoDB表存储引擎的处理过程。 参数innodb_fast_shutdown 在关闭时，参数innodb_fast_shutdown影响着表的存储引擎为InnoDB的行为。该参数可取值为0、1、2。 0代表当MySQL关闭时，InnoDB需要完成所有的full purge和merge insert buffer操作，这会需要一些时间，有时甚至需要几个小时来完成。如果在做InnoDB plugin升级，通常需要将这个参数调为0，然后再关闭数据库。 1是该参数的默认值，表示不需要完成上述的full purge和merge insert buffer操作，但是在缓冲池的一些数据脏页还是会刷新到磁盘。 2表示不完成full purge和merge insert buffer操作，也不将缓冲池中的数据脏页写回磁盘，而是将日志都写入日志文件。这样不会有任何事务会丢失，但是MySQL数据库下次启动时，会执行恢复操作（recovery）。 当正常关闭MySQL数据库时，下一次启动应该会很正常。但是，如果没有正常地关闭数据库，如用kill命令关闭数据库，在MySQL数据库运行过程中重启了服务器，或者在关闭数据库时将参数innodb_fast_shutdown设为了2，MySQL数据库下次启动时都会对InnoDB存储引擎的表执行恢复操作。 参数innodb_force_recovery 参数innodb_force_recovery影响了整个InnoDB存储引擎的恢复状况。该值默认为0，表示当需要恢复时执行所有的恢复操作。当不能进行有效恢复时，如数据页发生了corruption，MySQL数据库可能会宕机，并把错误写入错误日志中。 但是，在某些情况下，我们可能并不需要执行完整的恢复操作，我们自己知道如何进行恢复。比如正在对一个表执行alter table操作，这时意外发生了，数据库重启时会对InnoDB表执行回滚操作。对于一个大表，这需要很长时间，甚至可能是几个小时。这时我们可以自行进行恢复，例如可以把表删除，从备份中重新将数据导入表中，这些操作的速度可能要远远快于回滚操作。 innodb_force_recovery还可以设置为6个非零值：1～6。大的数字包含了前面所有小数字的影响，具体情况如下。 1（SRV_FORCE_IGNORE_CORRUPT）：忽略检查到的corrupt页。 2（SRV_FORCE_NO_BACKGROUND）：阻止主线程的运行，如主线程需要执行full purge操作，会导致crash。 3（SRV_FORCE_NO_TRX_UNDO）：不执行事务回滚操作。 4（SRV_FORCE_NO_IBUF_MERGE）：不执行插入缓冲的合并操作。 5（SRV_FORCE_NO_UNDO_LOG_SCAN）：不查看撤销日志（Undo Log），InnoDB存储引擎会将未提交的事务视为已提交。 6（SRV_FORCE_NO_LOG_REDO）：不执行前滚的操作。 需要注意的是，当设置参数innodb_force_recovery大于0后，可以对表进行select、create、drop操作，但insert、update或者delete这类操作是不允许的。 参考链接： https://segmentfault.com/a/1190000004673132","link":"/2018/05/22/mysql/mysql技术内幕第二章/"},{"title":"zookeeper分享总结","text":"给公司组内成员做的zookeeper的分享，研究了两三个星期，包含zookeeper的各个方面，由浅入深，没有探讨一致性算法，但对zookeeper的理解和使用、常用应用做了详细的整理和总结。 一. 定义 官方定义： Zookeeper是分布式系统的高性能协调服务。 它将公共服务：像 命名、配置管理、同步、和 群组服务 暴露在一个简单的接口里。 你可以使用现成的Zookeeper去实现 共识、群组管理、领导人选举和 presence protocols（存在，出席协议）。 你没有必要从头开始实现它们，并且可以在它的基础之上建立自己的特定的需求。 共识： 就是在一个进程提出了一个值应当是什么后，每个进程都提出自己的提议，最终通过共识算法，使所有进程对这个值达成一致意见。 自己理解 zookeeper是 znode组成的文件系统 + watcher监听器 + 一致性协议zab协议 为什么要使用zookeeper： 如果应用程序自己去实现这些服务都不可避免的引入大量的工作。 zookeeper将协调服务与系统服务解耦，降低复杂度。 二. znode znode是一个跟Unix文件系统路径相似的节点，由一系列斜杠进行分割的路径表示。 node可以指代主机、服务器、集群成员、客户端进程等等。 注意：引用时路径必须是绝对的，必须由斜杠字符 ( / ) 来开头。 既像文件一样维护着数据、元信息、ACL、时间戳等数据结构，又像目录一样可以作为路径标识的一部分 每个Znode由3部分组成: ① stat：此为状态信息, 描述该Znode的版本, 权限等信息 ② data：与该Znode关联的数据 ③ children：该Znode下的子节点 zookeeper是存储在内存中的，所以它非常快，但内存有限，所以它存储的数据非常小，它存的是一些管理调度数据， 通常就是配置信息。 ZooKeeper的服务器和客户端都严格限制Znode的数据大小至多1M，但常规使用中应该远小于此值。 zookeeper提供的操作均是原子操作。操作不可分割，读写都是一次性操作节点全部的数据，读就是一下读全部，写就是一下写全部。 znode节点类型 节点类型分为持久节点（PERSISTENT ）、临时节点（EPHEMERAL），以及时序节点（SEQUENTIAL ）,一般是组合使用，可以生成以下4种节点类型 持久节点（PERSISTENT） 创建后，就一直存在，直到有删除操作来主动清除这个节点. 持久顺序节点（PERSISTENT_SEQUENTIAL ） 在创建子节点的时候，可以设置这个属性，那么在创建节点过程中，ZK会自动为给定节点名加上一个数字后缀，作为新的节点名。这个数字后缀的上限是整型的最大值。 临时节点（EPHEMERAL ） 生命周期和客户端会话绑定, 会话失效，而非连接断开。另外，在 临时节点下面不能创建子节点 临时顺序节点（EPHEMERAL_SEQUENTIAL） 三. 客户端调用 Java 123456789101112131415161718192021222324252627282930313233343536373839// 创建一个与服务器的连接ZooKeeper zk = new ZooKeeper(&quot;localhost:&quot; + CLIENT_PORT, ClientBase.CONNECTION_TIMEOUT, new Watcher() { // 监控所有被触发的事件 public void process(WatchedEvent event) { System.out.println(&quot;已经触发了&quot; + event.getType() + &quot;事件！&quot;); } });// 创建一个目录节点zk.create(&quot;/testRootPath&quot;, &quot;testRootData&quot;.getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);// 创建一个子目录节点zk.create(&quot;/testRootPath/testChildPathOne&quot;, &quot;testChildDataOne&quot;.getBytes(), Ids.OPEN_ACL_UNSAFE,CreateMode.PERSISTENT);System.out.println(new String(zk.getData(&quot;/testRootPath&quot;,false,null)));// 取出子目录节点列表System.out.println(zk.getChildren(&quot;/testRootPath&quot;,true));// 修改子目录节点数据zk.setData(&quot;/testRootPath/testChildPathOne&quot;,&quot;modifyChildDataOne&quot;.getBytes(),-1);System.out.println(&quot;目录节点状态：[&quot;+zk.exists(&quot;/testRootPath&quot;,true)+&quot;]&quot;);// 创建另外一个子目录节点zk.create(&quot;/testRootPath/testChildPathTwo&quot;, &quot;testChildDataTwo&quot;.getBytes(), Ids.OPEN_ACL_UNSAFE,CreateMode.PERSISTENT);System.out.println(new String(zk.getData(&quot;/testRootPath/testChildPathTwo&quot;,true,null)));// 删除子目录节点zk.delete(&quot;/testRootPath/testChildPathTwo&quot;,-1);zk.delete(&quot;/testRootPath/testChildPathOne&quot;,-1);// 删除父目录节点zk.delete(&quot;/testRootPath&quot;,-1);// 关闭连接zk.close(); 命令行 1234567891011121314151617181920212223[zk: localhost:2181(CONNECTED) 15] help ZooKeeper -server host:port cmd args stat path [watch] // exits set path data [version] // setData ls path [watch] // getchildren delquota [-n|-b] path ls2 path [watch] // exits + getchildren setAcl path acl setquota -n|-b val path history redo cmdno printwatches on|off delete path [version] // delete sync path listquota path rmr path get path [watch] // getData create [-s] [-e] path data acl addauth scheme auth quit getAcl path close connect host:port 四. watch触发器 监视器 ,当节点状态发生改变时将会触发watch所对应的操作。当watch被触发时，ZooKeeper将会向客户端发送且仅发送一条通知。 五. 服务端 Zookeeper有三种模式，单机模式、伪集群模式和集群模式。 ■ 单机模式：Zookeeper只运行在一台服务器上，适合测试环境；■ 伪集群模式：就是在一台物理机上运行多个Zookeeper 实例；■ 集群模式：Zookeeper运行于一个集群上，适合生产环境，这个计算机集群被称为一个“集合体”（ensemble） 配置伪集群 官网下载tar包 解压：sudo tar -zxvf zookeeper-3.4.10.tar.gz 重命名：mv zookeeper-3.4.10 zk 配置文件： 每启动一个服务都需要各自的 .cfg配置文件 一个data文件夹，data文件夹下myid文件 .cfg配置文件 conf 下根据自带的zoo_sample.cfg 创建 配置文件zoo1.cfg、zoo2.cfg、zoo3.cfg zoo1.cfg 123456789101112131415The number of milliseconds of each ticktickTime=2000The number of ticks that the initialsynchronization phase can takeinitLimit=10The number of ticks that can pass betweensyncLimit=5the directory where the snapshot is stored.dataDir=/usr/local/zk/data1 //zoo2.cfg, zoo3.cfg需改data目录the port at which the clients will connectclientPort=2181 //zoo2.cfg, zoo3.cfg需改端口server.1=localhost:2287:3387server.2=localhost:2288:3388server.3=localhost:2289:3389 zoo2.cfg、zoo3.cfg 与zoo1.cfg差不多 参数说明： 123456789tickTime：这个时间是作为 Zookeeper 服务器之间、客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。dataDir：顾名思义就是 Zookeeper 保存数据的目录，默认情况下，Zookeeper 将写数据的日志文件也保存在这个目录里。clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。initLimit：这个配置项是用来配置 Follower 服务器初始化连接leader时最长能忍受多少个心跳时间间隔数。当已经超过 10 个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 5*2000=10 秒syncLimit：这个配置项标识 Leader 与 Follower 之间请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是 2*2000=4 秒server.A=B：C：D：其中 A 是一个数字，表示这个是第几号服务器；B 是这个服务器的 ip 地址； C 表示的是这个服务器与集群中的 Leader 服务器交换信息的端口 (leader开启这个端口的监听，与follower交换信息 ) ； D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。 ​ data文件夹、myid文件 myid 位于data文件夹下，data文件夹的位置在 .cfg文件中配置，如上。 ​ myid 文件中为server.id对应id start status stop 12345./zhServer.sh start conf/zoo.cfg./zhServer.sh status conf/zoo.cfg./zhServer.sh stop conf/zoo.cfg 六. zookeeper的功能 zookeeper除了在znode上存储些配置数据还能做什么。 命名服务 客户端根据指定名字获取资源或服务地址，提供者等信息。被命名的实体通常可以是集群中的机器，提供的服务地址，远程对象等等。 较为常见的就是一些分布式服务框架中的服务地址列表。通过调用ZK提供的创建节点的API，能够很容易创建一个全局唯一的path，这个path就可以作为一个名称。 举个例子： Dubbo中使用ZooKeeper来作为其命名服务，维护全局的服务地址列表 *服务提供者 启动的时候，向ZK上的指定节点/dubbo/${serviceName}/providers目录下写入自己的URL地址，这个操作就完成了服务的发布。 * *服务消费者 启动的时候，订阅/dubbo/${serviceName}/providers目录下的提供者URL地址， 并向/dubbo/${serviceName} /consumers目录下写入自己的URL地址。 * 数据发布与订阅（配置中心） 发布者将数据发布到ZK节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新. 通常场景 应用来节点获取一次配置，同时，在节点上注册一个Watcher，这样一来，以后每次配置有更新的时候，都会实时通知到订阅的客户端，从来达到动态获取最新配置信息的目的。 (就是有一个节点，大家一起读，一起改，都在这儿设置监视器) 注：数据量很小，但是数据更新可能会比较快的场景。 举三个例子 HBase中，客户端就是连接一个Zookeeper，获得必要的HBase集群的配置信息，然后才可以进一步操作。 Kafka中，也使用Zookeeper来维护broker的信息。 Dubbo中也广泛的使用Zookeeper管理一些配置来实现服务治理。 负载均衡 分布式环境中，为了保证高可用性，通常同一个服务的 提供方会部署多份，达到对等服务。而消费者就须要在这些对等的服务器中选择一个来执行相关的业务逻辑。 Kafka 和 阿里开源的 metaq 都是通过zookeeper来做到 生产者、消费者的负载均衡 举个例子kafka 生产者负载均衡： 生产者客户端 在发送消息须选择一台broker(就是一台生产者服务端server)上的一个分区来发送消息， kafka 会把所有broker和对应分区信息全部注册到ZK指定节点上 生产者 在通过ZK获取分区列表之后，会按照brokerId和partition的顺序排列组织成一个有序的分区列表，发送的时候按照从头到尾循环往复的方式选择一个分区来发送消息。 消费策略是 group订阅topic，partition的增删对应group中消费者重新进行负载均衡。 一个partition对应一个consumer，group监听topic，此时新加一条消息的话，可能会新加一个topic中的partition索引，也可能会去掉一个topic中的partition索引。 新增partition的话，在group中找到一个consumer对应，然后在owners 和 offsets 添加分区和消费者对应的信息和消费偏移量的信息，此时讲道理消费者和生产者broker已经连接了。 如果不是新增partition，就是向partition中放消息的话，此时已经对应了consumer，就直接由那个consumer消费。 如果是删除了一个partion或broker， 对应topic下的索引删除，consumer不再消费对应partition，group会重新进行负载均衡。 分布式通知/协调 协调不同系统。 跟配置中心挺像，配置中心是修改配置给所有人看，通知/协调是一个系统修改配置给另一个系统看。 通过 watcher注册与异步通知机制，能够很好的实现分布式环境下不同系统之间的通知与协调，实现对数据变更的实时处理。 使用方法通常是不同系统都对ZK上同一个znode进行注册，监听znode的变化（包括znode本身内容及子节点的），其中一个系统update了znode，那么另一个系统能够收到通知，并作出相应处理。 举两个例子 调度系统， 某系统有 控制台 和 推送系统 两部分组成，控制台的职责是控制推送系统进行相应的推送工作。管理人员在控制台作的一些操作，实际上是修改了ZK上某些节点的状态，而ZK就把这些变化通知给他们注册Watcher的客户端，即推送系统，于是，作出相应的推送任务. 任务分发系统，子任务启动后，到zk来注册一个临时节点，并且定时将自己的进度进行汇报（将进度写回这个临时节点），这样任务管理者就能够实时知道任务进度。 分布式锁 这个锁是给一个分布式应用提供的。 提供两类锁服务，一个是独占锁，另一个是时序锁。 独占锁就是从一堆客户端中选一个获得锁，只有一个获得。 时序锁是将这些客户端获取锁的顺序进行排序。 独占锁通常的做法是把zk上的一个znode看作是一把锁，通过create znode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。 时序锁是 /distribute_lock 已经预先存在，客户端在它下面创建临时有序节点（这个可以通过节点的属性控制：CreateMode.EPHEMERAL_SEQUENTIAL来指定）。Zk的父节点（/distribute_lock）维持一份sequence,保证子节点创建的时序性，从而也形成了每个客户端的全局时序 分布式队列 两种，一种是常规的先进先出队列，另一种是要等到队列成员聚齐之后的才统一按序执行。 先进先出队列，和分布式锁服务中的控制时序场景基本原理一致。 第二种队列其实是在FIFO队列的基础上作了一个增强。 通常可以在 /queue 这个znode下预先建立一个/queue/num 节点，并且赋值为n（或者直接给/queue赋值n），表示队列大小，之后每次有队列成员加入后，就判断下是否已经到达队列大小，决定是否可以开始执行了。 这种用法的典型场景是，分布式环境中，一个大任务Task A，需要在很多子任务完成（或条件就绪）情况下才能进行。这个时候，凡是其中一个子任务完成（就绪），那么就去 /taskList 下建立自己的临时时序节点（CreateMode.EPHEMERAL_SEQUENTIAL），当 /taskList 发现自己下面的子节点满足指定个数，就可以进行下一步按序进行处理了。 集群管理与Master选举 利用ZooKeeper有两个特性，就可以实时另一种集群机器存活性监控系统： 客户端在节点 x 上注册一个Watcher，那么如果 x?的子节点变化了，会通知该客户端。 创建EPHEMERAL类型的节点，一旦客户端和服务器的会话结束或过期，那么该节点就会消失。 例如，监控系统在 /clusterServers 节点上注册一个Watcher，以后每动态加机器，那么就往 /clusterServers 下创建一个 EPHEMERAL类型的节点：/clusterServers/{hostname}. 这样，监控系统就能够实时知道机器的增减情况，至于后续处理就是监控系统的业务了。 Master选举则是zookeeper中最为经典的应用场景。 利用ZooKeeper的强一致性，能够保证在分布式高并发情况下节点创建的全局唯一性，即：同时有多个客户端请求创建 /currentMaster 节点，最终一定只有一个客户端请求能够创建成功。利用这个特性，就能很轻易的在分布式环境中进行集群选取了。 上文中提到，所有客户端创建请求，最终只有一个能够创建成功。在这里稍微变化下，就是允许所有请求都能够创建成功，但是得有个创建顺序，于是所有的请求最终在ZK上创建结果的一种可能情况是这样： /currentMaster/{sessionId}-1 ,?/currentMaster/{sessionId}-2 ,?/currentMaster/{sessionId}-3 ….. 每次选取序列号最小的那个机器作为Master，如果这个机器挂了，由于他创建的节点会马上小时，那么之后最小的那个机器就是Master了。 七. 一致性 顺序一致性 一个客户端的更新将按照发送的顺序被写入到服务端。 并发一致性 zookeeper 并不保证在某个时刻两个不同客户端具有一致的数据视图，因为网络的延迟一个客户端可能在另一个客户端得到修改通知之前进行更新。如果不同客户端读取到相同的值很重要，那么客户端应该在执行读取操作之前调用 sync() 方法，使得读操作的连接所连的 zookeeper 实例能与 leader 进行同步，从而能读到最新的内容。 zab协议 ZooKeeper Atomic Broadcast ( ZooKeeper 原子消息广播协议 ) 是zookeeper数据一致性的核心算法。 功能实现 使用单一主进程来接收并处理客户端的所有事务请求，并采用原子广播协议，将服务器数据的状态变更以事务 Proposal（ 提议 ） 的形式广播到所有的副本进程上去。 保证一个全局的变更序列被顺序应用。 当前主进程出现异常情况的时候，依旧能够正常工作。 核心 ​ 所有事务请求必须由一个全局唯一的服务器来协调处理，这样的服务器被称为 Leader服务器，而余下的其他服务器为 Follower 服务器或Observer服务器。 ​ Leader 服务器负责将一个客户端事务请求转换成一个事务proposal（提议），并将该 Proposal分发给集群中所有的Follower服务器。之后 Leader 服务器需要等待所有Follower 服务器的反馈,一旦超过半数的Follower服务器进行了正确的反馈后，那么 Leader 就会再次向所有的 Follower服务器分发Commit消息，要求其将前一个proposal进行提交。","link":"/2017/07/19/zookeeper/zookeeper分享总结/"},{"title":"springboot文档阅读 第一章","text":"@RestController和@RequestMapping Example类上使用的第一个注解是@RestController，这被称为构造型（stereotype）注解。它为阅读代码的人提供暗示（这是一个支持REST的控制器），对于Spring，该类扮演了一个特殊角色。在本示例中，我们的类是一个web @Controller，所以当web请求进来时，Spring会考虑是否使用它来处理。 @RequestMapping注解提供路由信息，它告诉Spring任何来自”/“路径的HTTP请求都应该被映射到home方法。@RestController注解告诉Spring以字符串的形式渲染结果，并直接返回给调用者。 注：@RestController和@RequestMapping是Spring MVC中的注解（它们不是Spring Boot的特定部分），具体参考Spring文档的MVC章节。 @EnableAutoConfiguration 第二个类级别的注解是@EnableAutoConfiguration，这个注解告诉Spring Boot根据添加的jar依赖猜测你想如何配置Spring。由于spring-boot-starter-web添加了Tomcat和Spring MVC，所以auto-configuration将假定你正在开发一个web应用，并对Spring进行相应地设置。Starters和Auto-Configuration：Auto-configuration设计成可以跟”Starters”一起很好的使用，但这两个概念没有直接的联系。你可以自由地挑选starters以外的jar依赖，Spring Boot仍会尽最大努力去自动配置你的应用。 创建可执行的jar 我们需要将spring-boot-maven-plugin添加到pom.xml中，在dependencies节点后面插入以下内容： 12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 如果查看target目录，你应该可以看到myproject-0.0.1-SNAPSHOT.jar，该文件大概有10Mb。想查看内部结构，可以运行jar tvf： 1$ jar tvf target/myproject-0.0.1-SNAPSHOT.jar //todo 上面这个方法在我的项目上没有成功，还不知道为什么，待解决。","link":"/2017/10/23/springboot/springboot文档理解/第一章 开始/"},{"title":"springboot文档阅读 第二章 继承parent与远程调试","text":"继承 starter parent ? 继承的话： 如果你想配置项目，让其继承自spring-boot-starter-parent，只需将parent按如下设置： 123456&lt;!-- Inherit defaults from Spring Boot --&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.1.BUILD-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 注：你应该只需在该依赖上指定Spring Boot版本，如果导入其他的starters，放心的省略版本号好了。 按照以上设置，你可以在自己的项目中通过覆盖属性来覆盖个别的依赖。例如，你可以将以下设置添加到pom.xml中来升级Spring Data到另一个发布版本。 123&lt;properties&gt; &lt;spring-data-releasetrain.version&gt;Fowler-SR2&lt;/spring-data-releasetrain.version&gt;&lt;/properties&gt; 注 查看spring-boot-dependencies pom获取支持的属性列表。 spring-boot-starter-parent选择了相当保守的Java兼容策略，如果你遵循我们的建议，使用最新的Java版本，可以添加一个java.version属性： 123&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt; Spring Boot包含一个[Maven插件](../VIII. Build tool plugins/58. Spring Boot Maven plugin.md)，它可以将项目打包成一个可执行jar。如果想使用它，你可以将该插件添加到&lt;plugins&gt;节点处： 12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 注：如果使用Spring Boot starter parent pom，你只需添加该插件而无需配置它，除非你想改变定义在partent中的设置。 不继承starter parent的话： 不是每个人都喜欢继承spring-boot-starter-parent POM，比如你可能需要使用公司的标准parent，或只是倾向于显式声明所有的Maven配置。 如果你不想使用spring-boot-starter-parent，通过设置scope=import的依赖，你仍能获取到依赖管理的好处： 123456789101112&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!-- Import dependency management from Spring Boot --&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.4.1.BUILD-SNAPSHOT&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 以上设置不允许你使用属性覆盖个别依赖，为了达到这个目的，你需要在项目的dependencyManagement节点中，在spring-boot-dependencies实体前插入一个节点。例如，为了将Spring Data升级到另一个发布版本，你需要将以下配置添加到pom.xml中： 12345678910111213141516171819&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- Override Spring Data release train provided by Spring Boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-releasetrain&lt;/artifactId&gt; &lt;version&gt;Fowler-SR2&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.4.1.BUILD-SNAPSHOT&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 注 示例中，我们指定了一个BOM，但任何的依赖类型都可以通过这种方式覆盖 远程调试 如果使用Spring Boot Maven或Gradle插件创建一个可执行jar，你可以使用java -jar运行应用。例如： 1$ java -jar target/myproject-0.0.1-SNAPSHOT.jar Spring Boot支持以远程调试模式运行一个打包的应用，下面的命令可以为应用关联一个调试器： 12$ java -Xdebug -Xrunjdwp:server=y,transport=dt_socket,address=8000,suspend=n \\ -jar target/myproject-0.0.1-SNAPSHOT.jar Java的远程调试在诊断远程应用问题时很有用，不幸的是，当应用部署在你的数据中心外时，它并不总能够启用远程调试。如果你使用基于容器的技术，比如Docker，远程调试设置起来非常麻烦。 为了突破这些限制，devtools支持基于HTTP的远程调试通道。远程客户端在8000端口提供一个本地server，这样远程debugger就可以连接了。一旦连接建立，调试信息就通过HTTP发送到远程应用。你可以使用spring.devtools.remote.debug.local-port属性设置不同的端口。 你需要确保远程应用启动时开启了远程调试功能，通常，这可以通过配置JAVA_OPTS实现，例如，对于Cloud Foundry，你可以将以下内容添加到manifest.yml： 123--- env: JAVA_OPTS: &quot;-Xdebug -Xrunjdwp:server=y,transport=dt_socket,suspend=n&quot; 注 注意你不需要传递一个address=NNNN的配置项到-Xrunjdwp，如果遗漏了，java会使用一个随机可用端口。 调试基于Internet的远程服务可能很慢，你可能需要增加IDE的超时时间。例如，在Eclipse中你可以从Preferences…选择Java -&gt; Debug，改变Debugger timeout (ms)为更合适的值（60000在多数情况下就能解决）。","link":"/2017/10/25/springboot/springboot文档理解/第二章 使用/"},{"title":"springboot文档阅读 第三章 配置信息读取","text":"稍微粘贴一下配置文件信息，但还是没有总结出最佳实践，todo待总结，不过想必是spring源码的配置方式吧。 判断环境是否是web环境 SpringApplication将尝试为你创建正确类型的ApplicationContext，默认情况下，根据你开发的是否为web应用决定使用AnnotationConfigApplicationContext或AnnotationConfigEmbeddedWebApplicationContext。 用于确定是否为web环境的算法相当简单（判断是否存在某些类），你可以使用setWebEnvironment(boolean webEnvironment)覆盖默认行为。 应用参数 如果需要获取传递给SpringApplication.run(…)的应用参数，你可以注入一个org.springframework.boot.ApplicationArguments类型的bean。ApplicationArguments接口即提供对原始String[]参数的访问，也提供对解析成option和non-option参数的访问： 123456789101112131415import org.springframework.boot.*import org.springframework.beans.factory.annotation.*import org.springframework.stereotype.*@Componentpublic class MyBean { @Autowired public MyBean(ApplicationArguments args) { boolean debug = args.containsOption(&quot;debug&quot;); List&lt;String&gt; files = args.getNonOptionArgs(); // if run with &quot;--debug logfile.txt&quot; debug=true, files=[&quot;logfile.txt&quot;] }} 注 Spring Boot也会注册一个包含Spring Environment属性的CommandLinePropertySource，这就允许你使用@Value注解注入单个的应用参数。 命令行参数 默认情况下，SpringApplication会将所有命令行配置参数（以’–’开头，比如--server.port=9000）转化成一个property，并将其添加到Spring Environment中。正如以上章节提过的，命令行属性总是优先于其他属性源。 如果不想将命令行属性添加到Environment，你可以使用SpringApplication.setAddCommandLineProperties(false)来禁用它们。 @ConfigurationProperties vs. @Value @Value是Spring容器的一个核心特性，它没有提供跟type-safe Configuration Properties相同的特性。下面的表格总结了@ConfigurationProperties和@Value支持的特性： 特性 @ConfigurationProperties @Value Relaxed绑定 Yes No Meta-data支持 Yes No SpEL表达式 No Yes 如果你为自己的组件定义了一系列的配置keys，我们建议你将它们以@ConfigurationProperties注解的POJO进行分组。由于@Value不支持relaxed绑定，所以如果你使用环境变量提供属性值的话，它就不是很好的选择。最后，尽管@Value可以写SpEL表达式，但这些表达式不会处理来自Application属性文件的属性。 Profiles Spring Profiles提供了一种隔离应用程序配置的方式，并让这些配置只在特定的环境下生效。任何@Component或@Configuration都能注解@Profile，从而限制加载它的时机： 1234567@Configuration@Profile(\"production\")public class ProductionConfiguration { // ...} 以正常的Spring方式，你可以使用spring.profiles.active的Environment属性来指定哪个配置生效。你可以使用通常的任何方式来指定该属性，例如，可以将它包含到application.properties中： 1spring.profiles.active=dev,hsqldb 或使用命令行开关： 1--spring.profiles.active=dev,hsqldb","link":"/2017/10/31/springboot/springboot文档理解/第三章 配置信息读取/"},{"title":"java并发","text":"- Java并发容器有哪些 - ArrayBlockingQueue和LinkedBlockingQueue的实现原理 - 阻塞队列原理 - 谈谈对ConcurrentHashMap的了解 - 谈谈对Java内存模型的了解 - volatile原理 - java的乐观锁CAS锁原理 - sychronized使用及原理 - 锁升级 - sychronized缺点 - sychronized reentranlock 的区别 - sychronized 和 valotile 的区别 - 弱引用 - ThreadLocal原理 - AQS同步器原理？tryAcquire的过程？ - CountDownLatch、Semaphore、CyclicBarrier含义及实现原理 java异步 - Callable、Future、FutureTask、CompletableFuture分别是什么 线程池 - 线程池的创建使用、有哪些参数 - 线程池的原理 - 怎么配置参数 - Java并发容器有哪些#concurrentHashmap: 线程安全的HashMap, Node数组+链表 + 红黑树copyonwriteArrayList: 线程安全的List，在读多写少的场合性能非常好concurrentLinkedQueue: 高效的并发队列，使用链表实现。可以看做一个线程安全的 LinkedListBlockingQueue(接口)1 ArrayBlockingQueue: 有界队列实现类 底层Object数组2 LinkedBlockingQueue: 单向链表3 PriorityBlockingQueue: 支持优先级的无界阻塞队列 - ArrayBlockingQueue和LinkedBlockingQueue的实现原理#ArrayBlockingQueue是object数组实现的线程安全的有界阻塞队列1.数组实现：使用数组实现循环队列2.有界：内部为数组实现，一旦创建完成，数组的长度不能再改变3.线程安全：使用了 ReentrantLock 和 两个 condition(notEmpty, notFull) 来保证线程安全4.阻塞队列：先进先出。当取出元素的时候，若队列为空，wait直到队列非空（notEmpty）；当存储元素的时候，若队列满，wait直到队列有空闲（notFull） LinkedBlockingQueue是一个单向链表实现的阻塞队列1.链表实现： head是链表的表头， last是链表的表尾。取出数据时，都是从表头head处取出，出队； 新增数据时，都是从表尾last处插入，入队。2.可有界可无界：可以在创建时指定容量大小，防止队列过度膨胀。如果未指定队列容量，默认容量大小为Integer.MAX_VALUE3.线程安全：使用了 两个 ReentrantLock 和 两个 condition，putLock是插入锁，takeLock是取出锁；notEmpty是“非空条件”，notFull是“未满条件”。通过它们对链表进行并发控制4.阻塞队列：先进先出。当取出元素的时候，若队列为空，wait直到队列非空（notEmpty）；当存储元素的时候，若队列满，wait直到队列有空闲（notFull） PriorityBlockingQueuePriorityBlockingQueue(具有优先级的无限阻塞队列). 是一个支持优先级的无界阻塞队列，内部结构是数组实现的二叉堆线程安全的排序。其数据结构是二叉堆(分为最大堆和最小堆)二叉堆本质是一颗二叉树：二叉堆是一种特殊的堆，二叉堆是完全二叉树或者是近似完全二叉树如果节点在数组中的位置是i(i是节点在数组中的下标), 则i节点对应的子节点在数组中的位置分别是 2i + 1 和 2i +2， 同时i的父节点的位置为 (i-1)/2（i从0 开始）通过一次上浮可以把符合条件的元素放到堆顶，反复进行上浮操作，可以将整个堆进行有序化。下沉操作可以把替代堆顶后的元素放到该放的位置，同时堆顶元素是符合条件的元素（前提是二叉堆已经是有序的） SynchronousQueueSynchronousQueue (SynchronousQueue是一个不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素), 每一个线程的入队操作必须等待另一个线程相应的出队（take）操作，相反，每一个线程的出队操作必须等待另一个线程相应的入队操作。 Executors.newCachedThreadPool() 使用的SynchronousQueue， 实际就不想往队列里放元素，就是想有多少任务就生成多少线程去做。线程拉满，不做任务堆积。 但newCachedThreadPool(). maxThreadSize 是Integer.MAX_VALUE, 容易内存溢出。 白话ArrayBlockingQueue和LinkedBlockingQueue都是线程安全的阻塞队列。 ArrayBlockingQueue底层是数组实现，是有界的队列，线程安全是使用一个 ReentrantLock 和 两个 condition实现的。 LinkedBlockingQueue底层是单向链表实现，是可有界可无界的队列，线程安全是使用两个 ReentrantLock 和 两个 condition实现的。 为什么ArrayBlockingQueue是一个ReentrantLock，LinkedBlockingQueue是两个？ArrayBlockingQueue在插入、取出的时候，都会对index做变更，有并发问题，需要同步处理。LinkedBlockingQueue从队头取出，从队尾插入，链表结构所以两种操作可并行。所以用两个lock, 提升并发能力，还用了一个AtomicInteger count; // 记录总数 - 阻塞队列原理#核心思想就是，何时阻塞：空不让你取，满不让你加。进行操作的方法，在操作前，都必须加锁。主要就是一个 ReentrantLock，和两个由它创建的 Condition：notFull、notEmpty。然后，在take、put、enqueue、dequeue 四个方法里面对这两个信号条件进行控制。 - 谈谈对ConcurrentHashMap的了解#1.7 结构： 分段的数组+链表; 并发：分段锁，锁一段数组 segment，默认有16个segment, 并发度只有默认是16 线程安全: segment上锁，继承ReentrantLock可重入锁 1.8 结构： Node数组+链表 + 红黑树; 并发： 并发控制使用 synchronized 和 CAS 线程安全: CAS和synchronized来保证并发安全, synchronized只锁定当前链表或红黑二叉树的首节点, 只要hash不冲突，就不会产生并发，效率又提升N倍 get是怎么做的 hash。 hashcode高低16位异或得到hash值，(h ^ h &gt;&gt;&gt; 16) &amp; 2147483647; 桶位节点就是要找节点，直接返回该节点 如果节点hash值小于0，说明是已迁移的节点或者红黑树bin，调用node.find(), TreeBin 和 ForwardingNode 都继承Node重写find方法 剩下情况就是链表，遍历判断是否节点存在 注：ForwordingNode的hash值为-1，红黑树的根结点的hash值为-2。 TreeBin 和 ForwardingNode 都继承Node重写find方法 put是怎么做的 hash。 hashcode高低16位异或得到hash值，(h ^ h &gt;&gt;&gt; 16) &amp; 2147483647; 桶位为空，cas设置新node，U.compareAndSetObject 如果hash值为-1，则helpTransfer，else 加synchronized锁住头结点，判断是树，调用添加到树中方法，如果是链表，添加到尾端。 判断是否到了8个，链表变树； 判断size是否到了阈值，触发扩容。size总数增加cas (U.compareAndSetLong) resize是怎么做的 newTable, 大小是旧表的2倍 头结点加锁，不允许其他线程更改，但可get， 判断桶中各节点位置，复制一模一样的节点到新表（非直接移过去，还要get），到新表可能在旧桶位也可能在新桶位 分配结束之后将头结点设置为fwd节点（指向新表） 白话：线程安全的map。1.7版本是使用分段锁实现的线程安全，segment上加锁，在构建的时候可以设置大小，默认是16，就是并发度默认只有16. 1.8版本的线程安全是用synchronized+cas实现的，使用synchronized锁住链表或红黑树的头结点，使用cas来进行size++和首个节点入桶。1.8的并发度是随着桶位增加而增加的，所以并发效率会随扩容提升很多倍。 - 谈谈对Java内存模型的了解#总结：jmm定义了线程间通信的方式，jmm使用共享内存的方式通信，jmm规范多线程下的执行顺序和多线程下共享变量的可见性问题，规定了一套happens-before规则。 jmm是为了解决线程间通信问题，线程间通信通常有两种解决方法，共享内存或通知机制， jmm使用了共享内存的方式。jmm定义了一套happens-before规则来规范多线程下的执行顺序和多线程下变量的可见性问题，规则底层是通过禁止部分编译器和处理器的指令重排序实现。happens-before有八个，分别是：程序顺序规则：一个线程中的每个操作，发生在该线程中任意后续操作之前监视器锁规则：对一个锁的解锁，发生在随后对这个锁的加锁之前volatile变量规则：对一个volatile域的写，发生在任意后续对这个volatile域的读之前传递性：如果A发生在B之前，B发生在C之前，那么A一定发生在C之前线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作；线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行；对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始； - volatile原理# volatile的特征A、禁止指令重排（有例外）B、可见性 Volatile的内存语义当写一个volatile变量时，JMM会把线程对应的本地内存中的共享变量值刷新到主内存。当读一个volatile变量时，JMM会把线程对应的本地内存置为无效，线程接下来将从主内存中读取共享变量 Volatile的重排序两个volatile变量操作不能够进行重排序； 白话：volatile有两个特性，可见性和禁止指令重排序。可见性，当一个线程更新volatile变量后，这个变量会立即写入到主内存中，其他线程读取时会从主内存中读取最新的值。禁止指令重排序，两个对volatile变量的操作不能被重排序，底层是通过内存屏障实现的。 - java的乐观锁CAS锁原理#CAS英文全称Compare and Swap，直白翻译过来即比较并交换，是一种无锁算法，在不使用锁即没有线程阻塞下实现多线程之间的变量同步，基于处理器的读-改-写原子指令来操作数据，可以保证数据在并发操作下的一致性。 CAS包含三个操作数：内存位置V，预期值A，写入的新值B。在执行数据操作时，当且仅当V的值等于A时，CAS才会通过原子操作方式用新值B来更新V的值（无论操作是否成功都会返回）。 CAS的含义是：我认为V的值应该为A，如果是，那么将V的值更新为B，否则不修改并告诉V的值实际为多少 CAS是怎么获取到预期值的? 通过unsafe类获取到的 12345678public final int getAndAddInt(Object var1, long var2, int var4) { int var5; do { var5 = this.getIntVolatile(var1, var2); } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;} CAS修改的值为什么要是volatile? 可见性 在compareAndSet的操作中，JNI借助CPU指令完成的，属于原子操作，保证多个线程在执行过程中看到同一个变量的修改值unsafe：操作内存内存空间valueOffset：value在内存中的偏移量（把存储单元的实际地址与其所在段的段地址之间的距离称为段内偏移），这里我们可以简单认为是内存地址，在类加载的时候，通过unsafe获取到value的偏移量。value： 顾名思义代表存储值，被volatile修饰，保证在线程间的可见性 CAS问题：1.ABA问题。CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。ABA问题的解决思路就是在变量前面添加版本号，每次变量更新的时候都把版本号加一，这样变化过程就从“A－B－A”变成了“1A－2B－3A”。JDK从1.5开始提供了AtomicStampedReference类来解决ABA问题，具体操作封装在compareAndSet()中。compareAndSet()首先检查当前引用和当前标志与预期引用和预期标志是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值。2.循环时间长开销大。CAS操作如果长时间不成功，会导致其一直自旋，给CPU带来非常大的开销。3.只能保证一个共享变量的原子操作。对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。Java从1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。 白话：CAS是Compare and Swap，比较并交换，是一种乐观锁实现线程安全的方式，更加轻量。底层是通过cpu的原子指令实现的比较并替换。使用的时候参数有内存位置，预期值，写入的新值，当通过内存位置拿到的值和预期值相等时，就用新值进行替换，整个操作是原子的，cpu指令保证。 - sychronized使用及原理# 修饰实例方法：作用于当前对象实例加锁，进入同步代码前要获得 当前对象实例的锁 修饰静态方法: 也就是给当前类加锁，会作用于类的所有对象实例 ，进入同步代码前要获得 当前 class 的锁。 修饰代码块: 对应的锁则是，传入的synchoronzed的对象实例。 synchronized原理对象分为3部分：对象头，对象数据，填充内容。对象头又分为：Mark Word，类型指针、数组长度。synchronized的锁依赖java对象头, 通过对象头中的mark word 和 monitor实现锁机制。mark word主要会记录对象关于锁的信息（偏向锁、轻量锁、重量锁）。Monitor是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步。 其中有两个队列 _EntryList和 _WaitSet，它们是用来保存ObjectMonitor对象列表， _owner指向持有ObjectMonitor对象的线程。当多个线程访问同步代码时，线程会进入_EntryList区，当线程获取对象的monitor后(对于线程获得锁的优先级，还有待考究)进入 _Owner区并且将 _owner指向获得锁的线程(monitor对象被线程持有)， _count++，其他线程则继续在 _EntryList区等待。若线程调用wait方法，则该线程进入 _WaitSet区等待被唤醒。线程执行完后释放monitor锁并且对ObjectMonitor中的值进行复位。 上面说到synchronized使用的锁都放在对象头里，大概指的就是Mark Word中指向互斥量的指针指向的monitor对象内存地址了。由以上可知为什么Java中每一个对象都可以作为锁对象了。 白话：sychronized可以使用在实例方法、静态方法和代码块上。synchronized依赖java对象头中的mark word和monitor实现线程同步。mark word会记录对象关于锁的信息（偏向锁、轻量锁、重量锁）。Monitor依赖于底层的操作系统的Mutex Lock（互斥锁）实现的线程同步。synchronized有多种锁类型，偏向锁、轻量锁、重量锁。偏向锁，通过对比Mark Word里存储的锁偏向的线程ID解决加锁问题，最多执行一次CAS操作。升级：当一个线程正持有偏向锁，被另外的线程所访问获取锁失败，偏向锁就会升级为轻量级锁。轻量级锁，线程通过线程栈帧与对象mark word之间的多次CAS操作和自旋，尝试获取轻量级锁。升级：若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。重量级锁：是将除了拥有锁的线程以外的线程都阻塞。依赖操作系统的metex lock, 存在用户态和内核态切换，消耗较大 - 锁升级#偏向锁通过对比Mark Word里存储的锁偏向的线程ID解决加锁问题，避免执行CAS操作。升级时机：当持有偏向锁的时候，被另外的线程所访问获取锁失败，偏向锁就会升级为轻量级锁。轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。 先在栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝 拷贝对象头中的Mark Word复制到锁记录中。拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。升级时机：若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。 重量级锁*是将除了拥有锁的线程以外的线程都阻塞。依赖操作系统的metex lock, 存在用户态和内核态切换，消耗较大。 - sychronized缺点# 效率低:锁的释放情况少,试图获得锁时不能设定超时,不能中断一个正在试图获得所得线程。 使用synchroinzed修饰一个代码块时，如果一个线程获取了对应的锁，并执行改代码块，其他线程只能一直等待。等待获取锁的线程释放锁，但是获取锁的线程执行释放锁只有2种方式（要么是执行完该代码块，正常释放。要么是.线程执行发生异常，JVM自动释放）一旦这个锁被别人获取，如果我还想获取，那么我只能选择等待或阻塞，只得到别的线程释放，如果别人永远不释放锁，那我只能永远等待下去。不能设定超时等待，无法做到响应中断。 不够灵活（多个线程只是做读写操作，线程直接就发生冲突。） 非公平。使用synchroinzd，非公平锁使一些线程处于饥饿状态，对于一些线程，可能长期无法抢占到锁。对于某些特定的业务，必须使用公平锁，这时synchronized无法满足要求 无法知道是否成功获取到锁 白话: 无有限等待。没有tryLock(带时间参数) 不可中断。没有lockInterruptibly(调用后一直阻塞到获得锁 但是接受中断信号) 读写锁不分离。没有读写锁，读读固定互斥，影响并发 不支持公平锁。 获取锁无返回值。无法知道线程当前有没有成功获得到锁，没有tryLock的返回值 无多路通知机制。lock.condition - sychronized reentranlock 的区别# 有限等待：需要有一种机制可以不让等待的线程一直无期限地等待下去（比如只等待一定的时间或者能够响应中断），这个是synchronized无法办到，Lock可以办到，由tryLock(带时间参数)实现； 可中断：使用synchronized时，等待的线程会一直阻塞，一直等待下去，不能够响应中断，而Lock锁机制可以让等待锁的线程响应中断，由lockInterruptibly()实现； 有返回值：需要一种机制可以知道线程有没有成功获得到锁，这个是synchronized无法办到，Lock可以办到，由tryLock()方式实现； 公平锁：synchronized中的锁是非公平锁，ReentrantLock默认情况下也是非公平锁，但可以通过构造方法ReentrantLock(true)来要求使用公平锁（底层由Condition的等待队列实现）。 读写分离，提高多个线程读操作并发效率：需要一种机制来使得多个线程都只是进行读操作时，线程之间不会发生冲突，这个是synchronized无法办到，Lock可以办到。 可实现选择性多路通知（锁可以绑定多个条件） - sychronized 和 valotile 的区别# 作用范围。volatile更轻量，性能更好，但volatile只能用于变量而synchronized关键字可以修饰方法以及代码块 是否阻塞。多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞 是否保证原子性。volatile关键字能保证数据的可见性，但不能保证数据的原子性 （eg： i++）.synchronized关键字两者都能保证 是否保证同步。volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性 - 弱引用#强引用任何被强引用指向的对象都不能被垃圾回收器回收。软引用如果有软引用指向这些对象，则只有在内存空间不足时才回收这些对象（回收发生在OutOfMemoryError之前）。弱引用如果一个对象只有弱引用指向它，垃圾回收器会立即回收该对象，这是一种急切回收方式。虚引用虚引等同于没有引用，拥有虚引用的对象可以在任何时候被垃圾回收器回收。 弱引用的出现就是为了垃圾回收服务的。它引用一个对象，但是并不阻止该对象被回收。如果使用一个强引用的话，只要该引用存在，那么被引用的对象是不能被回收的。弱引用则没有这个问题。在垃圾回收器运行的时候，如果一个对象的所有引用都是弱引用的话，该对象会被回收 - ThreadLocal原理#用多线程多份数据，来避免线程不安全 每个Thread 维护一个 ThreadLocalMap 映射表，这个映射表的 key是 ThreadLocal 实例本身，value 是真正需要存储的 Object。也就是说 ThreadLocal 本身并不存储值，它只是作为一个 key 来让线程从 ThreadLocalMap 获取 value。 由于每一条线程均含有各自私有的ThreadLocalMap容器，这些容器相互独立互不影响，因此不会存在线程安全性问题，从而也无需使用同步机制来保证多条线程访问容器的互斥性。 ThreadLocalMap 是使用 ThreadLocal 的弱引用作为 Key的，弱引用的对象在 GC 时会被回收。Entry 继承 WeekReference&lt;ThreadLocal&lt;?&gt;&gt;，也就是说，一个Entry对象是由ThreadLocal对象和一个Object（ThreadLocal关联的对象）组成。 为什么选择弱引用？为了应对非常大和长时间的用途，哈希表使用弱引用的 key由于ThreadLocalMap的生命周期跟Thread一样长，如果都没有手动删除对应key，都会导致内存泄漏，但是使用弱引用可以多一层保障：弱引用ThreadLocal key不会内存泄漏，对应的value在下一次ThreadLocalMap调用set,get,remove的时候会被清除 内存泄漏问题在ThreadLocalMap中，只有key是弱引用，value仍然是一个强引用。当某一条线程中的ThreadLocal使用完毕，没有强引用指向它的时候，这个key指向的对象就会被垃圾收集器回收，从而这个key就变成了null；然而，此时value和value指向的对象之间仍然是强引用关系，只要这种关系不解除，value指向的对象永远不会被垃圾收集器回收，从而导致内存泄漏！ 解决办法：ThreadLocal提供了这个问题的解决方案，其实，ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。但是这些被动的预防措施并不能保证不会内存泄漏：使用static的ThreadLocal，延长了ThreadLocal的生命周期，可能导致的内存泄漏。分配使用了ThreadLocal又不再调用get(),set(),remove()方法，那么就会导致内存泄漏。 ThreadLocal最佳实践综合上面的分析，我们可以理解ThreadLocal内存泄漏的前因后果，那么怎么避免内存泄漏呢？每次使用完ThreadLocal，都调用它的remove()方法，清除数据。在使用线程池的情况下，没有及时清理ThreadLocal，不仅是内存泄漏的问题，更严重的是可能导致业务逻辑出现问题。所以，使用ThreadLocal就跟加锁完要解锁一样，用完就清理。 - AQS同步器原理？tryAcquire的过程？#**AQS使用一个volatile的int类型的成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作。AQS通过CAS完成对state值的修改 核心思想是，如果被请求的共享资源空闲，将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，将暂时获取不到锁的线程加入到队列中, 需要一定的阻塞等待唤醒机制机制来保证锁分配。这个机制主要用的是CLH队列实现的** AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配。通过简单的几行代码就能实现同步功能，这就是AQS的强大之处。 自定义同步器实现的相关方法也只是为了通过修改State字段来实现多线程的独占模式或者共享模式。自定义同步器需要实现以下方法（ReentrantLock需要实现的方法如下，并不是全部）： ReentrantLock这类自定义同步器自己实现了获取锁和释放锁的方式，而其余的等待队列的处理、线程中断等功能，异常与性能处理，还有并发优化等细节工作，都是由AQS统一提供，这也是AQS的强大所在。对同步器这类应用层来说，AQS屏蔽了底层的，同步器只需要设计自己的加锁和解锁逻辑即可 一般来说，自定义同步器要么是独占方式，要么是共享方式，它们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。ReentrantLock是独占锁，所以实现了tryAcquire-tryRelease。 独占与共享最大不同就在各自的tryacquire里，对于独占来说只有true或false，只有一个线程得以执行任务；而对于共享锁的tryAcquireShared来说，线程数没达到限制都可以直接执行。但本质上都是对AQS同步状态的修改，一个是0与1之间，另一个允许更多而已 应用：1.ReentrantLock使用AQS保存锁重复持有的次数。当一个线程获取锁时，ReentrantLock记录当前获得锁的线程标识，用于检测是否重复获取，以及错误线程试图解锁操作时异常情况的处理。2.Semaphore使用AQS同步状态来保存信号量的当前计数。tryRelease会增加计数，acquireShared会减少计数。3.CountDownLatch使用AQS同步状态来表示计数。计数为0时，所有的Acquire操作（CountDownLatch的await方法）才可以通过 白话：AQS是jdk提供的一个同步器，可以很方便的生成自定义同步器。AQS内部使用一个volatile的state来表示同步状态，通过一个FIFO队列来做多线程获取资源的排队操作，AQS通过CAS来做state变量的修改。实现AQS只要实现其中判断获取锁和释放锁的方法即可，AQS内部会去做队列入队出队等复杂逻辑处理。使用AQS实现的同步器有ReentrantLock，Semaphore，CountDownLatch。 - CountDownLatch、Semaphore、CyclicBarrier含义及实现原理#CountDownLatch一个或多个线程等待其他线程完成一些列操作CountDownLatch是一个同步辅助类，当CountDownLatch类中的计数器减少为0之前所有调用await方法的线程都会被阻塞，如果计数器减少为0，则所有线程被唤醒继续运行。 典型应用场景 开始执行前等待n个线程完成各自任务：例如有一个任务想要往下执行，但必须要等到其他任务执行完毕后才可以继续往下执行。假如这个想要继续往下执行的任务调用一个CountDownLatch对象的await()方法，其他的任务执行完自己的任务后调用同一个CountDownLatch对象上的countDown()方法，这个调用await()方法的任务将一直阻塞等待，直到这个CountDownLatch对象的计数值减到0为止。 CyclicBarrier多个线程相互等待，直到到达同一个同步点，再继续一起执行。CyclicBarrier适用于多个线程有固定的多步需要执行，线程间互相等待，当都执行完了，在一起执行下一步。 CyclicBarrier和CountDownLatch的异同CountDownLatch 是一次性的，CyclicBarrier 是可循环利用的CountDownLatch 参与的线程的职责是不一样的，有的在倒计时，有的在等待倒计时结束。CyclicBarrier 参与的线程职责是一样的。 个人理解： CountDownLatch 是当前线程等着别人做好再开始做。像做饭一样，买好菜。CountDownLatch内部是AQS做的同步，共享模式，共享释放，只有减到0才能获得countdownlatchawait的时候，判断当前state是否为0，为0可以获取共享锁，非0则加入阻塞。countdown的时候，将state -1 , 并判断是否减到0， 减到0就唤醒阻塞的线程。 Semaphore 是多个线程去获取，有的话就有，没有就等着。 像买房摇号。Semaphore 内部是AQS做的同步，非0就可获得，0就不行了 CyclicBarrier 是各个线程都达到某个预设点的时候， 可以执行一段逻辑，然后打开所有线程的限制。 像赛马.CyclicBarrier 底层是依赖Reentrantlock保证同步 和 一个condition 来阻塞和放开早到达的多个线程，其实也是AQS java异步#- Callable、Future、FutureTask、CompletableFuture分别是什么#Callable是一个接口，提供一个回调方法，可以放到executorService中 Future接口提供了三种功能：1）判断任务是否完成；2）能够中断任务；3）能够获取任务执行结果。 FutureTask可以看出RunnableFuture继承了Runnable接口和Future接口，而FutureTask实现了RunnableFuture接口，那就可以得出FutureTask即可以作为一个Runnable线程执行，又可以作为Future得到Callable返回值。FutureTask是Future的唯一实现类 listenableFutureListenableFuture和JDK原生Future最大的区别是前者做到了一个可以监听结果的Futurevoid addListener(Runnable listener, Executor executor); CompletableFuture在JDK8中开始引入的，这个在一定程度上与ListenableFuture非常类似。比如说ListenableFuture的listener监听回调，在这个类中，相当于thenRun或者whneComplete操作原语 线程池#- 线程池的创建使用、有哪些参数#为什么要用线程池？ 1. 降低资源消耗。 通过重复利用已创建的线程降低线程创建和销毁造成的消耗 （重复利用） 2. 提高响应速度。 当任务到达时，任务可以不需要的等到线程创建就能立即执行 （提前开始任务） 3. 提高线程的可管理性。 线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控 （控制线程数量） 如何创建线程池 1. Executors - 不允许 CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致OOM 2. ThreadPoolExcutor 参数： 核心线程数， 最大线程数，非核心线程空闲存活时间，阻塞队列，拒绝策略，有必要的话还有ThreadFactory线程工厂. 好处： - corePoolSize, maximumPoolSize 弹性控制线程数量，可伸缩，可扩容可释放 - keepAliveTime, TimeUnit.SECONDS 设置后在回收前可让其他任务使用，减少重新创建线程的开销 - BlockingQueue, 设置队列大小，起到缓冲的作用 - rejectHandler - 线程池的原理# 先讲构造参数corePoolSize： 线程池核心线程数最大值maximumPoolSize： 线程池最大线程数大小keepAliveTime： 线程池中非核心线程空 闲的存活时间大小unit： 线程空闲存活时间单位workQueue： 存放任务的阻塞队列threadFactory： 用于设置创建线程的工厂，可以给创建的线程设置有意义的名字，可方便排查问题。handler： 线城池的饱和策略事件，主要有四种类型。 再描述提交任务后的执行过程 提交一个任务，线程池里存活的核心线程数小于线程数corePoolSize时，线程池会创建一个核心线程去处理提交的任务。 如果线程池核心线程数已满，即线程数已经等于corePoolSize，一个新提交的任务，会被放进任务队列workQueue排队等待执行。 当线程池里面存活的线程数已经等于corePoolSize了,并且任务队列workQueue也满，判断线程数是否达到maximumPoolSize，即最大线程数是否已满，如果没到达，创建一个非核心线程执行提交的任务。 如果当前的线程数达到了maximumPoolSize，还有新的任务过来的话，直接采用拒绝策略处理。 四种拒绝策略 AbortPolicy(抛出一个异常，默认的)DiscardPolicy(直接丢弃任务)DiscardOldestPolicy（丢弃队列里最老的任务，将当前这个任务继续提交给线程池）CallerRunsPolicy（交给线程池调用所在的线程进行处理) 如何自定义拒绝策略：实现RejectedExecutionHandler接口，实现rejectedExecution方法public interface RejectedExecutionHandler { void rejectedExecution(Runnable r, ThreadPoolExecutor executor);} - 怎么配置参数#线程数： 如果是CPU密集型应用，则线程池大小设置为N+1 如果是IO密集型应用，则线程池大小设置为2N+1 系统负载： 一个进程或线程正在被cpu执行或等待被cpu执行，则系统负载+1， 单核cpu负载小于1表示cpu可以在线程不等待的情况下处理完 IO密集：通常指网络IO","link":"/2021/07/29/interview/juc/"}],"tags":[{"name":"java","slug":"java","link":"/tags/java/"},{"name":"并发","slug":"并发","link":"/tags/并发/"},{"name":"jvm","slug":"jvm","link":"/tags/jvm/"},{"name":"concurrenthashmap","slug":"concurrenthashmap","link":"/tags/concurrenthashmap/"},{"name":"design","slug":"design","link":"/tags/design/"},{"name":"framework","slug":"framework","link":"/tags/framework/"},{"name":"pcursor","slug":"pcursor","link":"/tags/pcursor/"},{"name":"设计模式","slug":"设计模式","link":"/tags/设计模式/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"英语","slug":"英语","link":"/tags/英语/"},{"name":"hadoop","slug":"hadoop","link":"/tags/hadoop/"},{"name":"hashmap","slug":"hashmap","link":"/tags/hashmap/"},{"name":"生活","slug":"生活","link":"/tags/生活/"},{"name":"maven","slug":"maven","link":"/tags/maven/"},{"name":"mybatis","slug":"mybatis","link":"/tags/mybatis/"},{"name":"List","slug":"List","link":"/tags/List/"},{"name":"面经","slug":"面经","link":"/tags/面经/"},{"name":"机器学习","slug":"机器学习","link":"/tags/机器学习/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"锁","slug":"锁","link":"/tags/锁/"},{"name":"索引","slug":"索引","link":"/tags/索引/"},{"name":"innodb","slug":"innodb","link":"/tags/innodb/"},{"name":"netty","slug":"netty","link":"/tags/netty/"},{"name":"线上问题","slug":"线上问题","link":"/tags/线上问题/"},{"name":"network","slug":"network","link":"/tags/network/"},{"name":"读书笔记","slug":"读书笔记","link":"/tags/读书笔记/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"tair","slug":"tair","link":"/tags/tair/"},{"name":"springboot","slug":"springboot","link":"/tags/springboot/"},{"name":"rss","slug":"rss","link":"/tags/rss/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"storm","slug":"storm","link":"/tags/storm/"},{"name":"旅游","slug":"旅游","link":"/tags/旅游/"},{"name":"vim","slug":"vim","link":"/tags/vim/"},{"name":"zookeeper","slug":"zookeeper","link":"/tags/zookeeper/"},{"name":"kafka","slug":"kafka","link":"/tags/kafka/"}],"categories":[{"name":"并发","slug":"并发","link":"/categories/并发/"},{"name":"java","slug":"java","link":"/categories/java/"},{"name":"design","slug":"design","link":"/categories/design/"},{"name":"设计模式","slug":"设计模式","link":"/categories/设计模式/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"英语","slug":"英语","link":"/categories/英语/"},{"name":"hadoop","slug":"hadoop","link":"/categories/hadoop/"},{"name":"jvm","slug":"jvm","link":"/categories/jvm/"},{"name":"生活","slug":"生活","link":"/categories/生活/"},{"name":"maven","slug":"maven","link":"/categories/maven/"},{"name":"mybatis","slug":"mybatis","link":"/categories/mybatis/"},{"name":"面经","slug":"面经","link":"/categories/面经/"},{"name":"机器学习","slug":"机器学习","link":"/categories/机器学习/"},{"name":"mysql","slug":"mysql","link":"/categories/mysql/"},{"name":"netty","slug":"netty","link":"/categories/netty/"},{"name":"线上问题","slug":"线上问题","link":"/categories/线上问题/"},{"name":"network","slug":"network","link":"/categories/network/"},{"name":"读书笔记","slug":"读书笔记","link":"/categories/读书笔记/"},{"name":"redis","slug":"redis","link":"/categories/redis/"},{"name":"springboot","slug":"springboot","link":"/categories/springboot/"},{"name":"rss","slug":"rss","link":"/categories/rss/"},{"name":"spring","slug":"spring","link":"/categories/spring/"},{"name":"storm","slug":"storm","link":"/categories/storm/"},{"name":"旅游","slug":"旅游","link":"/categories/旅游/"},{"name":"vim","slug":"vim","link":"/categories/vim/"},{"name":"zookeeper","slug":"zookeeper","link":"/categories/zookeeper/"},{"name":"kafka","slug":"kafka","link":"/categories/kafka/"}]}